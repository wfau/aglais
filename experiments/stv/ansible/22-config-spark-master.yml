#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

- name: "Configure YARN masters"
  hosts: master01:zeppelin
  gather_facts: false
  vars:
    hdbase: "/opt"
    hdhome: "/opt/hadoop"
    hdhost: "{{groups['masters'][0]}}"
    spbase: "/opt"
    sphome: "/opt/spark"
    spdata: "/var/local/spark"
    sphost: "master01"
    spuser: "{{hostvars[inventory_hostname].login}}"

  tasks:

    - name: Creates directory
      file:
        path: "{{sphome}}/local"
        state: directory
        owner: "{{spuser}}"
        group: "{{spuser}}"
        mode: 0775
    #
    # Documentation
    # https://spark.apache.org/docs/3.0.0-preview2/running-on-yarn.html#configuration
    # https://spark.apache.org/docs/3.0.0-preview2/configuration.html
    #
    - name: "Configure [{{sphome}}/conf/spark-defaults.conf]"
      become: true
      blockinfile:
        path:   "{{sphome}}/conf/spark-defaults.conf"
        create: yes
        marker: "# {mark} Ansible managed Spark configuration"
        insertbefore: "EOF"
        block: |
            # https://spark.apache.org/docs/3.0.0-preview2/running-on-yarn.html#spark-properties
            spark.master            yarn
            spark.driver.memory              5g
            spark.yarn.am.memory            5g
            spark.executor.memory          5g
            spark.eventLog.enabled  true
            spark.driver.maxResultSize	8192m
            spark.local.dir         {{sphome}}/local
            spark.executor.cores            3
            spark.master            yarn
            spark.eventLog.enabled  true
            spark.eventLog.dir      hdfs://{{hdhost}}:9000/spark-log
    
    #
    # https://spark.apache.org/docs/3.0.0-preview2/configuration.html#environment-variables
    # - name: "Update [/etc/profile.d/spark.sh]"
    #   become: true
    #   blockinfile:
    #     dest:  '/etc/profile.d/spark.sh'
    #     state: present
    #     create: yes
    #     owner: 'root'
    #     group: 'root'
    #     mode:  'u=rw,g=r,o=r'
    #     insertafter: 'EOF'
    #     marker: '# {mark} Ansible managed Hadoop config'
    #     block: |
    #       export YARN_CONF_DIR={{hdhome}}/etc/hadoop
    #       export HADOOP_CONF_DIR={{hdhome}}/etc/hadoop

    #
    # https://spark.apache.org/docs/3.0.0-preview2/configuration.html#environment-variables
    # Note: When running Spark on YARN in cluster mode, environment variables need to be set using the spark.yarn.appMasterEnv.[EnvironmentVariableName] property in your conf/spark-defaults.conf file.
    # Environment variables that are set in spark-env.sh will not be reflected in the YARN Application Master process in cluster mode.
    - name: "Configure [{{sphome}}/conf/spark-defaults.conf]"
      become: true
      blockinfile:
        path:   "{{sphome}}/conf/spark-defaults.conf"
        create: yes
        marker: "# {mark} Ansible managed Spark environment"
        insertbefore: "EOF"
        block: |
            # https://spark.apache.org/docs/3.0.0-preview2/configuration.html#inheriting-hadoop-cluster-configuration
            spark.yarn.appMasterEnv.YARN_CONF_DIR={{hdhome}}/etc/hadoop
            spark.yarn.appMasterEnv.HADOOP_CONF_DIR={{hdhome}}/etc/hadoop

#
# TODO Experiment
# Move Spark to master02, add Yarn config.
# {{hdhome}}/etc/hadoop/yarn-site.xml


#
# TODO History server.
# https://spark.apache.org/docs/3.0.0-preview2/monitoring.html#viewing-after-the-fact
#
# TODO Metrics.
# https://spark.apache.org/docs/3.0.0-preview2/monitoring.html#metrics
#
