#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#  
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#




# To summarise issue 155: 
# We're running the HDBSCAN on a single worker node via a Spark job. This job takes a long time to continue, and eventuall causes the worker node to detach from the Yarn/Hadoop Cluster
# Any further Spark jobs fail with a "Connection Refused" exception
# ...

# Continuing from where we left off, we are currently in a state described above, where no Zeppelin jobs are running.


# Restart Hadoop
# ------------------------------
ssh stv-dev-master
  stop-all.sh
  start-all.sh

  # All good, no errors

exit


# Check Hadoop Status
# ------------------------------

# All good, no dead/lost nodes
# All worker nodes show up as live




# Try running a simple Spark cell
# -------------------------------

java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)

# Oops, looks like a simple hadoop restart doesn't recover Zeppelin, we need to restart Zeppelin itself




# Restart Zeppelin
# ------------------------------

ssh stv-dev-master
  /home/fedora/zeppelin/bin/zeppelin-daemon.sh restart
exit



# -------------------------------------------------------------
# Let's try to kill Zeppelin/Spark again, and closely observe the logs
# Run the following Notebook:
http://128.232.224.69:8080/#/notebook/2FG43SCW3

# First few cells work fine ..
# The Cell with ID 20200605-165000_1292852380 seem to have ran for over 20 minutes. Then failed with the following error

io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at io.grpc.Status.asRuntimeException(Status.java:526)
	at io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:434)
	at io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
	at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
	at io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
	at io.grpc.internal.CensusStatsModule$StatsClientInterceptor$1$1.onClose(CensusStatsModule.java:678)
	at io.grpc.PartialForwardingClientCallListener.onClose(PartialForwardingClientCallListener.java:39)
	at io.grpc.ForwardingClientCallListener.onClose(ForwardingClientCallListener.java:23)
	at io.grpc.ForwardingClientCallListener$SimpleForwardingClientCallListener.onClose(ForwardingClientCallListener.java:40)
	at io.grpc.internal.CensusTracingModule$TracingClientInterceptor$1$1.onClose(CensusTracingModule.java:403)
	at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:459)
	at io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:63)
	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:546)
	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$600(ClientCallImpl.java:467)
	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:584)
	at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.zeppelin.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /127.0.0.1:36011
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zeppelin.io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:325)
	at org.apache.zeppelin.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)
	at org.apache.zeppelin.io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:634)
	at org.apache.zeppelin.io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:581)
	at org.apache.zeppelin.io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:498)
	at org.apache.zeppelin.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
	at org.apache.zeppelin.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:884)
	at org.apache.zeppelin.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	... 11 more
Fail to setJobGroup



# Trying out a Spark cell in a different notebook, we see the following exception:

java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:182)
	at org.apache.zeppelin.interpreter.remote.ClientFactory.create(ClientFactory.java:51)
	at org.apache.zeppelin.interpreter.remote.ClientFactory.create(ClientFactory.java:37)
	at org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:60)
	at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:861)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:435)
	at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:363)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.getClient(RemoteInterpreterProcess.java:62)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:133)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:228)



# Let's try restarting the Spark interpreter this time.
# In Zeppelin GUI, Click on "admin" username on top right to get menu / Interpreter / Spark / Restart


# Run some Spark jobs in this notebook: http://128.232.224.69:8080/#/notebook/2FGP4V8EJ
# Running Spark jobs now works!
# So a restart of the interpreter did the trick
 


# Attempt 4
# ---------------------------------

	# Run the same notebook
	# Different issue this time??
	# Running cell with id: 20200709-153147_80241281 in notebook 2FG43SCW3 completes after 17 minutes

	# Running the next cell produces this exception


	---------------------------------------------------------------------------
	ModuleNotFoundError                       Traceback (most recent call last)
	<ipython-input-20-25905647c0ce> in <module>
	----> 1 import hdbscan
	      2 
	      3 def clustering_info(clusterer, add_to_data=False, df=[], index=-1):
	      4     '''
	      5     REQUIRED

	ModuleNotFoundError: No module named 'hdbscan'


	# hdbscan module not available????


	# Restart Zeppelin and Hadoop

	ssh stv-dev-master
	   stop-all.sh
	   start-all.sh
	exit


	ssh stv-dev-zeppelin
	  /home/fedora/zeppelin/bin/zeppelin-daemon.sh restart
	exit


	# importing hdbscan now works..








# Attempt 5
# ---------------------------------

	# Run the same notebook
	# Running cell with id: 20200709-153147_80241281 took 17 but completed this time
	# Running cell with id: 20200605-165000_1292852380 failed with exception:

	org.apache.thrift.transport.TTransportException
		at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)
		....


	# All other Spark notebook cells fail...


	# Attempted fix a) Restart Interpreter
	# ---------------------

		# hdbscan module not available again..

		# Exception when running first cell in:
		# http://128.232.224.69:8080/#/notebook/2FGP4V8EJ
		---------------------------------------------------------------------------
		ModuleNotFoundError                       Traceback (most recent call last)
		<ipython-input-8-7087a469dced> in <module>
		      1 import sys, os
		----> 2 import hdbscan
		      3 print(sys.executable)
		      4 #import healpy
		      5 #import matplotlib

		ModuleNotFoundError: No module named 'hdbscan'

		# Try the kounkel & covey UDF notebook again from the beginning
		# All cells seem to work fine, except the usual problematic one



	# Attempted fix (now for hdbscan missing issue) b) Restart Zeppelin
	# ---------------------
		
	ssh stv-dev-zeppelin
	  /home/fedora/zeppelin/bin/zeppelin-daemon.sh restart
	exit


	# importing hdbscan now works again..




# Brief Summary so far
#-----------------------------------------------

# Cell in Kunkel and Covey that runs HDBSCAN in the Spark interpreter consistently kills the Zeppelin/Spark interaction, so that no Spark cells can work unless we manually invervene to restart.
# Restarting interpreter seems to work for that notebook, but causes other strange behaviours in other notebooks, like making hdbscan library unavailable
# Restarting Zeppelin seems to do be the only way for Zeppelin to recover correctly.


