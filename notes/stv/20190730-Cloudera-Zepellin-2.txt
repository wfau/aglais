#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2018, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

## Notes on experiments with Cloudera



## Links
https://medium.com/@SnazzyHam/how-to-get-up-and-running-with-clouderas-quickstart-docker-container-732c04ed0280
https://www.cloudera.com/documentation/enterprise/5-6-x/topics/quickstart_docker_container.html
https://justtech.blog/2019/01/31/howto-run-cloudera-quickstart-in-docker/
https://zeppelin.apache.org/docs/0.7.0/install/docker.html



## Pull official Cloudera image
docker pull cloudera/quickstart:latest




## Start Cloudera container
docker run -it \
 -p 81:80 \
 -p 7180:7180 \
 -p 4040:4040 \
 -p 8020:8020 \
 -p 8022:8022 \
 -p 8030:8030 \
 -p 8032:8032 \
 -p 8033:8033 \
 -p 8040:8040 \
 -p 8042:8042 \
 -p 8088:8088 \
 -p 8480:8480 \
 -p 8485:8485 \
 -p 8888:8888 \
 -p 9083:9083 \
 -p 10020:10020 \
 -p 10033:10033 \
 -p 18088:18088 \
 -p 19888:19888 \
 -p 25000:25000 \
 -p 25010:25010 \
 -p 25020:25020 \
 -p 50010:50010 \
 -p 50020:50020 \
 -p 50070:50070 \
 -p 50075:50075 \
 -h quickstart.cloudera --privileged=true \
   cloudera/quickstart  /usr/bin/docker-quickstart;



## By default, cloudera manager is not started in container, so, lets enable it first.
[root@quickstart /]# /home/cloudera/cloudera-manager --express


## Open in browser

# Hue: http://0.0.0.0:8888 username: cloudera / password: cloudera
# Cloudera Live: http://0.0.0.0:81/#/

# Cloudera Manager http://0.0.0.0:32771/cmf/home
# username: cloudera
# password: cloudera



## Number of errors show up in Cloudera Manager

date      # will show difference between real date and server one
sudo chkconfig --add ntpd
sudo service ntpd restart 
date      # to make sure that ntpd is working and date is sync




## -----------------------------------------------------------------------------





## Check our Zeppelin and Hadoop Version

## In Cloudera Container

[root@quickstart zeppelin]# spark-submit --version
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 1.6.0
      /_/
                        
Type --help for more information.



[root@quickstart zeppelin]# hadoop version
Hadoop 2.6.0-cdh5.7.0
Subversion http://github.com/cloudera/hadoop -r c00978c67b0d3fe9f3b896b5030741bd40bf541a
Compiled by jenkins on 2016-03-23T18:36Z
Compiled with protoc 2.5.0
From source with checksum b2eabfa328e763c88cb14168f9b372
This command was run using /usr/jars/hadoop-common-2.6.0-cdh5.7.0.jar





## Can we submit a job to Spark in Yarn mode?
## Example command, files and class are not there, so this should fail gracefully (expecting missing jar / classes message)

spark-submit --class org.apache.spark.examples.SparkPi     --master yarn     --deploy-mode cluster     --driver-memory 4g     --executor-memory 2g     --executor-cores 1     --queue thequeue     examples/jars/spark-examples*.jar     10

..
## 19/08/02 17:54:59 INFO ipc.Client: Retrying connect to server: quickstart.cloudera/172.17.0.2:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)

## Restart Yarn Resource Manager

sudo service hadoop-yarn-resourcemanager restart

## Restart Hadoop Node

service hadoop-hdfs-namenode restart



## And Try again

spark-submit --class org.apache.spark.examples.SparkPi     --master yarn     --deploy-mode cluster     --driver-memory 4g     --executor-memory 2g     --executor-cores 1     --queue thequeue     examples/jars/spark-examples*.jar     10

Exception in thread "main" java.lang.IllegalArgumentException: Required AM memory (4096+409 MB) is above the max threshold (2816 MB) of this cluster! Please increase the value of 'yarn.scheduler.maximum-allocation-mb'.
	at org.apache.spark.deploy.yarn.Client.verifyClusterResources(Client.scala:291)
	at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:140)
	at org.apache.spark.deploy.yarn.Client.run(Client.scala:1023)
	at org.apache.spark.deploy.yarn.Client$.main(Client.scala:1083)
	at org.apache.spark.deploy.yarn.Client.main(Client.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)



## Reduce Executor & driver memory 
## And Try again


19/08/02 18:11:28 INFO client.RMProxy: Connecting to ResourceManager at quickstart.cloudera/172.17.0.2:8032
19/08/02 18:11:28 INFO yarn.Client: Requesting a new application from cluster with 0 NodeManagers
19/08/02 18:11:28 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (2816 MB per container)
19/08/02 18:11:28 INFO yarn.Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead
19/08/02 18:11:28 INFO yarn.Client: Setting up container launch context for our AM
19/08/02 18:11:28 INFO yarn.Client: Setting up the launch environment for our AM container
19/08/02 18:11:28 INFO yarn.Client: Preparing resources for our AM container
Exception in thread "main" org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot create directory /user/root/.sparkStaging/application_1564769048389_0003. Name node is in safe mode.
The reported blocks 0 needs additional 914 blocks to reach the threshold 0.9990 of total blocks 914.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.



## Remove Node from Safemode
## And Try again

sudo su hdfs -l -c 'hdfs dfsadmin -safemode leave'

 ## Safe mode is OFF


19/08/02 18:14:29 INFO client.RMProxy: Connecting to ResourceManager at quickstart.cloudera/172.17.0.2:8032
19/08/02 18:14:29 INFO yarn.Client: Requesting a new application from cluster with 0 NodeManagers
19/08/02 18:14:30 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (2816 MB per container)
19/08/02 18:14:30 INFO yarn.Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead
19/08/02 18:14:30 INFO yarn.Client: Setting up container launch context for our AM
19/08/02 18:14:30 INFO yarn.Client: Setting up the launch environment for our AM container
19/08/02 18:14:30 INFO yarn.Client: Preparing resources for our AM container
19/08/02 18:14:30 INFO yarn.Client: Uploading resource file:/opt/zeppelin/conf/examples/jars/spark-examples*.jar -> hdfs://quickstart.cloudera:8020/user/root/.sparkStaging/application_1564769048389_0004/spark-examples*.jar
19/08/02 18:14:30 INFO yarn.Client: Deleting staging directory .sparkStaging/application_1564769048389_0004
Exception in thread "main" java.io.FileNotFoundException: File file:/opt/zeppelin/conf/examples/jars/spark-examples*.jar does not exist



## Missing Files message
## We now need to setup a real data example

cd ~
mkdir examples
cd examples


nano words.txt
   blah blah ..
....


hdfs dfs -copyFromLocal /root/examples/words.txt


[root@quickstart examples]# hdfs dfs -copyFromLocal /root/examples/words.txt
19/08/02 18:48:56 WARN hdfs.DFSClient: DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/root/words.txt._COPYING_ could only be replicated to 0 nodes instead of minReplication (=1).  There are 0 datanode(s) running and no node(s) are excluded in this operation.

## Restart hdfs nodes
## Namenode not restarting 

	
[root@quickstart examples]# service hadoop-hdfs-namenode start
## Failed to start Hadoop namenode. Return value: 1           [FAILED]


## ...... 


## After trying many things, solution for Namenode to start was to give full permissions (777) to /var/lib/hadoop-hdfs/cache/hdfs/dfs/name directory
## 777 should only be used as a temporary solution, need to figure out later what is the minimum permissions needed (and what group ownership is needed


## Now try copying file from local to hadoop
hadoop fs -copyFromLocal /root/examples/words.txt 
    
    copyFromLocal: `.': No such file or directory


hdfs dfs -ls 

    copyFromLocal: `.': No such file or directory



## Need to specify directory to copy to
# https://stackoverflow.com/questions/48128736/hadoop-copyfromlocal-no-such-file-or-directory

[root@quickstart ~]# hadoop fs -copyFromLocal /root/examples/words.txt  /root
[root@quickstart ~]# hdfs dfs -ls /root
Found 1 items
-rw-r--r--   1 root root        157 2019-08-03 11:21 /root/words.txt






## Create count.py (Spark job file)

text_file = sc.textFile("hdfs://root/words.txt")
counts = text_file.flatMap(lambda line: line.split(" ")) \
             .map(lambda word: (word, 1)) \
             .reduceByKey(lambda a, b: a + b)
counts.saveAsTextFile("hdfs://words-output.txt")




[root@quickstart examples]# spark-submit     --master yarn     --deploy-mode cluster     /root/examples/count.py    
19/08/03 12:43:36 INFO client.RMProxy: Connecting to ResourceManager at quickstart.cloudera/172.17.0.2:8032
19/08/03 12:43:37 INFO yarn.Client: Requesting a new application from cluster with 0 NodeManagers
19/08/03 12:43:37 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (2816 MB per container)
19/08/03 12:43:37 INFO yarn.Client: Will allocate AM container, with 1408 MB memory including 384 MB overhead
19/08/03 12:43:37 INFO yarn.Client: Setting up container launch context for our AM
19/08/03 12:43:37 INFO yarn.Client: Setting up the launch environment for our AM container
19/08/03 12:43:37 INFO yarn.Client: Preparing resources for our AM container
Exception in thread "main" org.apache.hadoop.security.AccessControlException: Permission denied: user=root, access=WRITE, inode="/":hdfs:supergroup:drwxr-xr-x



 
## Permission Denied Error
## Change hadoop fs permissions to 777 (Using 777 just for this example, this probably should be a more strict one, or we need to add the user as a superuser?)   

sudo -u hdfs hadoop fs -chmod -R 777 /root
sudo -u hdfs hadoop fs -chmod -R 777 /




## Spark History Node is down
## Logs show a missing directory, create it

sudo -u hdfs hadoop fs -mkdir /user/spark/applicationHistory
sudo -u hdfs hadoop fs -chmod -R 777 /user/spark/applicationHistory




## Retry submitting ..

spark-submit --master yarn --deploy-mode client --executor-memory 1g \
  --name wordcount --conf "spark.app.id=wordcount" count.py \
  hdfs:/root/words.txt 2




## ..  Gets stuck in a loop  ..

19/08/03 13:49:23 INFO yarn.Client: Application report for application_1564832896083_0022 (state: ACCEPTED)
19/08/03 13:49:24 INFO yarn.Client: Application report for application_1564832896083_0022 (state: ACCEPTED)
19/08/03 13:49:25 INFO yarn.Client: Application report for application_1564832896083_0022 (state: ACCEPTED)




## Check Hadoop Yarn node manager and resource manager

[root@quickstart examples]# sudo service hadoop-yarn-nodemanager status
Hadoop nodemanager is not running                          [FAILED]

[root@quickstart examples]# sudo service hadoop-yarn-resourcemanager status
Hadoop resourcemanager is running                          [  OK  ]



[root@quickstart examples]# sudo service hadoop-yarn-nodemanager restart
no nodemanager to stop
Stopped Hadoop nodemanager:                                [  OK  ]
starting nodemanager, logging to /var/log/hadoop-yarn/yarn-yarn-nodemanager-quickstart.cloudera.out
log4j:ERROR Could not find value for key log4j.appender.RFA
log4j:ERROR Could not instantiate appender named "RFA".
log4j:WARN No appenders could be found for logger (org.apache.hadoop.yarn.server.nodemanager.NodeManager).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/zookeeper/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/llama/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Started Hadoop nodemanager:                                [  OK  ]

[root@quickstart examples]# sudo service hadoop-yarn-nodemanager status
Hadoop nodemanager is running                              [  OK  ]
[root@quickstart examples]# sudo service hadoop-yarn-resourcemanager status
Hadoop resourcemanager is running                          [  OK  ]







## --------------------------------------------------------------------------

## Zepellin Container Setup


## New terminal

## Run separate Docker container with Zepellin
https://zeppelin.apache.org/docs/0.7.3/install/docker.html




## Run Zepellin Container
docker run -p 8080:8080 --rm --name zeppelin apache/zeppelin:0.7.3



docker images
..
apache/zeppelin             0.7.3               393fb4938510        22 months ago       2.42GB
cloudera/quickstart         latest              4239cd2958c6        3 years ago         6.34GB
..



docker ps 

CONTAINER ID        IMAGE                   COMMAND                  CREATED              STATUS              PORTS                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                NAMES
aff4fa041b70        apache/zeppelin:0.7.3   "/usr/bin/tini -- bi…"   About a minute ago   Up About a minute   0.0.0.0:8080->8080/tcp                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               zeppelin
8b9a4a8ae0cd        cloudera/quickstart     "/usr/bin/docker-qui…"   2 hours ago          Up 2 hours          0.0.0.0:4040->4040/tcp, 0.0.0.0:7180->7180/tcp, 0.0.0.0:8020->8020/tcp, 0.0.0.0:8022->8022/tcp, 0.0.0.0:8030->8030/tcp, 0.0.0.0:8032-8033->8032-8033/tcp, 0.0.0.0:8040->8040/tcp, 0.0.0.0:8042->8042/tcp, 0.0.0.0:8088->8088/tcp, 0.0.0.0:8480->8480/tcp, 0.0.0.0:8485->8485/tcp, 0.0.0.0:8888->8888/tcp, 0.0.0.0:9083->9083/tcp, 0.0.0.0:10020->10020/tcp, 0.0.0.0:10033->10033/tcp, 0.0.0.0:18088->18088/tcp, 0.0.0.0:19888->19888/tcp, 0.0.0.0:25000->25000/tcp, 0.0.0.0:25010->25010/tcp, 0.0.0.0:25020->25020/tcp, 0.0.0.0:50010->50010/tcp, 0.0.0.0:50020->50020/tcp, 0.0.0.0:50070->50070/tcp, 0.0.0.0:50075->50075/tcp, 0.0.0.0:81->80/tcp   wizardly_albattani



## Should probably create a Docker network for the two container next time, for now use the host IP: 192.168.42.48




## In Zepellin Container..
## https://zeppelin.apache.org/docs/0.7.3/install/yarn_install.html

root@aff4fa041b70:/zeppelin# cp conf/zeppelin-env.sh.template conf/zeppelin-env.sh


export JAVA_HOME="/usr/java/jdk1.7.0_67-cloudera/"
export HADOOP_CONF_DIR="/etc/hadoop/conf"
export ZEPPELIN_JAVA_OPTS="-Dhdp.version=2.6.0-cdh5.7.0"
export SPARK_HOME="/usr/lib/spark"






