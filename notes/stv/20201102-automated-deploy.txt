#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

# -----------------------------------------------------
# Create Clouds YAML file
#[user@desktop]

cat > "${HOME}/clouds.yaml" << EOF

clouds:


  gaia-test:
    auth:
      auth_url: https://cumulus.openstack.hpc.cam.ac.uk:5000/v3
      application_credential_id:     '$(secret 'stv-gaia-test.CREDENTIAL_ID')'
      application_credential_secret: '$(secret 'stv-gaia-test.CREDENTIAL_SECRET')'
    region_name: "RegionOne"
    interface: "public"
    identity_api_version: 3
    auth_type: "v3applicationcredential"

  gaia-test-super:
    auth:
      auth_url: https://cumulus.openstack.hpc.cam.ac.uk:5000/v3
      application_credential_id:     '$(secret 'stv-gaia-test.CREDENTIAL_ID')'
      application_credential_secret: '$(secret 'stv-gaia-test.CREDENTIAL_SECRET')'
    region_name: "RegionOne"
    interface: "public"
    identity_api_version: 3
    auth_type: "v3applicationcredential"

EOF



# -----------------------------------------------------
# Create our project config file.
#[user@desktop]

cat > "${HOME:?}/aglais.env" << 'EOF'

AGLAIS_REPO='git@github.com:stvoutsin/aglais.git'
AGLAIS_HOME="${PROJECTS_ROOT:?}/aglais"
AGLAIS_CODE="${AGLAIS_HOME:?}"
AGLAIS_CLOUD=gaia-test
AGLAIS_USER=stv

EOF



# -----------------------------------------------------
# Edit hosts.yml file 
#[user@desktop]

  source "${HOME}/aglais.settings"
  nano ${AGLAIS_CODE:?}/experiments/zrq/ansible/hosts.yml
	..	
	keypair: ''
	...


# -----------------------------------------------------
# Create a container to work with.
# https://podman.readthedocs.io/en/latest/markdown/podman-run.1.html
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler10 \
        --hostname ansibler \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock" \
        --env "clouduser=${AGLAIS_USER:?}" \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml" \
        --env "ANSIBLE_CODE=/mnt/ansible" \
        --volume "${AGLAIS_CODE:?}/experiments/zrq/ansible:/mnt/ansible" \
        atolmis/ansible-client:latest \
        bash

	# Success





# -----------------------------------------------------
# Create our Ansible include vars file.
#[root@ansibler]

    cat > /tmp/ansible-vars.yml << EOF
buildtag:  'aglais-$(date '+%Y%m%d')'
cloudname: '${cloudname}'
clouduser: '${clouduser}'
EOF


# -----------------------------------------------------
# Run the scripts from the ansible directory.
#[root@ansibler]

    cd "${ANSIBLE_CODE:?}"



# -----------------------------------------------------
# Run the initial part of our deployment.
#[root@ansibler]
	
    ansible-playbook \
        --inventory "hosts.yml" \
        "combined-01.yml"




# -----------------------------------------------------
# Run the Hadoop part of our deployment.
#[root@ansibler]

    ansible-playbook \
        --inventory "hosts.yml" \
        "combined-02.yml"



# -----------------------------------------------------
# Format the HDFS NameNode on master01.
#[root@ansibler]

    ssh master01 \
        '
        hdfs namenode -format
        '

# -----------------------------------------------------
# Start the HDFS services.
#[root@ansibler]

    ssh master01 \
        '
        start-all.sh
	'	

# -----------------------------------------------------
# Start the HDFS services.
#[root@ansibler]

    ssh master01 \
        '
        hdfs dfsadmin -safemode leave
	'	

# -----------------------------------------------------
# Create our HDFS log directory.
#[root@ansibler]

    ssh master01 \
        '
        hdfs dfs -mkdir /spark-log
        '


# -----------------------------------------------------
# Check the HDFS status.
#[root@ansibler]

    ssh master01 \
        '
        hdfs dfsadmin -report
	'



# -----------------------------------------------------
# Install the Spark binaries.
#[root@ansibler]

    ansible-playbook \
        --inventory "hosts.yml" \
        "20-install-spark.yml"


PLAY RECAP **************************************************************************************************************************************************************************************************
master01                   : ok=3    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
zeppelin                   : ok=3    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0 





# -----------------------------------------------------
# Add the security rules for Spark.
#[root@ansibler]

    ansible-playbook \
        --inventory "hosts.yml" \
        "21-config-spark-security.yml"


PLAY RECAP **************************************************************************************************************************************************************************************************
localhost                  : ok=6    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   



# -----------------------------------------------------
# Create our Spark configuration.
#[root@ansibler]

    ansible-playbook \
        --inventory "hosts.yml" \
        "22-config-spark-master.yml"

	
PLAY RECAP **************************************************************************************************************************************************************************************************
gateway                    : ok=2    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
master01                   : ok=2    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


# -----------------------------------------------------
# Run the SparkPi example from the Spark install instructtions.
# https://spark.apache.org/docs/3.0.0-preview2/running-on-yarn.html#launching-spark-on-yarn
#[root@ansibler]

    ssh master01 \
        '
        cd "${SPARK_HOME:?}"

        spark-submit \
            --class org.apache.spark.examples.SparkPi \
            --master yarn \
            --deploy-mode cluster \
            --driver-memory 1g \
            --executor-memory 1g \
            --executor-cores 1 \
            examples/jars/spark-examples*.jar \
                10
        '
2020-11-02 15:27:21,500 INFO yarn.Client: Application report for application_1604330473093_0001 (state: ACCEPTED)
2020-11-02 15:27:22,502 INFO yarn.Client: Application report for application_1604330473093_0001 (state: ACCEPTED)
2020-11-02 15:27:23,505 INFO yarn.Client: Application report for application_1604330473093_0001 (state: ACCEPTED)
2020-11-02 15:27:24,507 INFO yarn.Client: Application report for application_1604330473093_0001 (state: ACCEPTED)
2020-11-02 15:27:25,510 INFO yarn.Client: Application report for application_1604330473093_0001 (state: ACCEPTED)
2020-11-02 15:27:26,511 INFO yarn.Client: Application report for application_1604330473093_0001 (state: RUNNING)
2020-11-02 15:27:26,512 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: worker03
	 ApplicationMaster RPC port: 38311
	 queue: default
	 start time: 1604330839226
	 final status: UNDEFINED
	 tracking URL: http://master01:8088/proxy/application_1604330473093_0001/
	 user: fedora
2020-11-02 15:27:27,513 INFO yarn.Client: Application report for application_1604330473093_0001 (state: RUNNING)
2020-11-02 15:27:28,515 INFO yarn.Client: Application report for application_1604330473093_0001 (state: RUNNING)
2020-11-02 15:27:29,516 INFO yarn.Client: Application report for application_1604330473093_0001 (state: RUNNING)
2020-11-02 15:27:30,518 INFO yarn.Client: Application report for application_1604330473093_0001 (state: RUNNING)
2020-11-02 15:27:31,520 INFO yarn.Client: Application report for application_1604330473093_0001 (state: RUNNING)
2020-11-02 15:27:32,522 INFO yarn.Client: Application report for application_1604330473093_0001 (state: RUNNING)
2020-11-02 15:27:33,525 INFO yarn.Client: Application report for application_1604330473093_0001 (state: FINISHED)
2020-11-02 15:27:33,525 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: worker03
	 ApplicationMaster RPC port: 38311
	 queue: default
	 start time: 1604330839226
	 final status: SUCCEEDED
	 tracking URL: http://master01:8088/proxy/application_1604330473093_0001/
	 user: fedora
2020-11-02 15:27:33,534 INFO util.ShutdownHookManager: Shutdown hook called
2020-11-02 15:27:33,535 INFO util.ShutdownHookManager: Deleting directory /opt/spark-2.4.7-bin-hadoop2.7/local/spark-dbe3c8cb-f4e2-487c-906c-835b8efb71ed
2020-11-02 15:27:33,546 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-f5045a01-9c93-4492-beac-60d102392f83





# -----------------------------------------------------
# Run the Zeppelin install.
#[root@ansibler]

    ansible-playbook \
        --inventory "hosts.yml" \
        "combined-04.yml"

# -----------------------------------------------------
# Start the YARN services.
#[root@ansibler]

    ssh zeppelin \
        '
        /home/fedora/zeppelin-0.8.2-bin-all/bin/zeppelin-daemon.sh start
        '
                                [  OK  ]


# -----------------------------------------------------
#  Get IP Address
#[root@ansibler]


    openstack \
        --os-cloud "${cloudname:?}" \
        floating ip list


# -----------------------------------------------------
# Try some Spark jobs via the Zeppelin GUI.
firefox http://128.232.227.125:8080/#/ &


%spark.pyspark
import random 
NUM_SAMPLES = 2000000000

def inside(p):
    x, y = random.random(), random.random()
    return x*x + y*y < 1

count = sc.parallelize(range(0, NUM_SAMPLES)) \
             .filter(inside).count()
print ("Pi is roughly %f" % (4.0 * count / NUM_SAMPLES))



> Pi is roughly 3.141593


# -----------------------------------------------------
# Fetch Gaia DR2 Parquet files
#[fedora@worker01]
# -----------------------------------------------------
# Run from a worker node

ssh worker01


	# Install wget
	sudo yum install -y wget


	cat << \EOF > "${HOME:?}/getGaiaParquet.sh" 
	#!/bin/bash
	content=$(wget https://cumulus.openstack.hpc.cam.ac.uk:6780/swift/v1/AUTH_21b4ae3a2ea44bc5a9c14005ed2963af/gaia-dr2-parquet/ -q -O -)
	set -- $content
	while [ $# -gt 0 ]
	do
		wget -q https://cumulus.openstack.hpc.cam.ac.uk:6780/swift/v1/AUTH_21b4ae3a2ea44bc5a9c14005ed2963af/gaia-dr2-parquet/$1 -P /data-01/gaia
		shift
	done
	EOF

	# Set Permissions
	chmod 755 getGaiaParquet.sh

	sudo mkdir /data-01/gaia
	sudo ${HOME:?}/getGaiaParquet.sh > out.log 2>&1 &

	# Put Files into HDFS
	hdfs dfs -mkdir /data
	hdfs dfs -put /data-01/gaia /data
	hdfs dfs -ls /data/gaia

exit




 -----------------------------------------------------
# Create notebook directory, connected to WFAU github notebook project
#[fedora@zeppelin]

# NOTE: As a one off we need to set the github user & pass for passwordless pushes to Github from Zeppelin

    ssh zeppelin \
        '
        export githubpass=password
        export githubuser=username

        rm -rf /home/fedora/zeppelin-0.8.2-bin-all/notebook
	git clone https://${githubuser:?}:${githubpass:?}@github.com/wfau/aglais-notebooks.git /home/fedora/zeppelin-0.8.2-bin-all/notebook

	cat > "${HOME}/zeppelin-0.8.2-bin-all/notebook/.git/hooks/post-commit" << EOF
	#!/bin/sh
	git push 
	EOF

	chmod +x ${HOME}/zeppelin-0.8.2-bin-all/notebook/.git/hooks/post-commit
	/home/fedora/zeppelin-0.8.2-bin-all/bin/zeppelin-daemon.sh restart
	'





 -----------------------------------------------------
# List the routers.
#[root@ansibler]

    openstack \
        --os-cloud "${cloudname:?}" \
        router list

+--------------------------------------+-----------------------------------------+--------+-------+----------------------------------+
| ID                                   | Name                                    | Status | State | Project                          |
+--------------------------------------+-----------------------------------------+--------+-------+----------------------------------+
| 247a2ac4-a58e-487b-bdee-58c004589825 | ceph-router                             | ACTIVE | UP    | bea28e83e6aa47a8962b59c3b24495fe |
| 48f99299-e13e-4bd5-b830-4384f5b030e2 | aglais-20201102-internal-network-router | ACTIVE | UP    | bea28e83e6aa47a8962b59c3b24495fe |
| f28d12e9-beb7-4b8b-94e7-794fe79c8981 | aglais-20201008-internal-network-router | ACTIVE | UP    | bea28e83e6aa47a8962b59c3b24495fe |
+--------------------------------------+-----------------------------------------+--------+-------+----------------------------------+


# -----------------------------------------------------
# List the networks.
#[root@ansibler]

    openstack \
        --os-cloud "${cloudname:?}" \
        network list

 +--------------------------------------+----------------------------------+----------------------------------------------------------------------------+
| ID                                   | Name                             | Subnets                                                                    |
+--------------------------------------+----------------------------------+----------------------------------------------------------------------------+
| 2827455c-e9a7-4849-9528-387d7ff59206 | private                          | 57d80485-06cc-4488-b392-0936d0b7627b                                       |
| 93e2e16b-c025-4a4a-8184-4d6cd5b2bedc | aglais-20201008-internal-network | b5d4eb06-bf13-4efe-bacd-20b315bc12df                                       |
| a929e8db-1bf4-4a5f-a80c-fabd39d06a26 | internet                         | 180dc961-c52f-461a-b241-8f7a30d022a5, 273123bb-70f6-4f51-a406-7fc4b446532d |
| cca83208-a805-4e93-96ed-e698fda10f16 | aglais-20201102-internal-network | 36cf51ce-01ad-40e6-9ef0-0a4117826a2a                                       |
| ecb791d5-1022-447a-a79c-8f38a0f5c990 | cumulus-internal                 | 01b76c7c-3c1a-4c5c-9a5a-14bcf6c0c290                                       |
+--------------------------------------+----------------------------------+----------------------------------------------------------------------------+



# -----------------------------------------------------
# Create a new Ceph router.


openstack \
         --os-cloud "${cloudname:?}" \
         router create \
             --format json \
             --enable \
             --project "${projectid:?}" \
             'ceph-router' \
     | tee '/tmp/ceph-router.json'

{
  "admin_state_up": true,
  "availability_zone_hints": [],
  "availability_zones": [],
  "created_at": "2020-11-03T15:08:45Z",
  "description": "",
  "external_gateway_info": null,
  "flavor_id": null,
  "id": "247a2ac4-a58e-487b-bdee-58c004589825",
  "location": {
    "cloud": "gaia-test",
    "region_name": "RegionOne",
    "zone": null,
    "project": {
      "id": "bea28e83e6aa47a8962b59c3b24495fe",
      "name": null,
      "domain_id": null,
      "domain_name": null
    }
  },
  "name": "ceph-router",
  "project_id": "bea28e83e6aa47a8962b59c3b24495fe",
  "revision_number": 2,
  "routes": [],
  "status": "ACTIVE",
  "tags": [],
  "updated_at": "2020-11-03T15:08:45Z"
}

newrouterid=$(
         jq -r '. | select(.name == "ceph-router") | .id' '/tmp/ceph-router.json'
         )


echo "Ceph router [${newrouterid:?}]"
Ceph router [247a2ac4-a58e-487b-bdee-58c004589825]


# -----------------------------------------------------
# Set the external gateway network.
#[root@ansibler]

    cumulusnetid=$(
        openstack \
            --os-cloud "${cloudname:?}" \
            network list \
                --format json \
        | jq -r '.[] | select(.Name == "cumulus-internal") | .ID'
        )

    openstack \
        --os-cloud "${cloudname:?}" \
        router set \
            --external-gateway "${cumulusnetid:?}" \
            "${newrouterid:?}"





# -----------------------------------------------------
# Create a network port for our cluster subnet.

# TODO: Remove hard coded version of date

clusternetid=$(
         openstack \
             --os-cloud "${cloudname:?}" \
             network list \
                 --format json \
         | jq -r '.[] | select(.Name | test("^aglais-20201102")) | .ID'
         )


clustersubid=$(
         openstack \
             --os-cloud "${cloudname:?}" \
             subnet list \
                 --format json \
         | jq -r '.[] | select(.Name | test("^aglais-20201102")) | .ID'
         )

openstack \
         --os-cloud "${cloudname:?}" \
         port create \
             --format json \
             --network "${clusternetid:?}" \
             --fixed-ip "subnet=${clustersubid:?}" \
         'aglais-subnet-port' \
     | tee '/tmp/aglais-subnet-port.json'

{
  "admin_state_up": true,
  "allowed_address_pairs": [],
  "binding_host_id": null,
  "binding_profile": null,
  "binding_vif_details": null,
  "binding_vif_type": null,
  "binding_vnic_type": "normal",
  "created_at": "2020-11-03T16:34:44Z",
  "data_plane_status": null,
  "description": "",
  "device_id": "",
  "device_owner": "",
  "dns_assignment": [
    {
      "hostname": "host-10-10-2-130",
      "ip_address": "10.10.2.130",
      "fqdn": "host-10-10-2-130.iris.cumulus.local."
    }
  ],
  "dns_domain": null,
  "dns_name": "",
  "extra_dhcp_opts": [],
  "fixed_ips": [
    {
      "subnet_id": "36cf51ce-01ad-40e6-9ef0-0a4117826a2a",
      "ip_address": "10.10.2.130"
    }
  ],
  "id": "896d790c-aba0-4cd5-965a-87bb7f1edd3f",
  "ip_allocation": null,
  "location": {
    "cloud": "gaia-test",
    "region_name": "RegionOne",
    "zone": null,
    "project": {
      "id": "bea28e83e6aa47a8962b59c3b24495fe",
      "name": null,
      "domain_id": null,
      "domain_name": null
    }
  },
  "mac_address": "fa:16:3e:03:c9:92",
  "name": "aglais-subnet-port",
  "network_id": "cca83208-a805-4e93-96ed-e698fda10f16",
  "port_security_enabled": false,
  "project_id": "bea28e83e6aa47a8962b59c3b24495fe",
  "propagate_uplink_status": null,
  "qos_network_policy_id": null,
  "qos_policy_id": null,
  "resource_request": null,
  "revision_number": 1,
  "security_group_ids": [
    "cf198a34-393f-4176-86e7-ca01fe46caa1"
  ],
  "status": "DOWN",
  "tags": [],
  "trunk_details": null,
  "updated_at": "2020-11-03T16:34:44Z"
}

	

# -----------------------------------------------------
# Add the network port to the Ceph router.
#[root@ansibler]

    newportid=$(
        jq -r '.id' /tmp/aglais-subnet-port.json
        )

    openstack \
        --os-cloud "${cloudname:?}" \
        router add port \
            "${newrouterid:?}" \
            "${newportid:?}"


# -----------------------------------------------------
# Add a route for the Ceph network to our original router.
#[root@ansibler]

    nexthop=$(
        jq -r '.fixed_ips[0].ip_address' '/tmp/aglais-subnet-port.json'
        )

    oldrouterid=$(
        openstack \
            --os-cloud "${cloudname:?}" \
            router list \
                --format json \
        | jq -r '.[] | select(.Name | test("^aglais-20201102")) | .ID'
        )

    openstack \
        --os-cloud "${cloudname:?}" \
        router set \
            --route "destination=10.206.0.0/16,gateway=${nexthop:?}" \
            "${oldrouterid:?}"



# -----------------------------------------------------
# Details of our original router.
#[root@ansibler]

    openstack \
        --os-cloud "${cloudname:?}" \
        router show \
            --format json \
            "${oldrouterid:?}"

{
  "admin_state_up": true,
  "availability_zone_hints": [],
  "availability_zones": [
    "nova"
  ],
  "created_at": "2020-11-02T14:36:19Z",
  "description": "",
  "external_gateway_info": {
    "network_id": "a929e8db-1bf4-4a5f-a80c-fabd39d06a26",
    "enable_snat": true,
    "external_fixed_ips": [
      {
        "subnet_id": "273123bb-70f6-4f51-a406-7fc4b446532d",
        "ip_address": "128.232.227.229"
      }
    ]
  },
  "flavor_id": null,
  "id": "48f99299-e13e-4bd5-b830-4384f5b030e2",
  "interfaces_info": [
    {
      "port_id": "0d53a1dc-4927-4499-9a1c-63f08032e598",
      "ip_address": "10.10.0.1",
      "subnet_id": "36cf51ce-01ad-40e6-9ef0-0a4117826a2a"
    }
  ],
  "location": {
    "cloud": "gaia-test",
    "region_name": "RegionOne",
    "zone": null,
    "project": {
      "id": "bea28e83e6aa47a8962b59c3b24495fe",
      "name": null,
      "domain_id": null,
      "domain_name": null
    }
  },
  "name": "aglais-20201102-internal-network-router",
  "project_id": "bea28e83e6aa47a8962b59c3b24495fe",
  "revision_number": 10,
  "routes": [
    {
      "nexthop": "10.10.2.130",
      "destination": "10.206.0.0/16"
    }
  ],
  "status": "ACTIVE",
  "tags": [],
  "updated_at": "2020-11-03T17:08:07Z"
}


# -----------------------------------------------------
# Details of our new ceph router.
#[root@ansibler]

    openstack \
        --os-cloud "${cloudname:?}" \
        router show \
            --format json \
            "${newrouterid:?}"


{
  "admin_state_up": true,
  "availability_zone_hints": [],
  "availability_zones": [
    "nova"
  ],
  "created_at": "2020-11-03T15:08:45Z",
  "description": "",
  "external_gateway_info": {
    "network_id": "ecb791d5-1022-447a-a79c-8f38a0f5c990",
    "enable_snat": true,
    "external_fixed_ips": [
      {
        "subnet_id": "01b76c7c-3c1a-4c5c-9a5a-14bcf6c0c290",
        "ip_address": "10.218.1.143"
      }
    ]
  },
  "flavor_id": null,
  "id": "247a2ac4-a58e-487b-bdee-58c004589825",
  "interfaces_info": [
    {
      "port_id": "896d790c-aba0-4cd5-965a-87bb7f1edd3f",
      "ip_address": "10.10.2.130",
      "subnet_id": "36cf51ce-01ad-40e6-9ef0-0a4117826a2a"
    }
  ],
  "location": {
    "cloud": "gaia-test",
    "region_name": "RegionOne",
    "zone": null,
    "project": {
      "id": "bea28e83e6aa47a8962b59c3b24495fe",
      "name": null,
      "domain_id": null,
      "domain_name": null
    }
  },
  "name": "ceph-router",
  "project_id": "bea28e83e6aa47a8962b59c3b24495fe",
  "revision_number": 9,
  "routes": [],
  "status": "ACTIVE",
  "tags": [],
  "updated_at": "2020-11-03T16:40:58Z"
}



# -----------------------------------------------------
# Set the Manila API version.
# https://stackoverflow.com/a/58806536
#[root@ansibler]

    export OS_SHARE_API_VERSION=2.51


# -----------------------------------------------------
# Get details of the Gaia DR2 share.
#[root@ansibler]

    sharename=gaia-dr2

    openstack \
        --os-cloud "${cloudname:?}" \
        share list


# Empty response..
