#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2019, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#  
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

## HDFS Disk space issue
## Nigel's noticed an issue when trying to running the following Spark job

%spark.pyspark
# Q: why am I having to prefix interpreter bindings with "spark." all of a sudden ?!

# define the data frame source on the given column selection only (we don't want to read the whole thing ... presumably?)
df = sqlContext.read.parquet("/hadoop/gaia/parquet/gdr2/gaia_source/*.parquet").select("source_id")

# register as an sql context queryable object
sqlContext.registerDataFrameAsTable(df, "gaia_source_ids")


## Looks like a disk space issue
## Exception message in Zeppelin cell: "No space left on device"




#------------------------------------
# Check hdfs report on Master node
#------------------------------------
 
ssh stv-dev-master

  hdfs dfsadmin -report

  # For each worker node, this shows
  # Shows 100% usage
  # Non DFS Used: ~ 190 Gb for each node
  # DFS Used: ~ to 300 Gb for each node

exit



#------------------------------------
# Check disk usage on Worker nodes
#------------------------------------


ssh stv-dev-worker-1

  df -h 
  # Shows 100% usage on /dev/vda1  

  sudo du -sh /home/fedora/hadoop/logs/  
  # > 150 Gb in Logs for each node

  # Same for the rest of the cluster workers

exit


#------------------------------------
# Clear log directory on each node
#------------------------------------

# For each worker node
rm -r /home/fedora/hadoop/logs/*



#------------------------------------
# Restart Hadoop on Master Node
#------------------------------------
 
ssh stv-dev-master

  stop-all.sh
  start-all.sh

exit


#------------------------------------
# Restart Zeppelin
#------------------------------------
ssh stv-dev-zeppelin

  /home/fedora/zeppelin/bin/zeppelin-daemon.sh stop
  /home/fedora/zeppelin/bin/zeppelin-daemon.sh start

exit


#------------------------------------
# Try running sample Spark notebooks
#------------------------------------

# Run Nigel's sample notebook (Sky counts map) using GUI works now

