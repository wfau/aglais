#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2015, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#  
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#


## 20191023-hdfs-yarn-cluster.txt


########################################################
## Setup Spark on Existing yarn & hdfs cluster
########################################################

## Download and Install Spark Binaries

## From Node Master (Cadelicia)


cd /home/Stevedore
wget https://d3kbcqa49mib13.cloudfront.net/spark-2.2.0-bin-hadoop2.7.tgz
tar -xvf spark-2.2.0-bin-hadoop2.7.tgz
mv spark-2.2.0-bin-hadoop2.7 spark


## Add Spark to Path

nano ~/.profile

	PATH=/home/Stevedore/hadoop/bin:/home/Stevedore/hadoop/sbin:/home/Stevedore/spark/bin:$PATH


nano ~/.bashrc

	export HADOOP_HOME=/home/Stevedore/hadoop
	export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.212.b04-0.fc28.x86_64/jre
	export HADOOP_CONF_DIR=/home/Stevedore/hadoop/etc/hadoop
	export SPARK_HOME=/home/Stevedore/spark
	export LD_LIBRARY_PATH=/home/Stevedore/hadoop/lib/native:$LD_LIBRARY_PAT
        export PATH=${PATH}:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin:${SPARK_HOME}/bin




mv $SPARK_HOME/conf/spark-defaults.conf.template $SPARK_HOME/conf/spark-defaults.conf


## Update Spark.Master parameters in config

nano $SPARK_HOME/conf/spark-defaults.conf

spark.master                     yarn
spark.driver.memory              512m
spark.yarn.am.memory		512m
spark.executor.memory          512m
spark.eventLog.enabled  true
spark.eventLog.dir hdfs://Cadelicia:9000/spark-log


## Create the log directory in HDFS:

hdfs dfs -mkdir /spark-logs

## Memory Allocation
## "For nodes with less than 4G RAM, the default configuration is not adequate and may trigger swapping and poor performance, or even the failure of application initialization due to lack of memory."



## Submit an Example Spark application

spark-submit --deploy-mode client                --class org.apache.spark.examples.SparkPi                $SPARK_HOME/examples/jars/spark-examples_2.11-2.2.0.jar 10

2019-10-23 17:55:38,348 INFO spark.SparkContext: Running Spark version 2.2.0
2019-10-23 17:55:39,108 INFO spark.SparkContext: Submitted application: Spark Pi
2019-10-23 17:55:39,139 INFO spark.SecurityManager: Changing view acls to: Stevedore
2019-10-23 17:55:39,139 INFO spark.SecurityManager: Changing modify acls to: Stevedore
2019-10-23 17:55:39,140 INFO spark.SecurityManager: Changing view acls groups to: 
2019-10-23 17:55:39,141 INFO spark.SecurityManager: Changing modify acls groups to: 
2019-10-23 17:55:39,142 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Stevedore); groups with view permissions: Set(); users  with modify permissions: Set(Stevedore); groups with modify permissions: Set()
2019-10-23 17:55:39,754 INFO util.Utils: Successfully started service 'sparkDriver' on port 37115.
2019-10-23 17:55:39,796 INFO spark.SparkEnv: Registering MapOutputTracker
2019-10-23 17:55:39,833 INFO spark.SparkEnv: Registering BlockManagerMaster
2019-10-23 17:55:39,837 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-10-23 17:55:39,838 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2019-10-23 17:55:39,852 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-aa74a112-136f-44bf-96a7-6fe7d00b8494
2019-10-23 17:55:39,886 INFO memory.MemoryStore: MemoryStore started with capacity 93.3 MB
2019-10-23 17:55:40,016 INFO spark.SparkEnv: Registering OutputCommitCoordinator
2019-10-23 17:55:40,118 INFO util.log: Logging initialized @2981ms
2019-10-23 17:55:40,202 INFO server.Server: jetty-9.3.z-SNAPSHOT
2019-10-23 17:55:40,230 INFO server.Server: Started @3095ms
2019-10-23 17:55:40,262 INFO server.AbstractConnector: Started ServerConnector@2b6ac666{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-10-23 17:55:40,262 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
2019-10-23 17:55:40,300 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7c18432b{/jobs,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,301 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@69adf72c{/jobs/json,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,301 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1a15b789{/jobs/job,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,302 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6c4f9535{/jobs/job/json,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,303 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@30c31dd7{/stages,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,304 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@596df867{/stages/json,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,304 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@241a53ef{/stages/stage,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,306 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@615f972{/stages/stage/json,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,306 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@73393584{/stages/pool,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,307 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1827a871{/stages/pool/json,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,308 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7249dadf{/storage,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,308 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@66238be2{/storage/json,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,309 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@200606de{/storage/rdd,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,310 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@f8908f6{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,311 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ef8a8c3{/environment,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,311 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@63fd4873{/environment/json,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,312 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7544a1e4{/executors,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,313 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7957dc72{/executors/json,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,314 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3aacf32a{/executors/threadDump,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,315 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@82c57b3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,325 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@600b0b7{/static,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,326 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@38875e7d{/,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,327 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@d816dde{/api,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,328 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3113a37{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,329 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4e9658b5{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-10-23 17:55:40,332 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.201.11:4040
2019-10-23 17:55:40,358 INFO spark.SparkContext: Added JAR file:/home/Stevedore/spark/examples/jars/spark-examples_2.11-2.2.0.jar at spark://192.168.201.11:37115/jars/spark-examples_2.11-2.2.0.jar with timestamp 1571849740357
2019-10-23 17:55:41,298 INFO client.RMProxy: Connecting to ResourceManager at Cadelicia/192.168.201.11:8032
2019-10-23 17:55:41,582 INFO yarn.Client: Requesting a new application from cluster with 2 NodeManagers
2019-10-23 17:55:41,661 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (1536 MB per container)
2019-10-23 17:55:41,662 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
2019-10-23 17:55:41,662 INFO yarn.Client: Setting up container launch context for our AM
2019-10-23 17:55:41,665 INFO yarn.Client: Setting up the launch environment for our AM container
2019-10-23 17:55:41,675 INFO yarn.Client: Preparing resources for our AM container
2019-10-23 17:55:43,316 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
2019-10-23 17:55:46,105 INFO yarn.Client: Uploading resource file:/tmp/spark-7a59ff1f-7f7c-45b4-bf22-7ad80975831e/__spark_libs__2942775799409865206.zip -> hdfs://Cadelicia:9000/user/Stevedore/.sparkStaging/application_1571833181041_0013/__spark_libs__2942775799409865206.zip
2019-10-23 17:55:47,503 INFO yarn.Client: Uploading resource file:/tmp/spark-7a59ff1f-7f7c-45b4-bf22-7ad80975831e/__spark_conf__1339660849856062914.zip -> hdfs://Cadelicia:9000/user/Stevedore/.sparkStaging/application_1571833181041_0013/__spark_conf__.zip
2019-10-23 17:55:47,599 INFO spark.SecurityManager: Changing view acls to: Stevedore
2019-10-23 17:55:47,600 INFO spark.SecurityManager: Changing modify acls to: Stevedore
2019-10-23 17:55:47,600 INFO spark.SecurityManager: Changing view acls groups to: 
2019-10-23 17:55:47,600 INFO spark.SecurityManager: Changing modify acls groups to: 
2019-10-23 17:55:47,600 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Stevedore); groups with view permissions: Set(); users  with modify permissions: Set(Stevedore); groups with modify permissions: Set()
2019-10-23 17:55:47,608 INFO yarn.Client: Submitting application application_1571833181041_0013 to ResourceManager
2019-10-23 17:55:47,665 INFO impl.YarnClientImpl: Submitted application application_1571833181041_0013
2019-10-23 17:55:47,670 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1571833181041_0013 and attemptId None
2019-10-23 17:55:48,683 INFO yarn.Client: Application report for application_1571833181041_0013 (state: ACCEPTED)
2019-10-23 17:55:48,691 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1571849747625
	 final status: UNDEFINED
	 tracking URL: http://Cadelicia:8088/proxy/application_1571833181041_0013/
	 user: Stevedore
2019-10-23 17:55:49,694 INFO yarn.Client: Application report for application_1571833181041_0013 (state: ACCEPTED)
2019-10-23 17:55:50,697 INFO yarn.Client: Application report for application_1571833181041_0013 (state: ACCEPTED)
2019-10-23 17:55:51,700 INFO yarn.Client: Application report for application_1571833181041_0013 (state: ACCEPTED)
2019-10-23 17:55:52,703 INFO yarn.Client: Application report for application_1571833181041_0013 (state: ACCEPTED)
2019-10-23 17:55:53,706 INFO yarn.Client: Application report for application_1571833181041_0013 (state: ACCEPTED)
2019-10-23 17:55:54,710 INFO yarn.Client: Application report for application_1571833181041_0013 (state: ACCEPTED)

...
..


2019-10-23 17:59:23,269 INFO yarn.Client: Application report for application_1571833181041_0013 (state: FAILED)
2019-10-23 17:59:23,270 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: Application application_1571833181041_0013 failed 2 times due to AM Container for appattempt_1571833181041_0013_000002 exited with  exitCode: 10
Failing this attempt.Diagnostics: [2019-10-23 17:59:22.837]Exception from container-launch.
Container id: container_1571833181041_0013_02_000001
Exit code: 10

[2019-10-23 17:59:22.908]Container exited with a non-zero exit code 10. Error file: prelaunch.err.
Last 4096 bytes of prelaunch.err :
Last 4096 bytes of stderr :
licationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:06,205 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:06,306 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:07,421 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:08,573 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:09,725 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:10,876 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:12,028 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:13,180 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:13,282 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:14,397 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:15,548 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:16,701 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:17,853 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:19,005 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:20,157 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:21,309 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:21,410 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:22,525 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:22,627 ERROR yarn.ApplicationMaster: Uncaught exception: 
org.apache.spark.SparkException: Failed to connect to driver!
	at org.apache.spark.deploy.yarn.ApplicationMaster.waitForSparkDriver(ApplicationMaster.scala:577)
	at org.apache.spark.deploy.yarn.ApplicationMaster.runExecutorLauncher(ApplicationMaster.scala:433)
	at org.apache.spark.deploy.yarn.ApplicationMaster.run(ApplicationMaster.scala:256)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anonfun$main$1.apply$mcV$sp(ApplicationMaster.scala:764)
	at org.apache.spark.deploy.SparkHadoopUtil$$anon$2.run(SparkHadoopUtil.scala:67)
	at org.apache.spark.deploy.SparkHadoopUtil$$anon$2.run(SparkHadoopUtil.scala:66)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.spark.deploy.SparkHadoopUtil.runAsSparkUser(SparkHadoopUtil.scala:66)
	at org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:762)
	at org.apache.spark.deploy.yarn.ExecutorLauncher$.main(ApplicationMaster.scala:785)
	at org.apache.spark.deploy.yarn.ExecutorLauncher.main(ApplicationMaster.scala)
2019-10-23 17:59:22,637 INFO yarn.ApplicationMaster: Final app status: FAILED, exitCode: 10, (reason: Uncaught exception: org.apache.spark.SparkException: Failed to connect to driver!)
2019-10-23 17:59:22,648 INFO yarn.ApplicationMaster: Unregistering ApplicationMaster with FAILED (diag message: Uncaught exception: org.apache.spark.SparkException: Failed to connect to driver!)
2019-10-23 17:59:22,650 INFO yarn.ApplicationMaster: Deleting staging directory hdfs://Cadelicia:9000/user/Stevedore/.sparkStaging/application_1571833181041_0013
2019-10-23 17:59:22,674 INFO util.ShutdownHookManager: Shutdown hook called


[2019-10-23 17:59:22.908]Container exited with a non-zero exit code 10. Error file: prelaunch.err.
Last 4096 bytes of prelaunch.err :
Last 4096 bytes of stderr :
licationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:06,205 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:06,306 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:07,421 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:08,573 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:09,725 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:10,876 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:12,028 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:13,180 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:13,282 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:14,397 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:15,548 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:16,701 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:17,853 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:19,005 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:20,157 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:21,309 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:21,410 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:22,525 ERROR yarn.ApplicationMaster: Failed to connect to driver at 192.168.201.11:37115, retrying ...
2019-10-23 17:59:22,627 ERROR yarn.ApplicationMaster: Uncaught exception: 
org.apache.spark.SparkException: Failed to connect to driver!
	at org.apache.spark.deploy.yarn.ApplicationMaster.waitForSparkDriver(ApplicationMaster.scala:577)
	at org.apache.spark.deploy.yarn.ApplicationMaster.runExecutorLauncher(ApplicationMaster.scala:433)
	at org.apache.spark.deploy.yarn.ApplicationMaster.run(ApplicationMaster.scala:256)
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anonfun$main$1.apply$mcV$sp(ApplicationMaster.scala:764)
	at org.apache.spark.deploy.SparkHadoopUtil$$anon$2.run(SparkHadoopUtil.scala:67)
	at org.apache.spark.deploy.SparkHadoopUtil$$anon$2.run(SparkHadoopUtil.scala:66)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	at org.apache.spark.deploy.SparkHadoopUtil.runAsSparkUser(SparkHadoopUtil.scala:66)
	at org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:762)
	at org.apache.spark.deploy.yarn.ExecutorLauncher$.main(ApplicationMaster.scala:785)
	at org.apache.spark.deploy.yarn.ExecutorLauncher.main(ApplicationMaster.scala)
2019-10-23 17:59:22,637 INFO yarn.ApplicationMaster: Final app status: FAILED, exitCode: 10, (reason: Uncaught exception: org.apache.spark.SparkException: Failed to connect to driver!)
2019-10-23 17:59:22,648 INFO yarn.ApplicationMaster: Unregistering ApplicationMaster with FAILED (diag message: Uncaught exception: org.apache.spark.SparkException: Failed to connect to driver!)
2019-10-23 17:59:22,650 INFO yarn.ApplicationMaster: Deleting staging directory hdfs://Cadelicia:9000/user/Stevedore/.sparkStaging/application_1571833181041_0013
2019-10-23 17:59:22,674 INFO util.ShutdownHookManager: Shutdown hook called


For more detailed output, check the application tracking page: http://Cadelicia:8088/cluster/app/application_1571833181041_0013 Then click on links to logs of each attempt.
. Failing the application.
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1571849747625
	 final status: FAILED
	 tracking URL: http://Cadelicia:8088/cluster/app/application_1571833181041_0013
	 user: Stevedore
2019-10-23 17:59:23,289 ERROR spark.SparkContext: Error initializing SparkContext.
org.apache.spark.SparkException: Yarn application has already ended! It might have been killed or unable to launch application master.
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.waitForApplication(YarnClientSchedulerBackend.scala:85)
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:62)
	at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:173)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:509)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2509)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:909)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:901)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
	at org.apache.spark.examples.SparkPi$.main(SparkPi.scala:31)
	at org.apache.spark.examples.SparkPi.main(SparkPi.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2019-10-23 17:59:23,307 INFO server.AbstractConnector: Stopped Spark@2b6ac666{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-10-23 17:59:23,311 INFO ui.SparkUI: Stopped Spark web UI at http://192.168.201.11:4040
2019-10-23 17:59:23,326 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to request executors before the AM has registered!
2019-10-23 17:59:23,333 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors
2019-10-23 17:59:23,339 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
2019-10-23 17:59:23,345 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices
(serviceOption=None,
 services=List(),
 started=false)
2019-10-23 17:59:23,347 INFO cluster.YarnClientSchedulerBackend: Stopped
2019-10-23 17:59:23,359 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2019-10-23 17:59:23,381 INFO memory.MemoryStore: MemoryStore cleared
2019-10-23 17:59:23,383 INFO storage.BlockManager: BlockManager stopped
2019-10-23 17:59:23,401 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
2019-10-23 17:59:23,402 WARN metrics.MetricsSystem: Stopping a MetricsSystem that is not running
2019-10-23 17:59:23,409 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2019-10-23 17:59:23,412 INFO spark.SparkContext: Successfully stopped SparkContext
Exception in thread "main" org.apache.spark.SparkException: Yarn application has already ended! It might have been killed or unable to launch application master.
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.waitForApplication(YarnClientSchedulerBackend.scala:85)
	at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:62)
	at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:173)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:509)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2509)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:909)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:901)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:901)
	at org.apache.spark.examples.SparkPi$.main(SparkPi.scala:31)
	at org.apache.spark.examples.SparkPi.main(SparkPi.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:755)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2019-10-23 17:59:23,424 INFO util.ShutdownHookManager: Shutdown hook called
2019-10-23 17:59:23,427 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-7a59ff1f-7f7c-45b4-bf22-7ad80975831e






## Run the History server

$SPARK_HOME/sbin/start-history-server.sh



## Check Spark UI

ssh -L '*:8085:Cadelicia:4040' Stevedore@Cadelicia

## curl http://localhost:8085


## Looks like this is a firewall issue on the manager node
systemctl stop firewalld

## Try sample job again

2019-10-23 18:19:01,111 INFO spark.SparkContext: Running Spark version 2.2.0
2019-10-23 18:19:01,730 INFO spark.SparkContext: Submitted application: Spark Pi
2019-10-23 18:19:01,760 INFO spark.SecurityManager: Changing view acls to: Stevedore
2019-10-23 18:19:01,761 INFO spark.SecurityManager: Changing modify acls to: Stevedore
2019-10-23 18:19:01,762 INFO spark.SecurityManager: Changing view acls groups to: 
2019-10-23 18:19:01,762 INFO spark.SecurityManager: Changing modify acls groups to: 
2019-10-23 18:19:01,763 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Stevedore); groups with view permissions: Set(); users  with modify permissions: Set(Stevedore); groups with modify permissions: Set()
2019-10-23 18:19:02,294 INFO util.Utils: Successfully started service 'sparkDriver' on port 43061.
2019-10-23 18:19:02,326 INFO spark.SparkEnv: Registering MapOutputTracker
2019-10-23 18:19:02,355 INFO spark.SparkEnv: Registering BlockManagerMaster
2019-10-23 18:19:02,359 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-10-23 18:19:02,360 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2019-10-23 18:19:02,371 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-98ab562c-5c67-4165-9bf1-4751cbf5b686
2019-10-23 18:19:02,402 INFO memory.MemoryStore: MemoryStore started with capacity 93.3 MB
2019-10-23 18:19:02,533 INFO spark.SparkEnv: Registering OutputCommitCoordinator
2019-10-23 18:19:02,635 INFO util.log: Logging initialized @2541ms
2019-10-23 18:19:02,718 INFO server.Server: jetty-9.3.z-SNAPSHOT
2019-10-23 18:19:02,742 INFO server.Server: Started @2649ms
2019-10-23 18:19:02,773 INFO server.AbstractConnector: Started ServerConnector@541d6055{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-10-23 18:19:02,774 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
2019-10-23 18:19:02,811 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7c18432b{/jobs,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,812 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@69adf72c{/jobs/json,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,812 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1a15b789{/jobs/job,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,813 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6c4f9535{/jobs/job/json,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,814 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@30c31dd7{/stages,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,815 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@596df867{/stages/json,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,815 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@241a53ef{/stages/stage,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,817 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@615f972{/stages/stage/json,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,817 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@73393584{/stages/pool,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,818 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1827a871{/stages/pool/json,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,819 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7249dadf{/storage,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,819 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@66238be2{/storage/json,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,820 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@200606de{/storage/rdd,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,821 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@f8908f6{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,822 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2ef8a8c3{/environment,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,822 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@63fd4873{/environment/json,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,823 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7544a1e4{/executors,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,824 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7957dc72{/executors/json,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,825 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3aacf32a{/executors/threadDump,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,825 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@82c57b3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,835 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@600b0b7{/static,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,836 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@38875e7d{/,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,838 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@d816dde{/api,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,839 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3113a37{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,839 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4e9658b5{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-10-23 18:19:02,842 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.201.11:4040
2019-10-23 18:19:02,869 INFO spark.SparkContext: Added JAR file:/home/Stevedore/spark/examples/jars/spark-examples_2.11-2.2.0.jar at spark://192.168.201.11:43061/jars/spark-examples_2.11-2.2.0.jar with timestamp 1571851142868
2019-10-23 18:19:03,875 INFO client.RMProxy: Connecting to ResourceManager at Cadelicia/192.168.201.11:8032
2019-10-23 18:19:04,130 INFO yarn.Client: Requesting a new application from cluster with 2 NodeManagers
2019-10-23 18:19:04,179 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (1536 MB per container)
2019-10-23 18:19:04,180 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
2019-10-23 18:19:04,180 INFO yarn.Client: Setting up container launch context for our AM
2019-10-23 18:19:04,183 INFO yarn.Client: Setting up the launch environment for our AM container
2019-10-23 18:19:04,191 INFO yarn.Client: Preparing resources for our AM container
2019-10-23 18:19:05,415 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
2019-10-23 18:19:07,713 INFO yarn.Client: Uploading resource file:/tmp/spark-ad34df7e-4e04-4385-aa74-1cd8ba865984/__spark_libs__4572068023907509584.zip -> hdfs://Cadelicia:9000/user/Stevedore/.sparkStaging/application_1571833181041_0015/__spark_libs__4572068023907509584.zip
2019-10-23 18:19:09,530 INFO yarn.Client: Uploading resource file:/tmp/spark-ad34df7e-4e04-4385-aa74-1cd8ba865984/__spark_conf__2546497470392040435.zip -> hdfs://Cadelicia:9000/user/Stevedore/.sparkStaging/application_1571833181041_0015/__spark_conf__.zip
2019-10-23 18:19:09,638 INFO spark.SecurityManager: Changing view acls to: Stevedore
2019-10-23 18:19:09,638 INFO spark.SecurityManager: Changing modify acls to: Stevedore
2019-10-23 18:19:09,638 INFO spark.SecurityManager: Changing view acls groups to: 
2019-10-23 18:19:09,638 INFO spark.SecurityManager: Changing modify acls groups to: 
2019-10-23 18:19:09,638 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Stevedore); groups with view permissions: Set(); users  with modify permissions: Set(Stevedore); groups with modify permissions: Set()
2019-10-23 18:19:09,654 INFO yarn.Client: Submitting application application_1571833181041_0015 to ResourceManager
2019-10-23 18:19:09,713 INFO impl.YarnClientImpl: Submitted application application_1571833181041_0015
2019-10-23 18:19:09,719 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1571833181041_0015 and attemptId None
2019-10-23 18:19:10,731 INFO yarn.Client: Application report for application_1571833181041_0015 (state: ACCEPTED)
2019-10-23 18:19:10,739 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1571851149679
	 final status: UNDEFINED
	 tracking URL: http://Cadelicia:8088/proxy/application_1571833181041_0015/
	 user: Stevedore
2019-10-23 18:19:11,744 INFO yarn.Client: Application report for application_1571833181041_0015 (state: ACCEPTED)
2019-10-23 18:19:12,748 INFO yarn.Client: Application report for application_1571833181041_0015 (state: ACCEPTED)
2019-10-23 18:19:13,750 INFO yarn.Client: Application report for application_1571833181041_0015 (state: ACCEPTED)
2019-10-23 18:19:14,754 INFO yarn.Client: Application report for application_1571833181041_0015 (state: ACCEPTED)
2019-10-23 18:19:15,757 INFO yarn.Client: Application report for application_1571833181041_0015 (state: ACCEPTED)
2019-10-23 18:19:16,759 INFO yarn.Client: Application report for application_1571833181041_0015 (state: ACCEPTED)
2019-10-23 18:19:17,012 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
2019-10-23 18:19:17,030 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> Cadelicia, PROXY_URI_BASES -> http://Cadelicia:8088/proxy/application_1571833181041_0015), /proxy/application_1571833181041_0015
2019-10-23 18:19:17,033 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2019-10-23 18:19:17,762 INFO yarn.Client: Application report for application_1571833181041_0015 (state: RUNNING)
2019-10-23 18:19:17,763 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 192.168.201.12
	 ApplicationMaster RPC port: 0
	 queue: default
	 start time: 1571851149679
	 final status: UNDEFINED
	 tracking URL: http://Cadelicia:8088/proxy/application_1571833181041_0015/
	 user: Stevedore
2019-10-23 18:19:17,768 INFO cluster.YarnClientSchedulerBackend: Application application_1571833181041_0015 has started running.
2019-10-23 18:19:17,785 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36309.
2019-10-23 18:19:17,787 INFO netty.NettyBlockTransferService: Server created on 192.168.201.11:36309
2019-10-23 18:19:17,790 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-10-23 18:19:17,795 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.201.11, 36309, None)
2019-10-23 18:19:17,802 INFO storage.BlockManagerMasterEndpoint: Registering block manager 192.168.201.11:36309 with 93.3 MB RAM, BlockManagerId(driver, 192.168.201.11, 36309, None)
2019-10-23 18:19:17,810 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.201.11, 36309, None)
2019-10-23 18:19:17,811 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.201.11, 36309, None)
2019-10-23 18:19:18,055 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f930e0{/metrics/json,null,AVAILABLE,@Spark}
2019-10-23 18:19:24,866 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.201.9:39604) with ID 1
2019-10-23 18:19:24,972 INFO storage.BlockManagerMasterEndpoint: Registering block manager Abecien:33287 with 93.3 MB RAM, BlockManagerId(1, Abecien, 33287, None)
2019-10-23 18:19:33,037 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)
2019-10-23 18:19:33,307 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/Stevedore/spark/bin/spark-warehouse').
2019-10-23 18:19:33,308 INFO internal.SharedState: Warehouse path is 'file:/home/Stevedore/spark/bin/spark-warehouse'.
2019-10-23 18:19:33,315 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4c38cd16{/SQL,null,AVAILABLE,@Spark}
2019-10-23 18:19:33,315 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@f5bf288{/SQL/json,null,AVAILABLE,@Spark}
2019-10-23 18:19:33,316 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@28fc1132{/SQL/execution,null,AVAILABLE,@Spark}
2019-10-23 18:19:33,317 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@20440c6c{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-10-23 18:19:33,318 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@233f52f8{/static/sql,null,AVAILABLE,@Spark}
2019-10-23 18:19:33,843 INFO state.StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
2019-10-23 18:19:34,165 INFO spark.SparkContext: Starting job: reduce at SparkPi.scala:38
2019-10-23 18:19:34,192 INFO scheduler.DAGScheduler: Got job 0 (reduce at SparkPi.scala:38) with 10 output partitions
2019-10-23 18:19:34,193 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (reduce at SparkPi.scala:38)
2019-10-23 18:19:34,194 INFO scheduler.DAGScheduler: Parents of final stage: List()
2019-10-23 18:19:34,197 INFO scheduler.DAGScheduler: Missing parents: List()
2019-10-23 18:19:34,208 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at map at SparkPi.scala:34), which has no missing parents
2019-10-23 18:19:34,461 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 1832.0 B, free 93.3 MB)
2019-10-23 18:19:34,514 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 1172.0 B, free 93.3 MB)
2019-10-23 18:19:34,518 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.201.11:36309 (size: 1172.0 B, free: 93.3 MB)
2019-10-23 18:19:34,523 INFO spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
2019-10-23 18:19:34,548 INFO scheduler.DAGScheduler: Submitting 10 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at map at SparkPi.scala:34) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2019-10-23 18:19:34,549 INFO cluster.YarnScheduler: Adding task set 0.0 with 10 tasks
2019-10-23 18:19:34,610 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, Abecien, executor 1, partition 0, PROCESS_LOCAL, 4836 bytes)
2019-10-23 18:19:35,101 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on Abecien:33287 (size: 1172.0 B, free: 93.3 MB)
2019-10-23 18:19:35,412 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, Abecien, executor 1, partition 1, PROCESS_LOCAL, 4836 bytes)
2019-10-23 18:19:35,439 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 857 ms on Abecien (executor 1) (1/10)
2019-10-23 18:19:35,457 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, Abecien, executor 1, partition 2, PROCESS_LOCAL, 4836 bytes)
2019-10-23 18:19:35,459 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 49 ms on Abecien (executor 1) (2/10)
2019-10-23 18:19:35,638 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, Abecien, executor 1, partition 3, PROCESS_LOCAL, 4836 bytes)
2019-10-23 18:19:35,641 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 185 ms on Abecien (executor 1) (3/10)
2019-10-23 18:19:35,664 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, Abecien, executor 1, partition 4, PROCESS_LOCAL, 4836 bytes)
2019-10-23 18:19:35,667 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 30 ms on Abecien (executor 1) (4/10)
2019-10-23 18:19:35,689 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, Abecien, executor 1, partition 5, PROCESS_LOCAL, 4836 bytes)
2019-10-23 18:19:35,690 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 27 ms on Abecien (executor 1) (5/10)
2019-10-23 18:19:35,715 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, Abecien, executor 1, partition 6, PROCESS_LOCAL, 4836 bytes)
2019-10-23 18:19:35,716 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 27 ms on Abecien (executor 1) (6/10)
2019-10-23 18:19:35,737 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, Abecien, executor 1, partition 7, PROCESS_LOCAL, 4836 bytes)
2019-10-23 18:19:35,740 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 25 ms on Abecien (executor 1) (7/10)
2019-10-23 18:19:35,760 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8, Abecien, executor 1, partition 8, PROCESS_LOCAL, 4836 bytes)
2019-10-23 18:19:35,761 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 25 ms on Abecien (executor 1) (8/10)
2019-10-23 18:19:35,784 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9, Abecien, executor 1, partition 9, PROCESS_LOCAL, 4836 bytes)
2019-10-23 18:19:35,785 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 25 ms on Abecien (executor 1) (9/10)
2019-10-23 18:19:35,816 INFO scheduler.TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 32 ms on Abecien (executor 1) (10/10)
2019-10-23 18:19:35,820 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-10-23 18:19:35,821 INFO scheduler.DAGScheduler: ResultStage 0 (reduce at SparkPi.scala:38) finished in 1.246 s
2019-10-23 18:19:35,831 INFO scheduler.DAGScheduler: Job 0 finished: reduce at SparkPi.scala:38, took 1.665406 s
Pi is roughly 3.141723141723142
2019-10-23 18:19:35,850 INFO server.AbstractConnector: Stopped Spark@541d6055{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-10-23 18:19:35,855 INFO ui.SparkUI: Stopped Spark web UI at http://192.168.201.11:4040
2019-10-23 18:19:35,866 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread
2019-10-23 18:19:35,899 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors
2019-10-23 18:19:35,900 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
2019-10-23 18:19:35,913 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices
(serviceOption=None,
 services=List(),
 started=false)
2019-10-23 18:19:35,916 INFO cluster.YarnClientSchedulerBackend: Stopped
2019-10-23 18:19:35,929 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2019-10-23 18:19:35,954 INFO memory.MemoryStore: MemoryStore cleared
2019-10-23 18:19:35,955 INFO storage.BlockManager: BlockManager stopped
2019-10-23 18:19:35,968 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
2019-10-23 18:19:35,974 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2019-10-23 18:19:35,980 INFO spark.SparkContext: Successfully stopped SparkContext
2019-10-23 18:19:35,986 INFO util.ShutdownHookManager: Shutdown hook called
2019-10-23 18:19:35,988 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-ad34df7e-4e04-4385-aa74-1cd8ba865984
Connection to cadelicia closed.


## Job successfully completed



## Try running a filter using Spark-shell


spark-shell
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
2019-10-23 18:27:47,098 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
2019-10-23 18:28:20,773 WARN metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
2019-10-23 18:28:21,002 WARN metastore.ObjectStore: Failed to get database default, returning NoSuchObjectException
2019-10-23 18:28:22,303 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
Spark context Web UI available at http://192.168.201.11:4040
Spark context available as 'sc' (master = yarn, app id = application_1571833181041_0018).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.2.0
      /_/
         
Using Scala version 2.11.8 (OpenJDK 64-Bit Server VM, Java 1.8.0_212)
Type in expressions to have them evaluated.
Type :help for more information.

scala> var input = spark.read.textFile("inputs/alice.txt")
input: org.apache.spark.sql.Dataset[String] = [value: string]

scala> input.filter(line => line.length()>0).count()
res1: Long = 2791

scala> 

