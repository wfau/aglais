#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2019, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#  
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#


## ----------------------------------------------- Setting Up and Running Spark on an OpenStack cluster -----------------------------------------------


########################################################
## First, Setup Hadoop on an Openstack cluster
########################################################

## 20191030-openstack-hdfs-yarn-cluster.txt



########################################################
## Setup Spark on Existing yarn & hdfs cluster
########################################################

## Download and Install Spark Binaries

## From Node Master (Cadelicia)


cd /home/fedora
wget https://d3kbcqa49mib13.cloudfront.net/spark-2.2.0-bin-hadoop2.7.tgz
tar -xvf spark-2.2.0-bin-hadoop2.7.tgz
mv spark-2.2.0-bin-hadoop2.7 spark


########################################################
## Update .profile and Spark
########################################################
cat > "${HOME:?}/.profile" << EOF
PATH=/home/fedora/spark/bin:$PATH
EOF



cat <<EOF >> "${HOME:?}/.bashrc"

export HADOOP_CONF_DIR=/home/fedora/hadoop/etc/hadoop
export SPARK_HOME=/home/fedora/spark
export LD_LIBRARY_PATH=/home/fedora/hadoop/lib/native:$LD_LIBRARY_PATH


EOF


source .profile
source .bashrc

########################################################
## Setup Spark Configuration
########################################################

mv $SPARK_HOME/conf/spark-defaults.conf.template $SPARK_HOME/conf/spark-defaults.conf


## Update Spark.Master parameters in config

cat <<EOF >> "$SPARK_HOME/conf/spark-defaults.conf"

spark.master                     yarn
spark.driver.memory              512m
spark.yarn.am.memory		512m
spark.executor.memory          512m
spark.eventLog.enabled  true
spark.eventLog.dir hdfs://master:9000/spark-log

EOF



## Create the log directory in HDFS:

hdfs dfs -mkdir /spark-log


## Memory Allocation
## "For nodes with less than 4G RAM, the default configuration is not adequate and may trigger swapping and poor performance, or even the failure of application initialization due to lack of memory."


########################################################
## Submit an Example Spark application
########################################################

spark-submit --deploy-mode client                --class org.apache.spark.examples.SparkPi                $SPARK_HOME/examples/jars/spark-examples_2.11-2.2.0.jar 10
2019-11-01 22:10:17,165 INFO spark.SparkContext: Running Spark version 2.2.0
2019-11-01 22:10:17,493 INFO spark.SparkContext: Submitted application: Spark Pi
2019-11-01 22:10:17,507 INFO spark.SecurityManager: Changing view acls to: fedora
2019-11-01 22:10:17,507 INFO spark.SecurityManager: Changing modify acls to: fedora
2019-11-01 22:10:17,507 INFO spark.SecurityManager: Changing view acls groups to: 
2019-11-01 22:10:17,508 INFO spark.SecurityManager: Changing modify acls groups to: 
2019-11-01 22:10:17,508 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fedora); groups with view permissions: Set(); users  with modify permissions: Set(fedora); groups with modify permissions: Set()
2019-11-01 22:10:17,713 INFO util.Utils: Successfully started service 'sparkDriver' on port 40003.
2019-11-01 22:10:17,728 INFO spark.SparkEnv: Registering MapOutputTracker
2019-11-01 22:10:17,739 INFO spark.SparkEnv: Registering BlockManagerMaster
2019-11-01 22:10:17,741 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-01 22:10:17,741 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2019-11-01 22:10:17,747 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-f7383441-0bea-471c-9592-f7429de45a34
2019-11-01 22:10:17,760 INFO memory.MemoryStore: MemoryStore started with capacity 93.3 MB
2019-11-01 22:10:17,831 INFO spark.SparkEnv: Registering OutputCommitCoordinator
2019-11-01 22:10:17,878 INFO util.log: Logging initialized @1220ms
2019-11-01 22:10:17,916 INFO server.Server: jetty-9.3.z-SNAPSHOT
2019-11-01 22:10:17,934 INFO server.Server: Started @1276ms
2019-11-01 22:10:17,945 INFO server.AbstractConnector: Started ServerConnector@5a4bef8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-01 22:10:17,946 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
2019-11-01 22:10:17,963 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@200606de{/jobs,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,963 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@402f80f5{/jobs/json,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,963 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@133e019b{/jobs/job,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,964 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@425357dd{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,965 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@210386e0{/stages,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,965 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65f87a2c{/stages/json,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,965 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6ce1f601{/stages/stage,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,966 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6e33c391{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,966 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@31c269fd{/stages/pool,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,967 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@47747fb9{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,967 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@213e3629{/storage,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,967 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2a7b6f69{/storage/json,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,968 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@70eecdc2{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,968 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7db0565c{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,969 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@52eacb4b{/environment,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,969 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2a551a63{/environment/json,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,969 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1edb61b1{/executors,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,970 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@cc62a3b{/executors/json,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,970 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@29539e36{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,970 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@f5c79a6{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,974 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5305c37d{/static,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,975 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@72bca894{/,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,976 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1fc793c2{/api,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,976 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4593ff34{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,976 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@30c0ccff{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-01 22:10:17,977 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.218.1.49:4040
2019-11-01 22:10:17,991 INFO spark.SparkContext: Added JAR file:/home/fedora/spark/examples/jars/spark-examples_2.11-2.2.0.jar at spark://10.218.1.49:40003/jars/spark-examples_2.11-2.2.0.jar with timestamp 1572646217991
2019-11-01 22:10:18,559 INFO client.RMProxy: Connecting to ResourceManager at master/10.218.1.49:8032
2019-11-01 22:10:18,680 INFO yarn.Client: Requesting a new application from cluster with 3 NodeManagers
2019-11-01 22:10:18,707 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (1536 MB per container)
2019-11-01 22:10:18,708 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
2019-11-01 22:10:18,708 INFO yarn.Client: Setting up container launch context for our AM
2019-11-01 22:10:18,709 INFO yarn.Client: Setting up the launch environment for our AM container
2019-11-01 22:10:18,714 INFO yarn.Client: Preparing resources for our AM container
2019-11-01 22:10:19,411 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
2019-11-01 22:10:21,358 INFO yarn.Client: Uploading resource file:/tmp/spark-f3becd3d-6cbd-476d-923a-0b653b84ec55/__spark_libs__6319865929165727963.zip -> hdfs://master:9000/user/fedora/.sparkStaging/application_1572643463891_0005/__spark_libs__6319865929165727963.zip
2019-11-01 22:10:22,303 INFO yarn.Client: Uploading resource file:/tmp/spark-f3becd3d-6cbd-476d-923a-0b653b84ec55/__spark_conf__5122674392593622717.zip -> hdfs://master:9000/user/fedora/.sparkStaging/application_1572643463891_0005/__spark_conf__.zip
2019-11-01 22:10:22,356 INFO spark.SecurityManager: Changing view acls to: fedora
2019-11-01 22:10:22,357 INFO spark.SecurityManager: Changing modify acls to: fedora
2019-11-01 22:10:22,357 INFO spark.SecurityManager: Changing view acls groups to: 
2019-11-01 22:10:22,357 INFO spark.SecurityManager: Changing modify acls groups to: 
2019-11-01 22:10:22,357 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fedora); groups with view permissions: Set(); users  with modify permissions: Set(fedora); groups with modify permissions: Set()
2019-11-01 22:10:22,360 INFO yarn.Client: Submitting application application_1572643463891_0005 to ResourceManager
2019-11-01 22:10:22,379 INFO impl.YarnClientImpl: Submitted application application_1572643463891_0005
2019-11-01 22:10:22,380 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1572643463891_0005 and attemptId None
2019-11-01 22:10:23,385 INFO yarn.Client: Application report for application_1572643463891_0005 (state: ACCEPTED)
2019-11-01 22:10:23,387 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1572646222368
	 final status: UNDEFINED
	 tracking URL: http://master:8088/proxy/application_1572643463891_0005/
	 user: fedora
2019-11-01 22:10:24,389 INFO yarn.Client: Application report for application_1572643463891_0005 (state: ACCEPTED)
2019-11-01 22:10:25,390 INFO yarn.Client: Application report for application_1572643463891_0005 (state: ACCEPTED)
2019-11-01 22:10:25,784 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
2019-11-01 22:10:25,789 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> master, PROXY_URI_BASES -> http://master:8088/proxy/application_1572643463891_0005), /proxy/application_1572643463891_0005
2019-11-01 22:10:25,790 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
2019-11-01 22:10:26,391 INFO yarn.Client: Application report for application_1572643463891_0005 (state: RUNNING)
2019-11-01 22:10:26,392 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 10.218.1.17
	 ApplicationMaster RPC port: 0
	 queue: default
	 start time: 1572646222368
	 final status: UNDEFINED
	 tracking URL: http://master:8088/proxy/application_1572643463891_0005/
	 user: fedora
2019-11-01 22:10:26,392 INFO cluster.YarnClientSchedulerBackend: Application application_1572643463891_0005 has started running.
2019-11-01 22:10:26,397 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35035.
2019-11-01 22:10:26,398 INFO netty.NettyBlockTransferService: Server created on 10.218.1.49:35035
2019-11-01 22:10:26,399 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-01 22:10:26,400 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.218.1.49, 35035, None)
2019-11-01 22:10:26,402 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.218.1.49:35035 with 93.3 MB RAM, BlockManagerId(driver, 10.218.1.49, 35035, None)
2019-11-01 22:10:26,404 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.218.1.49, 35035, None)
2019-11-01 22:10:26,404 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.218.1.49, 35035, None)
2019-11-01 22:10:26,493 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6d0290d8{/metrics/json,null,AVAILABLE,@Spark}
2019-11-01 22:10:26,645 INFO scheduler.EventLoggingListener: Logging events to hdfs://master:9000/spark-log/application_1572643463891_0005
2019-11-01 22:10:29,531 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.218.1.11:36084) with ID 1
2019-11-01 22:10:29,573 INFO storage.BlockManagerMasterEndpoint: Registering block manager worker03:42523 with 93.3 MB RAM, BlockManagerId(1, worker03, 42523, None)
2019-11-01 22:10:30,513 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.218.1.33:58302) with ID 2
2019-11-01 22:10:30,546 INFO storage.BlockManagerMasterEndpoint: Registering block manager worker01:40791 with 93.3 MB RAM, BlockManagerId(2, worker01, 40791, None)
2019-11-01 22:10:30,576 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
2019-11-01 22:10:30,610 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/fedora/spark-warehouse').
2019-11-01 22:10:30,610 INFO internal.SharedState: Warehouse path is 'file:/home/fedora/spark-warehouse'.
2019-11-01 22:10:30,614 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@33eb0d4{/SQL,null,AVAILABLE,@Spark}
2019-11-01 22:10:30,614 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@a3cba3a{/SQL/json,null,AVAILABLE,@Spark}
2019-11-01 22:10:30,615 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@40bd0f8{/SQL/execution,null,AVAILABLE,@Spark}
2019-11-01 22:10:30,615 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6169be09{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-11-01 22:10:30,616 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@703e8050{/static/sql,null,AVAILABLE,@Spark}
2019-11-01 22:10:31,085 INFO state.StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
2019-11-01 22:10:31,222 INFO spark.SparkContext: Starting job: reduce at SparkPi.scala:38
2019-11-01 22:10:31,239 INFO scheduler.DAGScheduler: Got job 0 (reduce at SparkPi.scala:38) with 10 output partitions
2019-11-01 22:10:31,239 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (reduce at SparkPi.scala:38)
2019-11-01 22:10:31,239 INFO scheduler.DAGScheduler: Parents of final stage: List()
2019-11-01 22:10:31,240 INFO scheduler.DAGScheduler: Missing parents: List()
2019-11-01 22:10:31,243 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at map at SparkPi.scala:34), which has no missing parents
2019-11-01 22:10:31,340 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 1832.0 B, free 93.3 MB)
2019-11-01 22:10:31,356 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 1172.0 B, free 93.3 MB)
2019-11-01 22:10:31,357 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.218.1.49:35035 (size: 1172.0 B, free: 93.3 MB)
2019-11-01 22:10:31,360 INFO spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
2019-11-01 22:10:31,370 INFO scheduler.DAGScheduler: Submitting 10 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at map at SparkPi.scala:34) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2019-11-01 22:10:31,371 INFO cluster.YarnScheduler: Adding task set 0.0 with 10 tasks
2019-11-01 22:10:31,391 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, worker03, executor 1, partition 0, PROCESS_LOCAL, 4836 bytes)
2019-11-01 22:10:31,392 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, worker01, executor 2, partition 1, PROCESS_LOCAL, 4836 bytes)
2019-11-01 22:10:31,632 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on worker03:42523 (size: 1172.0 B, free: 93.3 MB)
2019-11-01 22:10:31,633 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on worker01:40791 (size: 1172.0 B, free: 93.3 MB)
2019-11-01 22:10:31,795 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, worker01, executor 2, partition 2, PROCESS_LOCAL, 4836 bytes)
2019-11-01 22:10:31,797 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, worker03, executor 1, partition 3, PROCESS_LOCAL, 4836 bytes)
2019-11-01 22:10:31,802 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 410 ms on worker01 (executor 2) (1/10)
2019-11-01 22:10:31,807 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 425 ms on worker03 (executor 1) (2/10)
2019-11-01 22:10:31,816 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, worker01, executor 2, partition 4, PROCESS_LOCAL, 4836 bytes)
2019-11-01 22:10:31,816 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 21 ms on worker01 (executor 2) (3/10)
2019-11-01 22:10:31,833 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, worker01, executor 2, partition 5, PROCESS_LOCAL, 4836 bytes)
2019-11-01 22:10:31,833 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 18 ms on worker01 (executor 2) (4/10)
2019-11-01 22:10:31,834 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, worker03, executor 1, partition 6, PROCESS_LOCAL, 4836 bytes)
2019-11-01 22:10:31,834 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 38 ms on worker03 (executor 1) (5/10)
2019-11-01 22:10:31,848 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, worker01, executor 2, partition 7, PROCESS_LOCAL, 4836 bytes)
2019-11-01 22:10:31,848 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 16 ms on worker01 (executor 2) (6/10)
2019-11-01 22:10:31,851 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8, worker03, executor 1, partition 8, PROCESS_LOCAL, 4836 bytes)
2019-11-01 22:10:31,852 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 19 ms on worker03 (executor 1) (7/10)
2019-11-01 22:10:31,863 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9, worker01, executor 2, partition 9, PROCESS_LOCAL, 4836 bytes)
2019-11-01 22:10:31,863 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 15 ms on worker01 (executor 2) (8/10)
2019-11-01 22:10:31,871 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 20 ms on worker03 (executor 1) (9/10)
2019-11-01 22:10:31,877 INFO scheduler.TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 14 ms on worker01 (executor 2) (10/10)
2019-11-01 22:10:31,878 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-01 22:10:31,879 INFO scheduler.DAGScheduler: ResultStage 0 (reduce at SparkPi.scala:38) finished in 0.498 s
2019-11-01 22:10:31,881 INFO scheduler.DAGScheduler: Job 0 finished: reduce at SparkPi.scala:38, took 0.658830 s
Pi is roughly 3.1416031416031416
2019-11-01 22:10:31,887 INFO server.AbstractConnector: Stopped Spark@5a4bef8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-01 22:10:31,889 INFO ui.SparkUI: Stopped Spark web UI at http://10.218.1.49:4040
2019-11-01 22:10:31,925 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread
2019-11-01 22:10:31,943 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors
2019-11-01 22:10:31,943 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
2019-11-01 22:10:31,946 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices
(serviceOption=None,
 services=List(),
 started=false)
2019-11-01 22:10:31,947 INFO cluster.YarnClientSchedulerBackend: Stopped
2019-11-01 22:10:31,950 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2019-11-01 22:10:31,956 INFO memory.MemoryStore: MemoryStore cleared
2019-11-01 22:10:31,957 INFO storage.BlockManager: BlockManager stopped
2019-11-01 22:10:31,959 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
2019-11-01 22:10:31,960 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2019-11-01 22:10:31,962 INFO spark.SparkContext: Successfully stopped SparkContext
2019-11-01 22:10:31,973 INFO util.ShutdownHookManager: Shutdown hook called
2019-11-01 22:10:31,974 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-f3becd3d-6cbd-476d-923a-0b653b84ec55



########################################################
## Using the Spark Shell
########################################################

Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
2019-11-01 22:11:51,860 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
2019-11-01 22:12:10,197 WARN metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
2019-11-01 22:12:10,293 WARN metastore.ObjectStore: Failed to get database default, returning NoSuchObjectException
2019-11-01 22:12:10,842 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
Spark context Web UI available at http://10.218.1.49:4040
Spark context available as 'sc' (master = yarn, app id = application_1572643463891_0006).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.2.0
      /_/
         
Using Scala version 2.11.8 (OpenJDK 64-Bit Server VM, Java 1.8.0_232)
Type in expressions to have them evaluated.
Type :help for more information.

scala> var input = spark.read.textFile("/hadoop/books/alice.txt")
input: org.apache.spark.sql.Dataset[String] = [value: string]

scala> input.filter(line => line.length()>0).count()
res0: Long = 2791



