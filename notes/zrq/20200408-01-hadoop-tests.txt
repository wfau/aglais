#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#


    #
    # https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-common/ClusterSetup.html#Configuring_Hadoop_in_Non-Secure_Mode
    # HDFS daemons are NameNode, SecondaryNameNode, and DataNode.
    # YARN daemons are ResourceManager, NodeManager, and WebAppProxy.
    # If MapReduce is to be used, then the MapReduce Job History Server will also be running.
    # For large installations, these are generally running on separate hosts.
    # 
    
    #
    # Nothing that clearly states which configuration settings go on the master and which go on the worker.
    # https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-common/ClusterSetup.html#Configuring_the_Hadoop_Daemons
    #
    # [Configurations for ResourceManager] include ResourceManager hostname etc.
    # In which case shouldn't these settings go on the NodeManager worker nodes?
    #

    #
    # Default settings with comments. 
    # https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/core-default.xml
    # https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
    # https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml
    # https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-common/yarn-default.xml
    # https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/DeprecatedProperties.html
    #


    


# -----------------------------------------------------
# Create a container to work with.
# https://podman.readthedocs.io/en/latest/markdown/podman-run.1.html
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --env "clouduser=${AGLAIS_USER:?}" \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --env "ANSIBLE_CODE=/mnt/ansible" \
        --volume "${AGLAIS_CODE:?}/experiments/zrq/ansible:/mnt/ansible:ro,z" \
        atolmis/ansible-client:latest \
        bash


# -----------------------------------------------------
# Create our Ansible include vars file.
#[root@ansibler]

    cat > /tmp/ansible-vars.yml << EOF
buildtag:  'aglais-$(date '+%Y%m%d')'
cloudname: '${cloudname}'
clouduser: '${clouduser}'
EOF


# -----------------------------------------------------
# Run the scripts from the ansible directory.
#[root@ansibler]

    # TODO Make this the working directory in the container ?
    # --env ANSIBLE_CODE=/mnt/ansible

    cd "${ANSIBLE_CODE:?}"


# -----------------------------------------------------
# Run the initial part of our deplyment.
#[root@ansibler]

    ansible-playbook \
        --inventory "hosts.yml" \
        "combined-01.yml"

    >   ....
    >   ....


# -----------------------------------------------------
# Run the Hadoop part of our deplyment.
#[root@ansibler]

    ansible-playbook \
        --inventory "hosts.yml" \
        "combined-02.yml"

    >   ....
    >   ....
    
