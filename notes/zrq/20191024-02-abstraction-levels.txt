#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2019, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#


Following on from yesterday's email with John Garbutt from StackHPC.
https://www.stackhpc.com/john-garbutt-joins-our-team.html

We have lots of questions about the best way to use OpenStack to deploy Spark and Hadoop.

Before we pester the guy with lots of daft questions I'm collecting notes and ideas
to see what the state of the art is according to the internets.

Basically it comes down to OpenStack native vs Kubernetes abstract.

We could create virtual machines ourselves and then use Ansible to deploy Hadoop and Spark.
https://github.com/cloudera/cloudera-playbook

    Ansible prefers to refer to machines by name rather than by IP address.
    At the moment, the OpenStack system doesn't have project internal DNS.
    We could use the OpenStack internal DNS (needs config changes to OpenStack).
    We could just setup our own dnamasq service to handle local machine names.

We could use Ansible to deploy Kubernetes onto our OpenStack virtual machines.

    There is a Kubernetes Special Interest Group (SIG) project called kubespray
    https://github.com/kubernetes-sigs/kubespray
    "Deploy a Production Ready Kubernetes Cluster"

    * Can be deployed on AWS, GCE, Azure, OpenStack, vSphere, Packet (bare metal), Oracle Cloud Infrastructure (Experimental), or Baremetal
    * Highly available cluster
    * Composable (Choice of the network plugin for instance)
    * Supports most popular Linux distributions
    * Continuous integration tests

We could use Rancher to deploy Kubernetes onto our virtual machines.
https://rancher.com/

    "From datacenter to cloud to edge, Rancher lets you deliver Kubernetes-as-a-Service"

    Gareth Francis used Rancher to deploy Kubernetes on the RAL OpenStack system.
    https://github.com/lsst-uk/jhub-test

We could use the Magnum cluster templates to deploy Kubernetes on OpenStack.
https://wiki.openstack.org/wiki/Magnum

    Magnum User Guide
    https://docs.openstack.org/magnum/latest/install/launch-instance.html

    This makes us dependent on the local OpenStack cluster templates.

    How portable will the cluster templates be ?
    How customised are the local cluster templates ?
    Will this make any different to a Kubernetes user ?

Once we have Kubernetes running, we could use Helm charts to deploy Hadoop and Spark onto a Kubernetes cluster.

    Gareth Francis used Helm to deploy JupyterHub on Kubernetes.
    https://github.com/lsst-uk/jhub-test

    Gareth's work was based on notes from Zero-to-JupyterHub
    https://zero-to-jupyterhub.readthedocs.io/en/latest/setup-helm.html
    https://zero-to-jupyterhub.readthedocs.io/en/latest/setup-jupyterhub.html

    Helm has an example chart for Hadoop, but HDFS is not used for large data.
    https://github.com/helm/charts/tree/master/stable/hadoop

    Cloudera provide a 'minimum viable product' (MVP) Helm chart for an Impala compute cluster on Kubernetes
    https://github.com/cloudera/hue/tree/master/tools/kubernetes/helm/impala-engine



    There are Helm charts for deploying Spark on Kubernetes
    https://github.com/helm/charts/tree/master/stable/spark

        Spark and Zeppelin in the same Helm chart

        * 1 x Spark Master with port 8080 exposed on an external LoadBalancer
        * 3 x Spark Workers with HorizontalPodAutoscaler to scale to max 10 pods when CPU hits 50% of 100m
        * 1 x Zeppelin with port 8080 exposed on an external LoadBalancer
        * All using Kubernetes Deployments

    https://github.com/GoogleCloudPlatform/spark-on-k8s-operator

        "The Kubernetes Operator for Apache Spark aims to make specifying and running Spark applications
        as easy and idiomatic as running other workloads on Kubernetes.
        It uses Kubernetes custom resources for specifying, running, and surfacing status of Spark applications.
        For a complete reference of the custom resource definitions, please refer to the API Definition.
        For details on its design, please refer to the design doc. It requires Spark 2.3 and above that
        supports Kubernetes as a native scheduler backend."


    Incubator chart for Cassandra
    https://github.com/helm/charts/tree/master/incubator/cassandra

    Incubator chart for Kafka
    https://github.com/helm/charts/tree/master/incubator/kafka

    Incubator chart for SparkOperator
    https://github.com/helm/charts/tree/master/incubator/sparkoperator


    The fact that there isn't (or I haven't managed to find) a Helm chart for
    deploying Hadoop on Kubernetes suggests that it might not be a good idea ?

    There is a stable Helm chart for Hadoop
    https://github.com/helm/charts/tree/master/stable/hadoop
    but it isn't for big data ...

    "This chart is primarily intended to be used for YARN and MapReduce job
    execution where HDFS is just used as a means to transport small artifacts
    within the framework and not for a distributed filesystem.
    Data should be read from cloud based datastores such as Google Cloud Storage,
    S3 or Swift."


There is lots of online discussions about Cloudera on Kubernetes

    There is an interesting discussion on the CDH support site from 2018
    https://community.cloudera.com/t5/Support-Questions/CDH-on-Kubernetes/td-p/64772
    (*) CDH is Cloudera’s open source distribution

    There is a comment from Cloudera about using Kubernetes for their Data Science Workbench
    https://docs.cloudera.com/documentation/data-science-workbench/1-6-x/topics/cdsw_faq.html#docker_kubernetes_support
    +ve "Cloudera Data Science Workbench uses Docker and Kubernetes to manage containers."
        "Cloudera Data Science Workbench only supports the versions of Docker and Kubernetes that are shipped with each release."
    -ve "Upgrading Docker, or Kubernetes, or running on third-party Kubernetes clusters is not supported."
    -ve "Cloudera does not support Kubernetes or Docker for running any other workloads beyond those on Cloudera Data Science Workbench."
    The comments suggest that we will need to be carful about what version of Kubernetes we choose.

    https://docs.cloudera.com/documentation/data-science-workbench/1-6-x/topics/cdsw_faq.html#kubernetes
    Q "Can I run Cloudera Data Science Workbench on my own Kubernetes cluster?"
    A "This is not supported."

    From  September 24, 2019
    https://www.datanami.com/2019/09/24/cloudera-begins-new-cloud-era-with-cdp-launch/
    "CDP is an amalgamation of, and the direct replacement for, Cloudera’s two legacy Hadoop distributions,
    including the Cloudera Distribution of Hadoop (CDH) and the Hortonworks Data Platform (HDP).
    But CDP differs in big ways from those on-premise oriented platforms, including the elimination of
    YARN in favor of Kubernetes for container management, and a replacement of HDFS for public cloud
    object stores, including Amazon S3. Support for Microsoft Azure and Google Cloud and their object
    stores will come later."

    Specifically:
    "the elimination of YARN in favor of Kubernetes for container management"

    From 26 Nov 2018
    https://thenewstack.io/will-kubernetes-sink-the-hadoop-ship/
    "Users deploying Hadoop in the cloud usually find it much simpler and cheaper to run
    it over cloud storage layers such as Amazon S3 or managed databases such as Amazon RedShift
    and Google BigQuery.
    When doing so, why choose an old and labor-intensive clustering technology like YARN, when
    they can switch to the newer and simpler Kubernetes?"

    "YARN limits users to Hadoop and Java focused tools while recent years have shown an uptake
    in post Hadoop data science frameworks including microservices and Python-based tools.
    So what if a user doesn’t want to give up on Hadoop but still enjoy modern AI microservices?"

    "The answer is just using Kubernetes as your orchestration layer. It will host different services
    including big data tools (Apache Spark or Presto), data-science and AI tools (Jupyter, TensorFlow,
    PyTorch, etc.) and any other application or data microservice. For data, it’s probably best to
    keep using managed cloud storage systems and databases, which are cheaper and simpler to maintain
    than the Hadoop file system."


    The Future of Serverless (8 Nov 2018)
    https://www.youtube.com/watch?v=HzmP25QWmZs&t=219
    People moving from OpenStack to Kubernetes on bare metal.


There is quite a lot about Hadoop on OpenStack

    Reference Architecture for Deploying Cloudera Enterprise 5.x on Red Hat OpenStack Platform 11 with Red Hat Ceph Storage 2.x
    https://docs.cloudera.com/documentation/other/reference-architecture/topics/ra_ce_red_hat.html

    The Hadoop Virtualization Extensions support the commercial clouds, but not OpenStack
    https://docs.cloudera.com/documentation/enterprise/5-7-x/topics/install_configs_for_cloud_platforms.html
    https://docs.cloudera.com/documentation/other/reference-architecture/topics/ra_private_cloud.html


    This looks like it has lots of useful information:
    Efficient Support of Big Data Storage Systems on the Cloud
    https://www.researchgate.net/publication/268988531_Efficient_Support_of_Big_Data_Storage_Systems_on_the_Cloud




Spark/Hadoop on OpenStack
    - Advantages:
        - Less complexity and fewer layers of abstraction.
        - We can use server-groups to provide affinity hints to OpenStack.

    - Disadvantages:
        - May become specific to OpenStack, possibly to IRIS OpenStack.
        - Storage location is abstracted, so no control over location?

Spark/Hadoop on Kubernetes
    - Advantages:
        - Higer level abstraction.
        - Portable to other Kubernetes clusters, e.g.
            - Google Cloud uses Kubernetes
            - Digital Ocean uses Kubernetes
            - IVOA Science Platforms group are using Kubernetes

    - Disadvantages:
        - Resource abstraction means less control over location or affinity
        - This might be an issue for Hadoop
        - Is this an issue for Spark ?


Based on all of this, my guess is we should adopt Spark on Kubernetes, leave the Hadoop filesystem
on OpenStack volumes, and look at replacing Hadoop filesystem with something more cloudy, possibly
Cassandrda for the large tables ?

However, we do need to say why we are not using OpenStack Sahara.
https://docs.openstack.org/sahara/queens/user/features.html
https://www.slideshare.net/Hadoop_Summit/t-525p230-afarrellee
https://launchpad.net/sahara
https://docs.openstack.org/sahara/latest/
https://github.com/openstack/sahara

Does it make sense to use OpenStack Sahara for the Hadoop filesystem, and Kubernetes for Spark analysis ?



    Terraform OpenStack provider
    https://www.terraform.io/docs/providers/openstack/

    Terraform KVM provider
    https://computingforgeeks.com/how-to-provision-vms-on-kvm-with-terraform/
    https://github.com/dmacvicar/terraform-provider-libvirt


