#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

    #
    # Continue from prev notes ...
    # zrq/20200415-01-spark-deploy.txt
    #

# -----------------------------------------------------
# Check the HDFS status.
#[user@desktop]

    ansiblerid=$(
        podman ps --filter 'name=ansibler' --format "{{.ID}}"
        )

    podman exec -it ${ansiblerid:?} /usr/bin/ssh master02 \
        '
        date
        hostname
        hdfs dfsadmin -report
        '

    >   Wed 15 Apr 2020 03:12:20 PM UTC
    >   aglais-20200415-master02.novalocal
    >   Configured Capacity: 4398046511104 (4 TB)
    >   Present Capacity: 4389384257536 (3.99 TB)
    >   DFS Remaining: 4389382365184 (3.99 TB)
    >   DFS Used: 1892352 (1.80 MB)
    >   DFS Used%: 0.00%
    >   Replicated Blocks:
    >   	Under replicated blocks: 0
    >   	Blocks with corrupt replicas: 0
    >   	Missing blocks: 0
    >   	Missing blocks (with replication factor 1): 0
    >   	Low redundancy blocks with highest priority to recover: 0
    >   	Pending deletion blocks: 0
    >   Erasure Coded Block Groups:
    >   	Low redundancy block groups: 0
    >   	Block groups with corrupt internal blocks: 0
    >   	Missing block groups: 0
    >   	Low redundancy blocks with highest priority to recover: 0
    >   	Pending deletion blocks: 0
    >
    >   -------------------------------------------------
    >   Live datanodes (4):
    >
    >   Name: 10.10.0.12:9866 (worker04)
    >   Hostname: worker04
    >   Decommission Status : Normal
    >   Configured Capacity: 1099511627776 (1 TB)
    >   DFS Used: 471040 (460 KB)
    >   Non DFS Used: 17301504 (16.50 MB)
    >   DFS Remaining: 1097345585152 (1021.98 GB)
    >   DFS Used%: 0.00%
    >   DFS Remaining%: 99.80%
    >   Configured Cache Capacity: 0 (0 B)
    >   Cache Used: 0 (0 B)
    >   Cache Remaining: 0 (0 B)
    >   Cache Used%: 100.00%
    >   Cache Remaining%: 0.00%
    >   Xceivers: 1
    >   Last contact: Wed Apr 15 15:12:21 UTC 2020
    >   Last Block Report: Wed Apr 15 12:30:38 UTC 2020
    >   Num of Blocks: 2
    >
    >
    >   Name: 10.10.0.16:9866 (worker01)
    >   Hostname: worker01
    >   Decommission Status : Normal
    >   Configured Capacity: 1099511627776 (1 TB)
    >   DFS Used: 475136 (464 KB)
    >   Non DFS Used: 17285120 (16.48 MB)
    >   DFS Remaining: 1097345597440 (1021.98 GB)
    >   DFS Used%: 0.00%
    >   DFS Remaining%: 99.80%
    >   Configured Cache Capacity: 0 (0 B)
    >   Cache Used: 0 (0 B)
    >   Cache Remaining: 0 (0 B)
    >   Cache Used%: 100.00%
    >   Cache Remaining%: 0.00%
    >   Xceivers: 1
    >   Last contact: Wed Apr 15 15:12:21 UTC 2020
    >   Last Block Report: Wed Apr 15 11:55:38 UTC 2020
    >   Num of Blocks: 3
    >
    >
    >   Name: 10.10.0.7:9866 (worker02)
    >   Hostname: worker02
    >   Decommission Status : Normal
    >   Configured Capacity: 1099511627776 (1 TB)
    >   DFS Used: 290816 (284 KB)
    >   Non DFS Used: 17289216 (16.49 MB)
    >   DFS Remaining: 1097345777664 (1021.98 GB)
    >   DFS Used%: 0.00%
    >   DFS Remaining%: 99.80%
    >   Configured Cache Capacity: 0 (0 B)
    >   Cache Used: 0 (0 B)
    >   Cache Remaining: 0 (0 B)
    >   Cache Used%: 100.00%
    >   Cache Remaining%: 0.00%
    >   Xceivers: 1
    >   Last contact: Wed Apr 15 15:12:21 UTC 2020
    >   Last Block Report: Wed Apr 15 12:46:27 UTC 2020
    >   Num of Blocks: 2
    >
    >
    >   Name: 10.10.0.9:9866 (worker03)
    >   Hostname: worker03
    >   Decommission Status : Normal
    >   Configured Capacity: 1099511627776 (1 TB)
    >   DFS Used: 655360 (640 KB)
    >   Non DFS Used: 17362944 (16.56 MB)
    >   DFS Remaining: 1097345404928 (1021.98 GB)
    >   DFS Used%: 0.00%
    >   DFS Remaining%: 99.80%
    >   Configured Cache Capacity: 0 (0 B)
    >   Cache Used: 0 (0 B)
    >   Cache Remaining: 0 (0 B)
    >   Cache Used%: 100.00%
    >   Cache Remaining%: 0.00%
    >   Xceivers: 1
    >   Last contact: Wed Apr 15 15:12:21 UTC 2020
    >   Last Block Report: Wed Apr 15 11:16:29 UTC 2020
    >   Num of Blocks: 3


# -----------------------------------------------------
# -----------------------------------------------------
# Login to the 'spare' master node to do the data transfer.
#[user@desktop]


    podman exec -it ${ansiblerid:?} /usr/bin/ssh master02

    >   ....
    >   ....


# -----------------------------------------------------
# Download the Gaia CDN index page and extract a list of files.
#[fedora@master02]

    sudo dnf install -y wget

    >   ....
    >   Installed:
    >     wget-1.20.3-1.fc30.x86_64


    wget http://cdn.gea.esac.esa.int/Gaia/gdr2/gaia_source/csv/

    >   --2020-04-15 15:15:35--  http://cdn.gea.esac.esa.int/Gaia/gdr2/gaia_source/csv/
    >   Resolving cdn.gea.esac.esa.int (cdn.gea.esac.esa.int)... 195.181.164.9
    >   Connecting to cdn.gea.esac.esa.int (cdn.gea.esac.esa.int)|195.181.164.9|:80... connected.
    >   HTTP request sent, awaiting response... 200 OK
    >   Length: unspecified [text/html]
    >   Saving to: ‘index.html’
    >
    >   index.html  [  <=>  ]   9.63M  34.6MB/s    in 0.3s
    >
    >   2020-04-15 15:15:35 (34.6 MB/s) - ‘index.html’ saved [10093850]


    head index.html

    >   <html>
    >   <head><title>Index of /Gaia/gdr2/gaia_source/csv/</title></head>
    >   <body>
    >   <h1>Index of /Gaia/gdr2/gaia_source/csv/</h1><hr><pre><a href="../">../</a>
    >   <a href="GaiaSource_1000172165251650944_1000424567594791808.csv.gz">GaiaSource_1000172165251650944_1000424567594791..&gt;</a> 16-Apr-2018 07:32             5347523
    >   <a href="GaiaSource_1000424601954531200_1000677322125743488.csv.gz">GaiaSource_1000424601954531200_1000677322125743..&gt;</a> 16-Apr-2018 07:32             5024698
    >   <a href="GaiaSource_1000677386549270528_1000959999693425920.csv.gz">GaiaSource_1000677386549270528_1000959999693425..&gt;</a> 16-Apr-2018 07:32             5976430
    >   <a href="GaiaSource_1000960034052654336_1001215258190537216.csv.gz">GaiaSource_1000960034052654336_1001215258190537..&gt;</a> 16-Apr-2018 07:32             6102333
    >   ....


    tail index.html

    >   ....
    >   <a href="GaiaSource_999299767199192704_999535170063180672.csv.gz">GaiaSource_999299767199192704_99953517006318067..&gt;</a> 16-Apr-2018 10:19             7062102
    >   <a href="GaiaSource_999535200126184320_999716967439074432.csv.gz">GaiaSource_999535200126184320_99971696743907443..&gt;</a> 16-Apr-2018 10:19             5795991
    >   <a href="GaiaSource_999717001796824064_999922369954904960.csv.gz">GaiaSource_999717001796824064_99992236995490496..&gt;</a> 16-Apr-2018 10:19             5240860
    >   <a href="GaiaSource_999922404314639104_1000172126596665472.csv.gz">GaiaSource_999922404314639104_10001721265966654..&gt;</a> 16-Apr-2018 10:19             5375567
    >   <a href="MD5SUM.txt">MD5SUM.txt</a>                                         22-Jun-2018 13:13             5623335
    >   <a href="_citation.txt">_citation.txt</a>                                      22-May-2018 15:39                 171
    >   <a href="_disclaimer.txt">_disclaimer.txt</a>                                    22-May-2018 15:39                 921
    >   </pre><hr></body>
    >   </html>


    sed -n '
        s/^<a href="\(GaiaSource[^"]*\)">.*/\1/p
        ' index.html \
    | tee files.txt


    >   GaiaSource_1000172165251650944_1000424567594791808.csv.gz
    >   GaiaSource_1000424601954531200_1000677322125743488.csv.gz
    >   GaiaSource_1000677386549270528_1000959999693425920.csv.gz
    >   GaiaSource_1000960034052654336_1001215258190537216.csv.gz
    >   ....
    >   ....
    >   GaiaSource_999299767199192704_999535170063180672.csv.gz
    >   GaiaSource_999535200126184320_999716967439074432.csv.gz
    >   GaiaSource_999717001796824064_999922369954904960.csv.gz
    >   GaiaSource_999922404314639104_1000172126596665472.csv.gz


    head files.txt

    >   GaiaSource_1000172165251650944_1000424567594791808.csv.gz
    >   GaiaSource_1000424601954531200_1000677322125743488.csv.gz
    >   GaiaSource_1000677386549270528_1000959999693425920.csv.gz
    >   GaiaSource_1000960034052654336_1001215258190537216.csv.gz
    >   ....


    tail files.txt

    >   ....
    >   GaiaSource_999299767199192704_999535170063180672.csv.gz
    >   GaiaSource_999535200126184320_999716967439074432.csv.gz
    >   GaiaSource_999717001796824064_999922369954904960.csv.gz
    >   GaiaSource_999922404314639104_1000172126596665472.csv.gz


# -----------------------------------------------------
# Download some of the data and upload it to HDFS.
#[fedora@master02]


    hdfs dfs -mkdir /Gaia
    hdfs dfs -mkdir /Gaia/gdr2
    hdfs dfs -mkdir /Gaia/gdr2/gaia_source
    hdfs dfs -mkdir /Gaia/gdr2/gaia_source/csv

    pushd $(mktemp -d)

        for filename in $(head -n 10 ${HOME:?}/files.txt)
        do
            wget -O "${filename}" "http://cdn.gea.esac.esa.int/Gaia/gdr2/gaia_source/csv/${filename}"
            hdfs dfs -put "${filename}" "/Gaia/gdr2/gaia_source/csv/"
            rm "${filename}"
        done

    popd


    hdfs dfs -ls /Gaia/gdr2/gaia_source/csv/


    >   -rw-r--r--   3 fedora supergroup    5347523 2020-04-15 15:21 /Gaia/gdr2/gaia_source/csv/GaiaSource_1000172165251650944_1000424567594791808.csv.gz
    >   -rw-r--r--   3 fedora supergroup    5024698 2020-04-15 15:21 /Gaia/gdr2/gaia_source/csv/GaiaSource_1000424601954531200_1000677322125743488.csv.gz
    >   -rw-r--r--   3 fedora supergroup    5976430 2020-04-15 15:21 /Gaia/gdr2/gaia_source/csv/GaiaSource_1000677386549270528_1000959999693425920.csv.gz
    >   -rw-r--r--   3 fedora supergroup    6102333 2020-04-15 15:21 /Gaia/gdr2/gaia_source/csv/GaiaSource_1000960034052654336_1001215258190537216.csv.gz
    >   -rw-r--r--   3 fedora supergroup    6143061 2020-04-15 15:21 /Gaia/gdr2/gaia_source/csv/GaiaSource_1001215288252921728_1001455428465395840.csv.gz
    >   -rw-r--r--   3 fedora supergroup    6517254 2020-04-15 15:21 /Gaia/gdr2/gaia_source/csv/GaiaSource_1001455467121397632_1001731032222989696.csv.gz
    >   -rw-r--r--   3 fedora supergroup    5591548 2020-04-15 15:21 /Gaia/gdr2/gaia_source/csv/GaiaSource_1001731062285590912_1001962891736267904.csv.gz
    >   -rw-r--r--   3 fedora supergroup    6225326 2020-04-15 15:21 /Gaia/gdr2/gaia_source/csv/GaiaSource_1001962921802480896_1002270686272717312.csv.gz
    >   -rw-r--r--   3 fedora supergroup    3445051 2020-04-15 15:21 /Gaia/gdr2/gaia_source/csv/GaiaSource_100222516391441280_100632114537641344.csv.gz
    >   -rw-r--r--   3 fedora supergroup    7090884 2020-04-15 15:21 /Gaia/gdr2/gaia_source/csv/GaiaSource_1002270754991788288_1002616826277079168.csv.gz


# -----------------------------------------------------
# -----------------------------------------------------
# Login to the master node to do the data transfer.
# TODO Can we install Spark on a different node to Yarn ?
#[user@desktop]

    podman exec -it ${ansiblerid:?} /usr/bin/ssh master01

    >   ....
    >   ....



# -----------------------------------------------------
# Start a PySpark session.
#[fedora@master01]

    pyspark

    >   Python 3.7.3 (default, Mar 27 2019, 13:36:35)
    >   [GCC 9.0.1 20190227 (Red Hat 9.0.1-0.8)] on linux
    >   Type "help", "copyright", "credits" or "license" for more information.
    >   2020-04-15 16:49:56,526 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
    >   Setting default log level to "WARN".
    >   To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
    >   2020-04-15 16:49:58,838 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
    >   Welcome to
    >         ____              __
    >        / __/__  ___ _____/ /__
    >       _\ \/ _ \/ _ `/ __/  '_/
    >      /__ / .__/\_,_/_/ /_/\_\   version 3.0.0-preview2
    >         /_/
    >
    >   Using Python version 3.7.3 (default, Mar 27 2019 13:36:35)
    >   SparkSession available as 'spark'.
    >   >>>


# -----------------------------------------------------
# Create our Python convert program.
#[pyspark]

    import time
    import pyspark
    import pyspark.sql
    import pyspark.conf
    import pyspark.context

    from pyspark.sql.types import *

    schema = StructType(
            [
            StructField("solution_id", LongType(), True),
            StructField("designation", StringType(), True),
            StructField("source_id", LongType(), True),
            StructField("random_index", LongType(), True),
            StructField("ref_epoch", DoubleType(), True),
            StructField("ra", DoubleType(), True),
            StructField("ra_error", DoubleType(), True),
            StructField("dec", DoubleType(), True),
            StructField("dec_error", DoubleType(), True),
            StructField("parallax", DoubleType(), True),
            StructField("parallax_error", DoubleType(), True),
            StructField("parallax_over_error", FloatType(), True),
            StructField("pmra", DoubleType(), True),
            StructField("pmra_error", DoubleType(), True),
            StructField("pmdec", DoubleType(), True),
            StructField("pmdec_error", DoubleType(), True),
            StructField("ra_dec_corr", FloatType(), True),
            StructField("ra_parallax_corr", FloatType(), True),
            StructField("ra_pmra_corr", FloatType(), True),
            StructField("ra_pmdec_corr", FloatType(), True),
            StructField("dec_parallax_corr", FloatType(), True),
            StructField("dec_pmra_corr", FloatType(), True),
            StructField("dec_pmdec_corr", FloatType(), True),
            StructField("parallax_pmra_corr", FloatType(), True),
            StructField("parallax_pmdec_corr", FloatType(), True),
            StructField("pmra_pmdec_corr", FloatType(), True),
            StructField("astrometric_n_obs_al", IntegerType(), True),
            StructField("astrometric_n_obs_ac", IntegerType(), True),
            StructField("astrometric_n_good_obs_al", IntegerType(), True),
            StructField("astrometric_n_bad_obs_al", IntegerType(), True),
            StructField("astrometric_gof_al", FloatType(), True),
            StructField("astrometric_chi2_al", FloatType(), True),
            StructField("astrometric_excess_noise", DoubleType(), True),
            StructField("astrometric_excess_noise_sig", DoubleType(), True),
            StructField("astrometric_params_solved", ShortType(), True),
            StructField("astrometric_primary_flag", BooleanType(), True),
            StructField("astrometric_weight_al", FloatType(), True),
            StructField("astrometric_pseudo_colour", DoubleType(), True),
            StructField("astrometric_pseudo_colour_error", DoubleType(), True),
            StructField("mean_varpi_factor_al", FloatType(), True),
            StructField("astrometric_matched_observations", DoubleType(), True),
            StructField("visibility_periods_used", ShortType(), True),
            StructField("astrometric_sigma5d_max", FloatType(), True),
            StructField("frame_rotator_object_type", IntegerType(), True),
            StructField("matched_observations", ShortType(), True),
            StructField("duplicated_source", BooleanType(), True),
            StructField("phot_g_n_obs", IntegerType(), True),
            StructField("phot_g_mean_flux", DoubleType(), True),
            StructField("phot_g_mean_flux_error", DoubleType(), True),
            StructField("phot_g_mean_flux_over_error", FloatType(), True),
            StructField("phot_g_mean_mag", FloatType(), True),
            StructField("phot_bp_n_obs", IntegerType(), True),
            StructField("phot_bp_mean_flux", DoubleType(), True),
            StructField("phot_bp_mean_flux_error", DoubleType(), True),
            StructField("phot_bp_mean_flux_over_error", FloatType(), True),
            StructField("phot_bp_mean_mag", FloatType(), True),
            StructField("phot_rp_n_obs", IntegerType(), True),
            StructField("phot_rp_mean_flux", DoubleType(), True),
            StructField("phot_rp_mean_flux_error", DoubleType(), True),
            StructField("phot_rp_mean_flux_over_error", FloatType(), True),
            StructField("phot_rp_mean_mag", FloatType(), True),
            StructField("phot_bp_rp_excess_factor", FloatType(), True),
            StructField("phot_proc_mode", ShortType(), True),
            StructField("bp_rp", FloatType(), True),
            StructField("bp_g", FloatType(), True),
            StructField("g_rp", FloatType(), True),
            StructField("radial_velocity", DoubleType(), True),
            StructField("radial_velocity_error", DoubleType(), True),
            StructField("rv_nb_transits", IntegerType(), True),
            StructField("rv_template_teff", FloatType(), True),
            StructField("rv_template_logg", FloatType(), True),
            StructField("rv_template_fe_h", FloatType(), True),
            StructField("phot_variable_flag", StringType(), True),
            StructField("l", DoubleType(), True),
            StructField("b", DoubleType(), True),
            StructField("ecl_lon", DoubleType(), True),
            StructField("ecl_lat", DoubleType(), True),
            StructField("priam_flags", LongType(), True),
            StructField("teff_val", FloatType(), True),
            StructField("teff_percentile_lower", FloatType(), True),
            StructField("teff_percentile_upper", FloatType(), True),
            StructField("a_g_val", FloatType(), True),
            StructField("a_g_percentile_lower", FloatType(), True),
            StructField("a_g_percentile_upper", FloatType(), True),
            StructField("e_bp_min_rp_val", FloatType(), True),
            StructField("e_bp_min_rp_percentile_lower", FloatType(), True),
            StructField("e_bp_min_rp_percentile_upper", FloatType(), True),
            StructField("flame_flags", LongType(), True),
            StructField("radius_val", FloatType(), True),
            StructField("radius_percentile_lower", FloatType(), True),
            StructField("radius_percentile_upper", FloatType(), True),
            StructField("lum_val", FloatType(), True),
            StructField("lum_percentile_lower", FloatType(), True),
            StructField("lum_percentile_upper", FloatType(), True),
            ]
        )

    start = time.time()
    print("-- [Staring conversion] --")

    dframe = spark.read.option(
        "header",
        "true"
        ).schema(
            schema
            ).csv(
                "hdfs://master01:9000/Gaia/gdr2/gaia_source/csv/*"
                    )

    dframe.write.parquet(
        "hdfs://master01:9000/Gaia/gdr2/gaia_source/parquet-01/"
        )


    end = time.time()
    print("-- [Finished conversion] --")
    print(str(end - start) + " seconds taken" )


    >   255.91789555549622 seconds taken


# -----------------------------------------------------
# Check the HDFS contents.
#[user@desktop]

    ansiblerid=$(
        podman ps --filter 'name=ansibler' --format "{{.ID}}"
        )

    podman exec -it ${ansiblerid:?} /usr/bin/ssh master02 \
        '
        hdfs dfs -ls /Gaia/gdr2/gaia_source/parquet/
        '


    >   Found 3 items
    >   -rw-r--r--   2 fedora supergroup          0 2020-04-15 17:10 /Gaia/gdr2/gaia_source/parquet/_SUCCESS
    >   -rw-r--r--   2 fedora supergroup   27796514 2020-04-15 17:10 /Gaia/gdr2/gaia_source/parquet/part-00000-50a9b363-811d-4d82-a4ec-9b075d7f0486-c000.snappy.parquet
    >   -rw-r--r--   2 fedora supergroup   22064406 2020-04-15 17:10 /Gaia/gdr2/gaia_source/parquet/part-00001-50a9b363-811d-4d82-a4ec-9b075d7f0486-c000.snappy.parquet

    #
    # Not what we were expecting to see ...
    #


