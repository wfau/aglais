#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

    Magunm cluster working fine for several days.
    Created 2020/07/31-14:48

    Last known good state ~ 2020/08/06-19:00

    Unable to connect via kubectl.

    Dashboard authenticates using token, but reports 'nothing to see here' for everything.

    Zeppelin and Spark seem to be  operating as normal.
    Access via LoadBalancer Ingress connected to Zeppelin Service.
    However, simple row count of single parquet file in S3 still running after 9min.

    Internal networking between K8s Pods seems OK.
    Edge networking broken ?

    Nuke it and start agin.
    Keep notes and see if it happens again.



# -----------------------------------------------------
# Access from original 'kubernator' container fails.
#[user@kubernator]

    kubectl cluster-info

    >   To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
    >   Unable to connect to the server: dial tcp 128.232.227.250:6443: i/o timeout


# -----------------------------------------------------
# Create a new client container to test.
#[user@desktop]

    source "${HOME}/aglais.env"
    podman run \
        --rm \
        --tty \
        --interactive \
        --hostname kubernator \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --env "clustername=${MAGNUM_CLUSTER:?}" \
        --volume "${HOME}/clouds.yaml:/etc/openstack/clouds.yaml:z" \
        --volume "${AGLAIS_CODE}/experiments/zrq/kubernetes:/kubernetes:z" \
        --volume "${ZEPPELIN_CODE}:/zeppelin:z" \
        atolmis/openstack-client \
            bash


# -----------------------------------------------------
# Get the connection details for our cluster.
#[user@kubernator]

    mkdir -p "${HOME}/.kube"
    openstack \
        --os-cloud "${cloudname:?}-super" \
        coe cluster config \
            "${clustername:?}" \
                --force \
                --dir "${HOME}/.kube"

    >   'SHELL'


# -----------------------------------------------------
# Check kubectl can get the connection details for our cluster.
#[user@kubernator]

    kubectl \
        cluster-info

    >   To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
    >   Unable to connect to the server: dial tcp 128.232.227.250:6443: i/o timeout
    >   
    >   
    >       kubectl \
    >           cluster-info dump
    >   Unable to connect to the server: dial tcp 128.232.227.250:6443: i/o timeout


# -----------------------------------------------------
# History

    Created using terraform template.
    notes/zrq/20200731-02-dashboard.txt

        Deleted old cluster.
        notes/zrq/20200718-03-openstack-delete.txt

        Created new cluster.
        notes/zrq/20200718-04-terraform-create.txt

    Added and tested OAuth proxy Ingress
    notes/zrq/20200801-01-ingress-test.txt

        Building on existing deployment.
        notes/zrq/20200731-02-dashboard.txt

    Added Zeppelin and Spark deployment.
    notes/zrq/20200806-03-zeppelin-test.txt

        Deploying modified Spark with AWS jar.
        notes/zrq/20200806-02-spark-S3.txt







