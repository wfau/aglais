#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

    Lots of browser windows open, all looking at different aspects of the problem.

    Magnum User Guide
    https://opendev.org/openstack/magnum/src/branch/master/doc/source/user/index.rst

        Ephemeral storage
        https://opendev.org/openstack/magnum/src/branch/master/doc/source/user/index.rst#ephemeral-storage

            Ephemeral storage provides the top layer of the Docker cow container image.
            Lasts for the lifetime of the container.

        Persistent storage
        https://opendev.org/openstack/magnum/src/branch/master/doc/source/user/index.rst#persistent-storage

            Lifetime is separate from the lifetime of the container.
            Static allocation of volumes to pods by putting the volule-id in the pod YAML definition file.

            "Kubernetes allows a previously created Cinder block to be mounted to a pod and this is done by
             specifying the block ID in the pod YAML file. When the pod is scheduled on a node, Kubernetes
             will interface with Cinder to request the volume to be mounted on this node, then Kubernetes
             will launch the Docker container with the proper options to make the filesystem on the Cinder
             volume accessible to the container in the pod. When the pod exits, Kubernetes will again send
             a request to Cinder to unmount the volume's filesystem, making it available to be mounted on
             other nodes."

    Get started with octavia-ingress-controller for Kubernetes
    https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/using-octavia-ingress-controller.md

        In Kubernetes, Ingress allows external users and client applications access to HTTP services.
        Ingress consists of two components.

        * Ingress Resource is a collection of rules for the inbound traffic to reach Services.
          These are Layer 7 (L7) rules that allow hostnames (and optionally paths) to be directed
          to specific Services in Kubernetes.

        * Ingress Controller which acts upon the rules set by the Ingress Resource, typically via
          an HTTP or L7 load balancer.

        ....

        The octavia-ingress-controller could solve all the above problems in the OpenStack environment
        by creating a single load balancer for multiple NodePort type services in an Ingress.

        ....


        Examples of how to deploy inside K8s ..


    Mount CephFS using FUSE
    https://docs.ceph.com/docs/master/cephfs/fuse/

        Commands for using the FUSE client to mount CephFS.

    Ceph Block Device
    https://docs.ceph.com/docs/master/rbd/

        Examples:
        "Ensure your Ceph cluster is running ...."


    Ceph Block Devices and Kubernetes
    https://docs.ceph.com/docs/master/rbd/rbd-kubernetes/

        "You may use Ceph Block Device images with Kubernetes v1.13 and later
         through ceph-csi, which dynamically provisions RBD images to back
         Kubernetes volumes and maps these RBD images as block devices (optionally
         mounting a file system contained within the image) on worker nodes running
         pods that reference an RBD-backed volume. Ceph stripes block device images
         as objects across the cluster, which means that large Ceph Block Device
         images have better performance than a standalone server!"

        Examples:
        "Ensure your Ceph cluster is running ...."

    RADOS Block Device Driver
    https://github.com/openstack/cinder/blob/master/cinder/volume/drivers/rbd.py

        I think this is the older 'in tree' driver ?

    OpenStack are using a code style checker
    https://github.com/openstack/cinder/commit/3eb9b422f43c5657740026720d1718698660413b
    http://flake8.pycqa.org/en/latest/


    Ephemeral Inline CSI volumes
    https://github.com/kubernetes/enhancements/blob/master/keps/sig-storage/20190122-csi-inline-volumes.md

        A KEP () to provide ephemeral (inline) storage via CSI (Container Storage Interface (CSI).


    Pod Inline Volume Support
    https://kubernetes-csi.github.io/docs/ephemeral-local-volumes.html

        Documentation for inline volumes
        Status: beta in 1.16


    Kubernetes Container Storage Interface (CSI) Documentation
    https://kubernetes-csi.github.io/docs/introduction.html

        "The Container Storage Interface (CSI) is a standard for exposing arbitrary block
         and file storage systems to containerized workloads on Container Orchestration Systems
         (COs) like Kubernetes."

        "Using CSI third-party storage providers can write and deploy plugins exposing new storage
         systems in Kubernetes without ever having to touch the core Kubernetes code."



    Kubernetes Enhancement Proposals (KEPs)
    https://github.com/kubernetes/enhancements/tree/master/keps

        "A Kubernetes Enhancement Proposal (KEP) is a way to propose, communicate and
         coordinate on new efforts for the Kubernetes project."

    Kubernetes Enhancement Proposal Process
    https://github.com/kubernetes/enhancements/blob/master/keps/0001-kubernetes-enhancement-proposal-process.md

        "A standardized development process for Kubernetes ..."


    Kubernetes - Volumes
    https://kubernetes.io/docs/concepts/storage/volumes/

        "On-disk files in a Container are ephemeral, which presents some problems for non-trivial
         applications when running in Containers."

        "First, when a Container crashes, kubelet will restart it, but the files will be lost -
         the Container starts with a clean state."

        "Second, when running Containers together in a Pod it is often necessary to share files
         between those Containers."

        .. volumes allow data sharng between containers within a pod.
        Question - when deploying Spark - are all the workers in the same pod ?


    Managing Compute Resources for Containers
    https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#local-ephemeral-storage

        Kubernetes version 1.8 introduces a new resource, ephemeral-storage for managing local ephemeral storage.

        "In each Kubernetes node, kubelet’s root directory (/var/lib/kubelet by default) and log directory (/var/log)
         are stored on the root partition of the node. This partition is also shared and consumed by Pods via emptyDir
         volumes, container logs, image layers and container writable layers."

        "This partition is “ephemeral” and applications cannot expect any performance SLAs (Disk IOPS for example)
         from this partition. Local ephemeral storage management only applies for the root partition; the optional
         partition for image layer and writable layer is out of scope."


        "How Pods with ephemeral-storage requests are scheduled"

        "When you create a Pod, the Kubernetes scheduler selects a node for the Pod to run on. Each node has a maximum
         amount of local ephemeral storage it can provide for Pods. For more information, see “Node Allocatable”.

        "The scheduler ensures that the sum of the resource requests of the scheduled Containers is less than the
         capacity of the node."

    Reserve Compute Resources for System Daemons
    https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable

        "Allocatable on a Kubernetes node is defined as the amount of compute resources that are available for pods.
         The scheduler does not over-subscribe Allocatable. CPU, memory and ephemeral-storage are supported as of now."


    Persistent Volumes
    https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims

        "This document describes the current state of PersistentVolumes in Kubernetes.
         Familiarity with volumes is suggested."

        * Persistent Volumes
        * Persistent Volume Claims
        * File system mount
        * Block device mount

        Writing Portable Configuration
            ....

----

    OpenStack command list
    https://docs.openstack.org/python-openstackclient/train/cli/command-list.html

    CephFS Native driver
    https://docs.openstack.org/ocata/config-reference/shared-file-systems/drivers/cephfs-native-driver.html

    CephFS driver
    https://docs.openstack.org/manila/train/admin/cephfs_driver.html

    OpenStack Admin Guide
    https://docs.openstack.org/manila/train/admin/index.html

    CSI Cinder driver
    https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/using-cinder-csi-plugin.md

        The CSI driver for OpenStack Cinder volumes.

    CSI Manila driver
    https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/using-manila-csi-plugin.md

        The CSI driver for OpenStack Manila shares.

    Kubernetes Container-Storage-Interface (CSI) components
    https://github.com/kubernetes-csi/


----

    Digital Ocean Kubernetes apps
    https://marketplace.digitalocean.com/category/kubernetes

        Empty list in Firefox, works in Chrome
        Spark not in the list

    Kubernetes How-Tos
    https://www.digitalocean.com/docs/kubernetes/how-to/

    How to Add Block Storage Volumes to Kubernetes Clusters
    https://www.digitalocean.com/docs/kubernetes/how-to/add-volumes/

        storageClassName: do-block-storage

    Highly available Block Storage
    https://www.digitalocean.com/products/block-storage/

**  A Container Storage Interface (CSI) Driver for DigitalOcean Block Storage
    https://github.com/digitalocean/csi-digitalocean

    Spaces - S3 compatible object storage
    https://www.digitalocean.com/docs/spaces/

    Digital Ocean StorageOS for Kubernetes
    https://marketplace.digitalocean.com/apps/storageos

    Take DigitalOcean Kubernetes for a Cruise
    https://thenewstack.io/take-digitalocean-kubernetes-for-a-cruise/


    Setting Up a Ceph Filesystem with Kubernetes on DigitalOcean
    http://www.kevinmusselman.com/2019/07/18/setting-up-a-ceph-filesystem-with-kubernetes-on-digitalocean/

    Deploy Ceph inside Kubernetes
    https://github.com/rook/rook/tree/release-1.0/cluster/examples/kubernetes/ceph

        Uses a Kubernetes cluster with volumes to provide a Ceph filesystem
            * DigitalOcean nodes
            * DigitalOcean volumes (*virtual*)
            * Kubernetes cluster
            * Deploy Rook
            * Publish Ceph filesystem

        Useful details in the examples though.

    Rook
    https://github.com/rook/rook/tree/release-1.0

        "Rook is an open source cloud-native storage orchestrator for Kubernetes, providing the platform,
         framework, and support for a diverse set of storage solutions to natively integrate with cloud
         native environments."

    Ceph Storage Quickstart
    https://github.com/rook/rook/blob/release-1.0/Documentation/ceph-quickstart.md

        "This guide will walk you through the basic setup of a Ceph cluster and enable you to consume block,
        object, and file storage from other pods running in your cluster."

**  Rook - Shared File System
    https://github.com/rook/rook/blob/release-1.0/Documentation/ceph-filesystem.md

        "A shared file system can be mounted with read/write permission from multiple pods.
         This may be useful for applications which can be clustered using a shared filesystem."


    Did any of you get rook ceph working with DO's kubernetes?
    https://www.digitalocean.com/community/questions/did-any-of-you-get-rook-ceph-working-with-do-s-kubernetes

    Shared storage on Digital Ocean Kubernetes
    https://www.digitalocean.com/community/questions/shared-storage-on-digital-ocean-kubernetes


----

    Dynamic Provisioning of PVCs
    https://docs.portworx.com/portworx-install-with-kubernetes/storage-operations/create-pvcs/dynamic-provisioning/

    Create shared PVCs
    https://docs.portworx.com/portworx-install-with-kubernetes/storage-operations/create-pvcs/create-shared-pvcs/#provision-a-shared-volume

    Kubernetes Storage 101
    https://docs.portworx.com/portworx-install-with-kubernetes/storage-operations/kubernetes-storage-101/

    Kubernetes Persistent volumes
    https://docs.portworx.com/portworx-install-with-kubernetes/storage-operations/kubernetes-storage-101/volumes/

    Stateful applications
    https://docs.portworx.com/portworx-install-with-kubernetes/storage-operations/kubernetes-storage-101/applications/

    Kubernetes Snapshots and Backups
    https://docs.portworx.com/portworx-install-with-kubernetes/storage-operations/kubernetes-storage-101/snapshots/

    Hyperconvergence
    https://docs.portworx.com/portworx-install-with-kubernetes/storage-operations/kubernetes-storage-101/hyperconvergence/

        "When a pod runs on the same host as its volume, it is known as convergence or hyper-convergence.
         Because this configuration reduces the network overhead of an application, performance is typically better."

        "Natively, Kubernetes does not support this. Portworx uses Stork to ensure that the nodes with data for a volume
         get prioritized when pods are being scheduled. Stork works as a scheduler extender here."

    Portworx Open Source Projects
    https://portworx.com/products/open-source/


    OpenStorage
    https://github.com/libopenstorage/openstorage

        "A multi-host clustered implementation of the open storage specification"

        "OpenStorage is an API abstraction layer providing support for multiple public APIs, including the OpenStorage SDK,
         CSI, and the Docker Volume API. Developers using OpenStorage for their storage systems can expect it to work
         seamlessly with any of the supported public APIs. These implementations provide users with the ability to run
         stateful services in Linux containers on multiple hosts."



----

    Stork - Storage Operator Runtime for Kubernetes
    https://github.com/libopenstorage/stork

        "Stork is a Cloud Native storage operator runtime scheduler plugin. It translates a scheduler's orchestration
         decisions into someting that an external cloud native storage solution can act upon. By doing so, it extends
         Kubernetes with more stateful awareness of the underlying storage provider, it's capabilities and state."







----

    Inspect Parquet from command line
    https://stackoverflow.com/questions/36140264/inspect-parquet-from-command-line

        ....

    Parquet tools
    https://github.com/apache/parquet-mr/tree/master/parquet-tools

        "Parquet-Tools contains java based command line tools that aid in the inspection of Parquet files."

    Parquet cli
    https://github.com/chhantyal/parquet-cli

        "Command line (CLI) tool to inspect Apache Parquet files on the go"


----

    Research Software Engineering Cambridge
    https://github.com/RSE-Cambridge

    Magnum
    https://github.com/RSE-Cambridge/magnum

        Container Infrastructure Management Service for OpenStack http://openstack.org
        Cloned from https://github.com/openstack/magnum

    iris-k8s-spark
    https://github.com/RSE-Cambridge/iris-k8s-spark

        .. <empty> ..

    cumulus-config
    https://github.com/RSE-Cambridge/cumulus-config

        Configuration of Cambridge UIS Evolution of Darwin (EoD) OpenStack infrastructure

        Config for the gaia_dev, gaia_test and gaia_prod projects.
        https://github.com/RSE-Cambridge/cumulus-config/blob/master/etc/cumulus-config/cumulus-config.yml#L121

----

    StackHPC
    https://github.com/stackhpc

        "StackHPC develops OpenStack capabilities for research computing use cases."

**  Autoscaling in OpenStack Magnum deployed Kubernetes
    https://github.com/stackhpc/magnum-terraform


    Example OpenHPC cluster
    https://github.com/stackhpc/eiffel-ohpc/blob/master/terraform_k8s/k8s.tf


        data "openstack_containerinfra_clustertemplate_v1" "kube14" {
          name = "kubernetes-1.14-2"
        }


    openstack_containerinfra_clustertemplate_v1
    https://github.com/terraform-providers/terraform-provider-openstack/blob/master/website/docs/r/containerinfra_clustertemplate_v1.html.markdown

        "Manages a V1 Magnum cluster template resource within OpenStack."


----

    Helm Chart for deployments of our cloud-based JupyterHub integrated with Spark
    https://github.com/dirac-institute/dirac-hub

        Uses S3A for storage
        https://github.com/dirac-institute/dirac-hub/blob/master/deployment/spark.yaml
        https://github.com/dirac-institute/dirac-hub/blob/master/deployment/storage.yaml
        https://hadoop.apache.org/docs/current/hadoop-aws/tools/hadoop-aws/index.html#Introducing_the_Hadoop_S3A_client.
        https://hadoop.apache.org/docs/current/hadoop-aws/tools/hadoop-aws/index.html#How_S3A_writes_data_to_S3

        HowTo - s3a on Spark on AWS EC2
        http://deploymentzone.com/2015/12/20/s3a-on-spark-on-aws-ec2/

----

    A JupyterLab extension for Apache Spark
    https://github.com/dirac-institute/spark-labextension

----

    LSST Spark
    https://github.com/dirac-institute/lsstspark

        "This repository is part of a project researching the benefits and issues related to running astronomical
         image analysis pipelines using cloud services. This particular repository contains a pipeline showcasing
         the required modifications to the Large Synoptic Sky Survey Telescope image analysis software required
         for it to be run on Amazon Web Services (AWS) using Spark."

    Fit and refine WCS
    https://github.com/dirac-institute/lsstspark/blob/master/notebooks/Astrometry.ipynb

        USes data in an S3 repository.

----

    Data Visualizations for the Gaia DR2 Solar System Objects
    https://github.com/dirac-institute/GaiaDR2_SSO_DataViz


----

    Make Alerts Really Simple
    https://github.com/LCOGT/ztf-alert-server

----

    Terraform scripts for the ZTF Alert Distribution System
    https://github.com/dirac-institute/zads-terraform

----

    Rackspace OpenStack
    https://www.rackspace.com/en-gb/openstack

    Rackspace Kubernetes-as-a-Service
    https://www.rackspace.com/en-gb/managed-kubernetes

    Optimized Spark Stack for Rackspace
    https://www.objectrocket.com/blog/company/optimized-spark-for-rackspace-managed-cloud-big-data/

    Managed Data Services for Big Data deployments
    https://www.rackspace.com/en-gb/data/big-data


