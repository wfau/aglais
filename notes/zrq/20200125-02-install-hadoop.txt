#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

    #
    # List the command history on a worker node from the live system.
    # Compare with our steps to see if we have missed anything.
    #

[fedora@stv-dev-worker-1 ~]$ history
    1  exit
    2  ls

    3  sudo yum install wget
    4  wget http://apache.cs.utah.edu/hadoop/common/current/hadoop-3.1.3.tar.gz

    5  tar -xzf hadoop-3.1.3.tar.gz
    6  mv hadoop-3.1.3 hadoop

    7  sudo yum install java-1.8.0-openjdk
    8  sudo yum install -y java-1.8.0-openjdk

    9  cat > "${HOME:?}/.profile" << EOF

   10  PATH=/home/fedora/spark/bin:/home/fedora/.local/bin:/home/fedora/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/bin:/sbin:/home/fedora/hadoop/bin:/home/fedora/hadoop/sbin
   11  EOF

       # Set $PATH to different hings in different places

   12  cat <<EOF >> "${HOME:?}/.bashrc"
   13  export HADOOP_HOME=/home/fedora/hadoop
   14  export PATH=/home/fedora/.local/bin:/home/fedora/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/bin:/sbin:/home/fedora/hadoop/bin:/home/fedora/hadoop/sbin:/home/fedora/spark/bin
   15  export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.232.b09-0.fc30.x86_64/jre/
   16  export HADOOP_CONF_DIR=/home/fedora/hadoop/etc/hadoop
   17  export SPARK_HOME=/home/fedora/spark
   18  export LD_LIBRARY_PATH=/home/fedora/hadoop/lib/native
   19  EOF

   20  sudo su
   21  cat > "${HOME:?}/.ssh/config" << EOF
       ....
   76  EOF

   77  sudo chmod 600 ~/.ssh/config
   78  sudo chmod 600 ~/.ssh/stv-master
   79  ls

   80  sudo yum install -y nano

   81  cd ~
   82  ls

   83  cat > "${HOME:?}/hadoop/etc/hadoop/core-site.xml" << EOF
       ....
  103  EOF

  104  cat > "${HOME:?}/hadoop/etc/hadoop/yarn-site.xml" << EOF
       ....
  167  EOF

  168  cat > "${HOME:?}/hadoop/etc/hadoop/workers" << EOF
  169  stv-dev-worker-1
  170  stv-dev-worker-2
  171  stv-dev-worker-3
  172  stv-dev-worker-4
  173  stv-dev-worker-5
  174  stv-dev-worker-6
  175  EOF

       # At some point, this gets changed from 6 to 8

  176  cat > "${HOME:?}/hadoop/etc/hadoop/mapred-site.xml" << EOF
       ....
  207  EOF

  208  cat > "${HOME:?}/hadoop/etc/hadoop/core-site.xml" << EOF
       ....
  216  EOF

  217  sudo mkdir /home/hadoop/

        # This directory is not used for anything.

  218  sudo chown -R fedora:root /home/hadoop/

  219  source /home/fedora/hadoop/bin/hdfs namenode -format

  220  source ~/.bashrc
  221  source /home/fedora/hadoop/bin/hdfs namenode -format

       # This is executed on all the worker nodes.

  222  exit

  223  ls
  224  sudo yum install python3
  225  sudo update-alternatives --install /usr/bin/python python /usr/bin/python3 10

  226  stop-all.
  227  stop-all.sh

    # stop-all ... but I can't see a start ?

  228  ls

  229  nano ~/.ssh/stv_master
  230  cat ~/.ssh/stv_master
  231  nano ~/.ssh/stv_master
  232  nano ~/.ssh/stv_master[A
  233  nano ~/.ssh/stv_master
  234  nano ~/.ssh/config
  235  nano ~/.ssh/stv_master
  236  rm ~/.ssh/stv_master
  237  nano ~/.ssh/stv-master
  238  sudo chmod 600 ~/.ssh/stv-master
  239  nano ~/.ssh/stv-master

       # This file is removed later.

  240  ls
  241  pwd

  242  ifconfig

  243  cat /etc/hosts

  244  cat > "${HOME:?}/hadoop/etc/hadoop/mapred-site.xml" << EOF
       ....
  275  EOF

       # Second time creating this file.
       # First time with $HADOOP_HOME
       # Second time with /home/fedora/hadoop

  276  ls
  277  cat ethms

  278  hdfs dfs -ls
  279  df -h

  280  exit

  281  pwd
  282  ls
  283  cd ..
  284  ls
  285  cd hadoop/
  286  ls
  287  pwd
  288  s
  289  ls
  290  mkdir gaia
  291  cd gaia
  292  mkdir gdr1
  293  d ..
  294  ls
  295  cd ..
  296  ls
  297  cd ..
  298  ls
  299  rm -r hadoop/gaia
  300  cd hadoop/
  301  ls
  302  mkdir ascii
  303  cd ascii/
  304  mkdir gaia
  305  cd gaia
  306  mkdir gdr1
  307  ls
  308  cd gdr1/
  309  mkdir gaia
  310  ls
  311  cd gaia/
  312  ls
  313  pwd
  314  ls

    # Looks like this sequence is editing /home/hadoop
    # Directory is not used.

  315  cat hadoop/etc/hadoop/mapred-site.xml
  316  cat /etc/hosts

  317  exit

  318  history

  319  cat /etc/hosts

  320  ping stv-dev-zeppelin:45487

  321  telnet 10.0.0.27

  322  yum install telnet
  323  sudo yum install telnet
  324  telnet 10.0.0.27

  325  ssh stv-dev-zeppelin
  326  telnet 10.0.0.27:45487
  327  telnet 10.0.0.27 -p 45487
  328  telnet 10.0.0.27 45487

  329  ifconfig

  330  history

  331  ls
  332  cd ..
  333  ls
  334  cd hadoop/ascii/
  335  ls
  336  cd ..
  337  ls

    # Is the ascii test data imported from elsewhere ?

  338  hdfs fs -put ascii/ /hadoop/ascii
  339  hdfs fs -put ascii /hadoop/ascii
  340  hdfs dfs -put ascii /hadoop/ascii
  341  exit

  342  history | grep scp
  343  ls
  344  cd ..
  345  ls
  346  cd hadoop/ascii/
  347  ls
  348  cd ..
  349  ls
  350  cd ..
  351  l
  352  ls

  353  scp -r hadoop/ascii/ stv-dev-master:/hadoop/ascii
  354  scp -r hadoop/ascii/ stv-dev-master:/hadoop/

  355  sudo scp -r hadoop/ascii/ stv-dev-master:/hadoop/

  356  scp -r hadoop/ascii/ stv-dev-master:/hadoop/
  357  scp -r hadoop/ascii/ stv-dev-master:/hadoop/ascii
  358  scp -r hadoop/ascii/ stv-dev-master:/hadoop/

    # This looks like pushing the ascii test data to the master node ?

  359  ls
  360  ssh stv-dev-master

  361  pwd
  362  cd ..
  363  ls
  364  pwd
  365  cd home/hadoop/
  366  ls

  367  scp -r ascii/* stv-dev-master:/hadoop/
  368  scp -r ascii/* stv-dev-master:/hadoop/ascii

    # This looks like pushing the ascii test data to the master node ?

  369  pwd
  370  ls
  371  cd /home/hadoop/
  372  ls
  373  pwd
  374  ls
  375  cd ascii/
  376  ls
  377  scp -r /home/hadoop/ascii/ stv-dev-master:/home/hadoop/
  378  ls
  379  cd ..
  380  ls
  381  cd /home/
  382  ls
  383  cd hadoop/
  384  ls
  385  cd ascii/
  386  ls
  387  cd gaia/
  388  ls
  389  cd gdr1/
  390  ls
  391  cd gaia/
  392  ls
  393  cd data/
  394  ls
  395  nano part-00000-eb15db47-f0d7-474d-a96b-017df830999a.txt
  396  pwd
  397  cd ..
  398  ls
  399  cd ..
  400  ls
  401  cd gaia/
  402  ls
  403  cd ..
  404  ls
  405  cd ..
  406  ls
  407  pwd
  408  ls
  409  mkdir gdr2
  410  ls
  411  cd gdr1/
  412  ls
  413  cd gaia/
  414  ls
  415  cd ..
  416  ls
  417  cd ..
  418  ls
  419  cd gdr1/gaia/data/
  420  pwd
  421  s
  422  pwd
  423  cd ..
  424  ls
  425  cd ..
  426  ls
  427  cd ..
  428  ls
  429  cd gdr2/
  430  ls
  431  mkdir gaia
  432  mkdir data
  433  ls
  434  pwd
  435  cd gaia/
  436  ls
  437  pwd

  438  ssh stv-dev-storage

  439  cat ~/.ssh/stv-master

  440  ls
  441  cd data/
  442  ls

  443  tar -xzvf GaiaSource_2953315445120754304_2953404234985104256.csv.gz
  444  gzip GaiaSource_2953315445120754304_2953404234985104256.csv.gz

  445  ls
  446  gzip -d GaiaSource_2953315445120754304_2953404234985104256.csv.gz

  447  ls
  448  more GaiaSource_2953315445120754304_2953404234985104256.csv

  449  ls
  450  rm -r csv/
  451  ls
  452  rm csv/
  453  lls
  454  rm -r csv/
  455  ls
  456  ls -al
  457  rm GaiaSource_2953315445120754304_2953404234985104256.csv
  458  rm GaiaSource_*
  459  ls
  460  cd ..
  461  ls
  462  rm -r data/
  463  nano ~/.ssh/config
  464  nano /etc/hosts

  465  exit

  466  nano hadoop/etc/hadoop/workers

  467  source /home/fedora/hadoop/bin/hdfs namenode -format

    # hdfs namenode -format

  468  >hadoop/etc/hadoop/workers
  469  cat > "${HOME:?}/hadoop/etc/hadoop/workers" << EOF
  470  stv-dev-worker-1
  471  stv-dev-worker-2
  472  stv-dev-worker-3
  473  stv-dev-worker-4
  474  stv-dev-worker-5
  475  stv-dev-worker-6
  476  EOF
  477  source ~/.bashrc
  478  sudo mkdir /home/hadoop/
  479  sudo chown -R fedora:root /home/hadoop/
  480  source /home/fedora/hadoop/bin/hdfs namenode -format
  481  stop-all.sh
  482  hdfs dfs -ls /hadoop/
  483  hdfs dfs -ls /hadoop/books
  484  nano hadoop/etc/hadoop/workers
  485  ssh stv-destora
  486  stop-all.sh
  487  source /home/fedora/hadoop/bin/hdfs namenode -format
  488  sudo rm -R /tmp/*
  489  ls
  490  cd /home/hadoop
  491  cd /home/hadoop/ascii/gaia/gdr1/gaia/
  492  ls
  493  hdfs dfs -put /home/hadoop/ascii/gaia/gdr1/gaia/data/* /hadoop/gaia/csv/gdr1/gaia_source
  494  hdfs dfs -put /hadoop/gaia/csv/gdr1/gaia_source
  495  hdfs dfs -mkdir /hadoop/gaia/csv/gdr1/gaia_source
  496  hdfs dfs -put /home/hadoop/ascii/gaia/gdr1/gaia/data/* /hadoop/gaia/csv/gdr1/gaia_source
  497  hdfs dfs -ls /hadoop/gaia/csv/gdr1/gaia_source
  498  ls
  499  hdfs dfs -mkdir /hadoop/gaia/csv/gdr1/gaia_source/data
  500  hdfs dfs -rm /hadoop/gaia/csv/gdr1/gaia_source/*.txt
  501  hdfs dfs -put /home/hadoop/ascii/gaia/gdr1/gaia/data/* /hadoop/gaia/csv/gdr1/gaia_source/data/
  502  hdfs dfs -put /home/hadoop/ascii/gaia/gdr1/gaia/GaiaSourceHeaderSchema /hadoop/gaia/csv/gdr1/gaia_source/

  503  spark-submit --num-executors 3 --driver-memory 4096m --executor-memory 1024m --executor-cores 2 asciiToParquetConverter.jar -input hdfs:///hadoop/gaia/csv/gdr1/gaia_source/data -output hdfs:///hadoop/gaia/parquet/gdr1/gaia_source -schema hdfs:///hadoop/gaia/csv/gdr1/gaia_source/GaiaSourceHeaderSchema

  504  hdfs dfs -ls /hadoop/gaia/parquet/gdr2/gaia_source
  505  hdfs dfs -mkdir /hadoop/gaia/csv/gdr2/gaia_source
  506  hdfs dfs -mkdir /hadoop/gaia/parquet/gdr2/gaia_source

  507  df -h
  508  hadoop dfsadmin -report
  509  df -h
  510  hdfs dfs -df
  511  hdfs dfs -df -h
  512  nano hadoop/etc/hadoop/hdfs-site.xml
  513  nano hadoop/etc/hadoop/mapred-env.sh
  514  nano hadoop/etc/hadoop/mapred-site.xml
  515  nano hadoop/etc/hadoop/core-site.xml
  516  nano hadoop/etc/hadoop/hdfs-site.xml
  517  nano hadoop/etc/hadoop/core-site.xml
  518  df -h
  519  hadoop dfsadmin -report
  520  df -h
  521  cat hadoop/etc/hadoop/workers
  522  ls
  523  hdfs dfs -ls /hadoop
  524  hdfs dfs -ls /hadoop/gaia
  525  hdfs dfs -ls /hadoop/gaia/parquet
  526  hdfs dfs -ls /hadoop/gaia/parquet/gdr2
  527  hdfs dfs -ls /hadoop/gaia/parquet/gdr2/csv
  528  ls
  529  hdfs dfsadmin -safemode leave
  530  pwd
  531  cd hadoop
  532  ls
  533  pwd
  534  cd etc/
  535  ls
  536  pwd
  537  ls
  538  cd hadoop/
  539  ls
  540  cat hdfs-site.xml
  541  hdfs namenode -format
  542  ls
  543  cat hadoop/etc/hadoop/workers
  544  nano hadoop/etc/hadoop/workers
  545  cd ~
  546  nano hadoop/etc/hadoop/workers
  547  cat hadoop/etc/hadoop/workers
  548  df -h
  549  cd /home/hadoop/ascii/gaia/gdr2/gaia/
  550  ls
  551  cd data/
  552  ls
  553  cd ..
  554  ls
  555  cd ..
  556  ls
  557  cd ..
  558  ls
  559  cd ..
  560  ls
  561  cd ..
  562  ls
  563  cd ..
  564  ls
  565  cd ..
  566  ls
  567  cd home/
  568  cd ..
  569  cd /home/hadoop
  570  ls
  571  cd  ascii
  572  ls
  573  cd gaia
  574  ls
  575  cd /home/hadoop
  576  ls
  577  cd ascii/
  578  ls
  579  cd gaia/
  580  ls
  581  cd ..
  582  ls
  583  cd ..
  584  ls
  585  cd ..
  586  ls
  587  cd /home/hadoop/
  588  ls
  589  rm -r ascii
  590  rm -r parquet
  591  df -h
  592  hdfs dfs -report
  593  exit

  594  cat hadoop/etc/hadoop/workers
  595  ls
  596  source /home/fedora/hadoop/bin/hdfs namenode -format
  597  hdfs dfs -ls /hadoop
  598  ls
  599  source /home/fedora/hadoop/bin/hdfs namenode -format
  600  rm -r /tmp/
  601  sudo rm -r /tmp/
  602  mkdir /tmp
  603  sudo mkdir /tmp
  604  rm -r /tmp/
  605  sudo rm -r /tmp/
  606  sudo mkdir /tmp
  607  source /home/fedora/hadoop/bin/hdfs namenode -format
  608  sudo chmod 755 /tmp/*
  609  sudo chmod 755 -R  /tmp/
  610  source /home/fedora/hadoop/bin/hdfs namenode -format
  611  ls /tmp
  612  sudo chown root:fedora /tmp
  613  source /home/fedora/hadoop/bin/hdfs namenode -format
  614  sudo chown root:root -R /tmp/
  615  sudo chmod 776 -R /tmp/
  616  source /home/fedora/hadoop/bin/hdfs namenode -format
  617  rm -r /tmp/
  618  sudp rm -r /tmp/
  619  sudo rm -r /tmp/
  620  source /home/fedora/hadoop/bin/hdfs namenode -format
  621  sudo mkdir /tm[
  622  sudo mkdir /tmp
  623  sudo rm -r /tmp/
  624  sudo rm -r /tm\[/
  625  sudo mkdir /tmp
  626  source /home/fedora/hadoop/bin/hdfs namenode -format
  627  sudo chmod -R 777 /tmp/
  628  source /home/fedora/hadoop/bin/hdfs namenode -format
  629  sudo rm -R /tmp/*
  630  rm -rf ~/hadoop/data/nameNode/*
  631  rm -rf ~/hadoop/data/dataNode/*
  632  hadoop namenode -format
  633  df -h
  634  ls
  635  pwd
  636  cd ~/
  637  ls
  638  cd /home/fedora/
  639  ls
  640  cd ${HOME}
  641  pwd
  642  cd ..
  643  cd ${HOME}
  644  pwd
  645  rm ~/.ssh/stv-master
  646  history | grep 8080
  647  nano ~/.ssh/authorized_keys
  648  cat ~/.ssh/authorized_keys
  649  ssh stv-dev-worker-2
  650  cat /etc/hosts
  651  sudo nano ~/.ssh/config
  652  cat /etc/hosts
  653  ssh stv-dev-worker-2
  654  ssh -vstv-dev-worker-2
  655  ssh -v stv-dev-worker-2
  656  ssh stv-dev-worker-2
  657  exit
  658  free -h
  659      df -h
  660  docker ps -a
  661  ps -ef
  662  ps --help
  663  ps -ef | sed -n '/^fedora/ p'
  664  top
  665  man top
  666  top -n 1
  667  top -n 1 | head
  668  top -n 1 | head -n 20
  669  reset
  670  top -n 1 | head -n 20
  671  reset
  672  top -b -n 1 | head -n 20
  673  top -b -n 1 | head -n 10
  674  top
  675  ps
  676  ps -ef
  677  htop
  678  top -b -n 1 | head -n 10
  679  top -b -n 1 | head -n 20
  680  top
  681  ls /home/fedora/hadoop/logs/
  682  ls -al /home/fedora/hadoop/logs/
  683  less /home/fedora/hadoop/logs/hadoop-fedora-datanode-stv-dev-worker-1.novalocal.log
  684  ls -al /home/fedora/hadoop/logs/userlogs/
  685  ls -al /home/fedora/hadoop/logs/userlogs/application_1578764470640_0013/
  686  ls -al /home/fedora/hadoop/logs/userlogs/application_1578764470640_0013/container_1578764470640_0013_01_000007/
  687  less /home/fedora/hadoop/logs/userlogs/application_1578764470640_0013/container_1578764470640_0013_01_000007/directory.info
  688  less /home/fedora/hadoop/logs/userlogs/application_1578764470640_0013/container_1578764470640_0013_01_000007/launch_container.sh
  689  less /home/fedora/hadoop/logs/userlogs/application_1578764470640_0013/container_1578764470640_0013_01_000007/prelaunch.err
  690  less /home/fedora/hadoop/logs/userlogs/application_1578764470640_0013/container_1578764470640_0013_01_000007/prelaunch.out
  691  less /home/fedora/hadoop/logs/userlogs/application_1578764470640_0013/container_1578764470640_0013_01_000007/stderr
  692  tail -f /home/fedora/hadoop/logs/userlogs/application_1578764470640_0013/container_1578764470640_0013_01_000007/stderr
  693  date
  694  cat ~/.ssh/known_hosts
  695  cat ~/.ssh/authorized_keys
  696  ls
  697  ls hadoop
  698  ls hadoop/lib
  699  ls hadoop/lib/native/
  700  ls hadoop
  701  ls hadoop/bin/
  702  ls hadoop/data/
  703  ls hadoop/etc/
  704  ls hadoop/etc/hadoop/
  705  ls hadoop/etc/
  706  ls hadoop/
  707  ls hadoop/include/
  708  ls hadoop/lib
  709  ls hadoop/lib/native/
  710  ls hadoop/libexec/
  711  find . -name '*.jar'
  712          find . -name '*aws*.jar'
  713  ls /usr/local/
  714          find . -name '*hadoop*.jar'
  715          find . -name '*hadoop-common*.jar'
  716          find . -name '*hadoop-mapreduce*.jar'
  717          find . -name '*hadoop-common*.jar'
  718          find . -name '*hadoop-mapreduce-client*.jar'
  719          find . -name '*hadoop-mapreduce-client-core*.jar'
  720  ls
  721  pwd
  722  ps -ef
  723  ps -ef | sed -n '/^fedora/p'
  724  ls
  725  grep -r 'S3AFileSystem' *
  726  df -h
  727  ls
  728  cd ..
  729  ls
  730  cd hadoop/
  731  ls
  732  u -sh /
  733  du -sh /
  734  sudo du -sh /
  735  sudo du -sh /tmp/
  736  ls
  737  sudo du -sh /home
  738  sudo du -sh /home/
  739  sudo du -sh /home/fedora
  740  sudo du -sh /home/hadoop
  741  sudo du -sh /home/fedora/hadoop/
  742  sudo du -sh /home/fedora/hadoop/data
  743  sudo du -sh /home/fedora/hadoop/logs/
  744  rm -r /home/fedora/hadoop/logs/*
  745  history
  746  ls
  747  history
  748  exit
  749  history
[fedora@stv-dev-worker-1 ~]$


