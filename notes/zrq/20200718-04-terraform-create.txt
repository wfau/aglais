#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --hostname terraformer \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --env "clustername=${MAGNUM_CLUSTER:?}" \
        --volume "${HOME}/clouds.yaml:/etc/openstack/clouds.yaml:z" \
        --volume "${AGLAIS_CODE}/experiments/zrq/terraform:/terraform:z" \
        atolmis/terraform-client \
        bash


# -----------------------------------------------------
# Set the cloud, credentials and cluster names.
#[user@terraformer]

    # Deprecated - inherited from aglais.env
    # cloudname=gaia-prod
    # clustername=Tiberius


# -----------------------------------------------------
# Delete any old state.
#[user@terraformer]

    rm -rf /terraform/.terraform
    rm -f  /terraform/tfvars

    rm -f  /terraform/terraform.tfsate
    rm -f  /terraform/terraform.tfsate.backup

# -----------------------------------------------------
# Create our tfvars file.
#[user@terraformer]

    cat > "${HOME}/cluster.tfvars" << EOF
zrq_cloud_name   = "${cloudname:?}-super"
zrq_cluster_name = "${clustername:?}"
zrq_master_count = 2
zrq_worker_count = 4
zrq_max_worker_count = 8
zrq_worker_flavor_name = "general.v1.small"
EOF


# -----------------------------------------------------
# Run Terraform to deploy our cluster.
#[user@terraformer]

    pushd "/terraform"

        terraform init

    >   ....
    >   Initializing modules...
    >   ....
    >   Initializing the backend...
    >   ....
    >   Initializing provider plugins...
    >   ....
    >   Terraform has been successfully initialized!


        terraform plan \
            -var-file "${HOME}/cluster.tfvars"


    >     ....
    >     # module.cluster.null_resource.kubeconfig will be created
    >     + resource "null_resource" "kubeconfig" {
    >       ....
    >       }
    >
    >     # module.cluster.openstack_compute_keypair_v2.zrq_keypair will be created
    >     + resource "openstack_compute_keypair_v2" "zrq_keypair" {
    >       ....
    >       }
    >
    >     # module.cluster.openstack_containerinfra_cluster_v1.zrq_cluster will be created
    >     + resource "openstack_containerinfra_cluster_v1" "zrq_cluster" {
    >       ....
    >       }
    >
    >   Plan: 3 to add, 0 to change, 0 to destroy.


        terraform apply \
            -var-file "${HOME}/cluster.tfvars"

        popd

    >   ....
    >   ....
    >
    >   Plan: 3 to add, 0 to change, 0 to destroy.
    >
    >   Do you want to perform these actions?
    >     Terraform will perform the actions described above.
    >     Only 'yes' will be accepted to approve.
    >
    >     Enter a value: yes
    >
    >   module.cluster.openstack_compute_keypair_v2.zrq_keypair: Creating...
    >   module.cluster.openstack_compute_keypair_v2.zrq_keypair: Creation complete after 1s [id=Tiberius-keypair]
    >   module.cluster.openstack_containerinfra_cluster_v1.zrq_cluster: Creating...
    >   module.cluster.openstack_containerinfra_cluster_v1.zrq_cluster: Still creating... [10s elapsed]
    >   module.cluster.openstack_containerinfra_cluster_v1.zrq_cluster: Still creating... [20s elapsed]
    >   ....
    >   ....
    >   module.cluster.openstack_containerinfra_cluster_v1.zrq_cluster: Still creating... [5m30s elapsed]
    >   module.cluster.openstack_containerinfra_cluster_v1.zrq_cluster: Still creating... [5m40s elapsed]
    >   module.cluster.openstack_containerinfra_cluster_v1.zrq_cluster: Still creating... [5m50s elapsed]
    >   module.cluster.openstack_containerinfra_cluster_v1.zrq_cluster: Still creating... [6m0s elapsed]
    >   module.cluster.openstack_containerinfra_cluster_v1.zrq_cluster: Creation complete after 6m4s [id=11bee166-2d47-49ba-b4a3-859f2049c403]
    >   module.cluster.null_resource.kubeconfig: Creating...
    >   module.cluster.null_resource.kubeconfig: Provisioning with 'local-exec'...
    >   module.cluster.null_resource.kubeconfig (local-exec): Executing: ["/bin/sh" "-c" "mkdir -p ~/.kube/Tiberius; openstack --os-cloud gaia-prod-super coe cluster config Tiberius --dir ~/.kube/Tiberius --force;"]
    >   module.cluster.null_resource.kubeconfig: Still creating... [10s elapsed]
    >   module.cluster.null_resource.kubeconfig (local-exec): 'SHELL'

    #
    # Skip the error message.
    # TODO figure out what causes this and fix it.
    #

    >   Error: Error running command 'mkdir -p ~/.kube/Tiberius; openstack --os-cloud gaia-prod-super coe cluster config Tiberius --dir ~/.kube/Tiberius --force;': exit status 1. Output: 'SHELL'


# -----------------------------------------------------
# Check the kubectl config for our cluster.
#[user@terraformer]

    cat "${HOME}/.kube/${clustername:?}/config"

    >   apiVersion: v1
    >   clusters:
    >   - cluster:
    >       certificate-authority-data: LS0tLS1C........UtLS0tLQ==
    >       server: https://128.232.227.216:6443
    >     name: Tiberius
    >   contexts:
    >   - context:
    >       cluster: Tiberius
    >       user: admin
    >     name: default
    >   current-context: default
    >   kind: Config
    >   preferences: {}
    >   users:
    >   - name: admin
    >     user:
    >       client-certificate-data: LS0tLS1C........RS0tLS0t
    >       client-key-data: LS0tLS1C........tLS0tLQo=

# -----------------------------------------------------
# Use kubectl to the endpoint addresses.
#[user@terraformer]

    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        cluster-info

    >   Kubernetes master is running at https://128.232.227.216:6443
    >   Heapster is running at https://128.232.227.216:6443/api/v1/namespaces/kube-system/services/heapster/proxy
    >   CoreDNS is running at https://128.232.227.216:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy




