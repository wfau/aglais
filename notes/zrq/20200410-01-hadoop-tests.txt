#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

    #
    # Continuing from prev notes ...
    # 

    #
    # TODO
    # Add [/opt/hadoop/sbin] to the PATH on masters.
    # 


# -----------------------------------------------------
# Investigate the start-xyz.sh scripts ..
#[root@ansibler]
    
    #
    # https://github.com/wfau/aglais/blob/master/notes/stv/20191209-openstack-deployment.txt#L607
    # On Master Node: (ssh stv-dev-master)
    #   start-all.sh
    #

    ssh master01

        vi /opt/hadoop/sbin/start-all.sh 

            ....
            ....
            # start hdfs daemons if hdfs is present
            if [[ -f "${HADOOP_HDFS_HOME}/sbin/start-dfs.sh" ]]; then
              "${HADOOP_HDFS_HOME}/sbin/start-dfs.sh" --config "${HADOOP_CONF_DIR}"
            fi

            # start yarn daemons if yarn is present
            if [[ -f "${HADOOP_YARN_HOME}/sbin/start-yarn.sh" ]]; then
              "${HADOOP_YARN_HOME}/sbin/start-yarn.sh" --config "${HADOOP_CONF_DIR}"
            fi


        vi /opt/hadoop/sbin/start-dfs.sh

            ....
            ....
            #---------------------------------------------------------
            # namenodes

            NAMENODES=$("${HADOOP_HDFS_HOME}/bin/hdfs" getconf -namenodes 2>/dev/null)

            if [[ -z "${NAMENODES}" ]]; then
              NAMENODES=$(hostname)
            fi

            echo "Starting namenodes on [${NAMENODES}]"
            hadoop_uservar_su hdfs namenode "${HADOOP_HDFS_HOME}/bin/hdfs" \
                --workers \
                --config "${HADOOP_CONF_DIR}" \
                --hostnames "${NAMENODES}" \
                --daemon start \
                namenode ${nameStartOpt}

            HADOOP_JUMBO_RETCOUNTER=$?

            #---------------------------------------------------------
            # datanodes (using default workers file)

            echo "Starting datanodes"
            hadoop_uservar_su hdfs datanode "${HADOOP_HDFS_HOME}/bin/hdfs" \
                --workers \
                --config "${HADOOP_CONF_DIR}" \
                --daemon start \
                datanode ${dataStartOpt}
            (( HADOOP_JUMBO_RETCOUNTER=HADOOP_JUMBO_RETCOUNTER + $? ))
            ....
            ....



