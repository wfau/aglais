#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

    Static volume, application credentials.

# -----------------------------------------------------

    Gaia has 5Ti bytes of data stored in Manila.
    Need to be able to treat the static data separately from the Kubernetes cluster.
    Delete existing K8s cluster, create a new K8s cluster, import the data as a static PersistentVolume.

    Demonstrates suspected bug in the Manila CSI plugin.
    Issue with accepting application credentials.

# -----------------------------------------------------

    Initial testing with a smaller 5GiB share.

    Start with a clean system:

        Cluster delete
            20200831-02-openstack-delete.txt
            Explicitly delete the CephFS router

        Magnum cluster
            20200828-01-magnum-cluster.txt
            Using Openstack directly, not Terraform.

        Nginx-controller
            20200807-06-nginx-ingress.txt
                Helm based deploy.

        Dashboard
            20200807-07-dashboard.txt
                Helm based deploy followed by kubectl additions.

        CephFS-router
            20200820-05-cephfs-router.txt
                Terraform deploy, Openstack to get configuration.


# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --hostname kubernator \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --env "clustername=${CLUSTER_NAME:?}" \
        --volume "${HOME}/clouds.yaml:/etc/openstack/clouds.yaml:z" \
        atolmis/openstack-client \
        bash


# -----------------------------------------------------
# Get the connection details for our cluster.
#[user@kubernator]

    mkdir -p "${HOME}/.kube"
    openstack \
        --os-cloud "${cloudname:?}" \
        coe cluster config \
            "${clustername:?}" \
                --force \
                --dir "${HOME}/.kube"


    kubectl \
        cluster-info

    >   Kubernetes master is running at https://....
    >   Heapster is running at https://....
    >   CoreDNS is running at https://....


# -----------------------------------------------------
# Install config editing tools.
# TODO - add this to the kubernator image
#[user@kubernator]

    mkdir   "${HOME:?}/bin"
    wget -O "${HOME:?}/bin/yq" https://github.com/mikefarah/yq/releases/download/3.3.2/yq_linux_amd64
    chmod a+x "${HOME:?}/bin/yq"


# -----------------------------------------------------
# Install the Ceph CSI plugin using Helm.
# https://github.com/ceph/ceph-csi
# https://github.com/ceph/ceph-csi/blob/master/charts/ceph-csi-cephfs/README.md#ceph-csi-cephfs
#[user@kubernator]

    helm repo add \
        ceph-csi \
            'https://ceph.github.io/csi-charts'

    >   "ceph-csi" has been added to your repositories


    kubectl create \
        namespace \
            ceph-csi-cephfs

    >   namespace/ceph-csi-cephfs created


    helm install \
        --namespace "ceph-csi-cephfs" \
        "ceph-csi-cephfs" \
            ceph-csi/ceph-csi-cephfs

    >   NAME: ceph-csi-cephfs
    >   LAST DEPLOYED: Tue Sep  1 11:32:14 2020
    >   NAMESPACE: ceph-csi-cephfs
    >   STATUS: deployed
    >   REVISION: 1
    >   TEST SUITE: None
    >   NOTES:
    >   Examples on how to configure a storage class and start using the driver are here:
    >   https://github.com/ceph/ceph-csi/tree/v3.1.0/examples/cephfs


# -----------------------------------------------------
# Install the git client.
#[user@kubernator]

    dnf install -y git


# -----------------------------------------------------
# Checkout a copy of the Cloud Provider OpenStack repo.
#[user@kubernator]

    pushd "${HOME}"

        git clone 'https://github.com/kubernetes/cloud-provider-openstack.git'

    popd


# -----------------------------------------------------
# Install the Manila CSI plugin using Helm.
# https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/using-manila-csi-plugin.md#kubernetes-115
#[user@kubernator]

    # Default install is NFS only.
    # We need our local values.yaml to install the CephFS driver.

    cat > "/tmp/csi-manila-cephfs-helm-values.yaml" << EOF
# Enabled Manila share protocols
shareProtocols:
   - protocolSelector: CEPHFS
     fwdNodePluginEndpoint:
       dir: /var/lib/kubelet/plugins/cephfs.csi.ceph.com
       sockFile: csi.sock

nameOverride: csi-manila-cephfs
EOF


    helm install \
        csi-manila-cephfs \
        "${HOME}/cloud-provider-openstack/charts/manila-csi-plugin" \
        --values "/tmp/csi-manila-cephfs-helm-values.yaml"

    >   NAME: csi-manila-cephfs
    >   LAST DEPLOYED: Tue Sep  1 11:38:59 2020
    >   NAMESPACE: default
    >   STATUS: deployed
    >   REVISION: 1
    >   TEST SUITE: None


# -----------------------------------------------------
# Check all the parts are in place.
# https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/using-manila-csi-plugin.md#verifying-the-deployment
#[user@kubernator]

    kubectl get all

    >   NAME                                                            READY   STATUS    RESTARTS   AGE
    >   ....
    >   pod/csi-manila-cephfs-controllerplugin-0                        3/3     Running   0          18s
    >   pod/csi-manila-cephfs-nodeplugin-2kd8l                          2/2     Running   0          18s
    >   pod/csi-manila-cephfs-nodeplugin-f8fv8                          2/2     Running   0          18s
    >   pod/csi-manila-cephfs-nodeplugin-ll4cv                          2/2     Running   0          18s
    >   pod/csi-manila-cephfs-nodeplugin-s62r4                          2/2     Running   0          18s
    >   ....
    >
    >
    >   NAME                                                          TYPE           CLUSTER-IP       EXTERNAL-IP       PORT(S)                      AGE
    >   ....
    >   service/csi-manila-cephfs-controllerplugin                    ClusterIP      10.254.246.254   <none>            12345/TCP                    18s
    >   service/kubernetes                                            ClusterIP      10.254.0.1       <none>            443/TCP                      22m
    >   ....
    >
    >   NAME                                          DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
    >   daemonset.apps/csi-manila-cephfs-nodeplugin   4         4         4       4            4           <none>          18s
    >   ....
    >
    >   NAME                                                  READY   AGE
    >   statefulset.apps/csi-manila-cephfs-controllerplugin   1/1     18s


# -----------------------------------------------------
# Create our secrets using application credentials from clouds.yaml.
#[user@kubernator]

    authurl=$(
        yq r /etc/openstack/clouds.yaml \
            'clouds.gaia-prod.auth.auth_url'
        )

    region=$(
        yq r /etc/openstack/clouds.yaml \
            'clouds.gaia-prod.region_name'
        )

    credentialID=$(
        yq r /etc/openstack/clouds.yaml \
            'clouds.gaia-prod.auth.application_credential_id'
        )

    credentialsecret=$(
        yq r /etc/openstack/clouds.yaml \
            'clouds.gaia-prod.auth.application_credential_secret'
        )


    cat > "/tmp/csi-manila-cephfs-secrets.yaml" << EOF
apiVersion: v1
kind: Secret
metadata:
  name: csi-manila-cephfs-secrets
  namespace: default
stringData:
  # Mandatory
  os-authURL: "${authurl:?}"
  os-region: "${region:?}"

  # Authentication using user credentials
  os-applicationCredentialID: "${credentialID:?}"
  os-applicationCredentialSecret: "${credentialsecret:?}"

EOF

    kubectl create \
        --filename "/tmp/csi-manila-cephfs-secrets.yaml"

    >   secret/csi-manila-cephfs-secrets created


    kubectl describe \
        secret \
            csi-manila-cephfs-secrets

    >   ....
    >   ....
    >   Data
    >   ====
    >   os-authURL:                      47 bytes
    >   os-region:                       9 bytes
    >   os-applicationCredentialID:      32 bytes
    >   os-applicationCredentialSecret:  35 bytes


# -----------------------------------------------------
# Set the Manila API version.
# https://stackoverflow.com/a/58806536
#[user@kubernator]

    export OS_SHARE_API_VERSION=2.51

# -----------------------------------------------------
# List the available shares.
#[user@kubernator]

    openstack \
        --os-cloud "${cloudname:?}" \
            share list

    >   +--------------------------------------+------------------------------------------+------+-------------+-----------+-----------+------------------+------+-------------------+
    >   | ID                                   | Name                                     | Size | Share Proto | Status    | Is Public | Share Type Name  | Host | Availability Zone |
    >   +--------------------------------------+------------------------------------------+------+-------------+-----------+-----------+------------------+------+-------------------+
    >   | ad1d9ca2-5b1c-4064-8c74-695286de6098 | gaia-dr2-share                           | 4399 | CEPHFS      | available | True      | cephfsnativetype |      | nova              |
    >   | a32ea61f-a922-4b9d-959b-a9d2d2e57c4b | magruela-share                           |    5 | CEPHFS      | available | True      | cephfsnativetype |      | nova              |
    >   | d71dae9a-b508-4a54-a5e9-7a91e8548b1e | pvc-41814ac5-00cc-4ba3-ae8b-6eddad01ef0c |    1 | CEPHFS      | available | False     | cephfsnativetype |      | nova              |
    >   +--------------------------------------+------------------------------------------+------+-------------+-----------+-----------+------------------+------+-------------------+

    shareid=$(
        openstack \
            --os-cloud "${cloudname:?}" \
                share list \
                --format json \
        | jq -r '.[] | select(.Name == "magruela-share") | .ID'
        )

    echo "Share [${shareid}]"

    >   Share [a32ea61f-a922-4b9d-959b-a9d2d2e57c4b]


# -----------------------------------------------------
# List our current share access rules.
#[user@kubernator]

    openstack \
        --os-cloud "${cloudname:?}" \
            share access list \
                "${shareid:?}"

    >   +--------------------------------------+-------------+----------------+--------------+--------+------------------------------------------+----------------------------+----------------------------+
    >   | id                                   | access_type | access_to      | access_level | state  | access_key                               | created_at                 | updated_at                 |
    >   +--------------------------------------+-------------+----------------+--------------+--------+------------------------------------------+----------------------------+----------------------------+
    >   | f658ea33-daef-46da-8fff-82b23ced65de | cephx       | magruela-share | rw           | active | AQCEe0xfABd/IhAA5/E9uQ/6ucGr3PzPme4RCQ== | 2020-08-31T04:24:36.000000 | 2020-08-31T04:24:36.000000 |
    >   +--------------------------------------+-------------+----------------+--------------+--------+------------------------------------------+----------------------------+----------------------------+

    shareaccessid=$(
        openstack \
            --os-cloud "${cloudname:?}" \
                share access list \
                    --format json \
                        "${shareid:?}" \
        | jq -r '.[0] | .id'
        )

    echo "Access [${shareaccessid}]"

    >   Access [f658ea33-daef-46da-8fff-82b23ced65de]


# -----------------------------------------------------
# Create our persistent volume.
#[user@kubernator]

    cat > "/tmp/magruela-volume.yaml" << EOF
apiVersion: v1
kind: PersistentVolume
metadata:
  name: magruela-volume
  labels:
    name: magruela-volume
spec:
  accessModes:
  - ReadWriteMany
  capacity:
    storage: 4Gi
  csi:
    driver: cephfs.manila.csi.openstack.org
    volumeHandle: magruela-volume-handle
    nodeStageSecretRef:
      name: csi-manila-cephfs-secrets
      namespace: default
    nodePublishSecretRef:
      name: csi-manila-cephfs-secrets
      namespace: default
    volumeAttributes:
      shareID: ${shareid:?}
      shareAccessID: ${shareaccessid:?}
EOF

    kubectl apply \
        --filename "/tmp/magruela-volume.yaml"

    >   persistentvolume/magruela-volume created


    kubectl describe \
        persistentvolume \
            magruela-volume

    >   Name:            magruela-volume
    >   Labels:          name=magruela-volume
    >   Annotations:     kubectl.kubernetes.io/last-applied-configuration:
    >                      {"apiVersion":"v1","kind":"PersistentVolume","metadata":{"annotations":{},"labels":{"name":"magruela-volume"},"name":"magruela-volume"},"s...
    >   Finalizers:      [kubernetes.io/pv-protection]
    >   StorageClass:
    >   Status:          Available
    >   Claim:
    >   Reclaim Policy:  Retain
    >   Access Modes:    RWX
    >   VolumeMode:      Filesystem
    >   Capacity:        4Gi
    >   Node Affinity:   <none>
    >   Message:
    >   Source:
    >       Type:              CSI (a Container Storage Interface (CSI) volume source)
    >       Driver:            cephfs.manila.csi.openstack.org
    >       VolumeHandle:      magruela-volume-handle
    >       ReadOnly:          false
    >       VolumeAttributes:      shareAccessID=f658ea33-daef-46da-8fff-82b23ced65de
    >                              shareID=a32ea61f-a922-4b9d-959b-a9d2d2e57c4b
    >   Events:                <none>


# -----------------------------------------------------
# Create our persistent volume claim.
#[user@kubernator]

    cat > "/tmp/magruela-claim.yaml" << EOF
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: magruela-claim
spec:
  accessModes:
  - ReadWriteMany
  resources:
    requests:
      storage: 3Gi
  selector:
    matchExpressions:
    - key: name
      operator: In
      values: ["magruela-volume"]
EOF

    kubectl apply \
        --filename "/tmp/magruela-claim.yaml"

    >   persistentvolumeclaim/magruela-claim created


    kubectl describe \
        persistentvolumeclaim \
            magruela-claim

    >   Name:          magruela-claim
    >   Namespace:     default
    >   StorageClass:
    >   Status:        Bound
    >   Volume:        magruela-volume
    >   Labels:        <none>
    >   Annotations:   kubectl.kubernetes.io/last-applied-configuration:
    >                    {"apiVersion":"v1","kind":"PersistentVolumeClaim","metadata":{"annotations":{},"name":"magruela-claim","namespace":"default"},"spec":{"acc...
    >                  pv.kubernetes.io/bind-completed: yes
    >                  pv.kubernetes.io/bound-by-controller: yes
    >   Finalizers:    [kubernetes.io/pvc-protection]
    >   Capacity:      4Gi
    >   Access Modes:  RWX
    >   VolumeMode:    Filesystem
    >   Mounted By:    <none>
    >   Events:        <none>


# -----------------------------------------------------
# Create a Pod that mounts the volume.
#[user@kubernator]

    cat > /tmp/magruela-pod.yaml << EOF
kind: Pod
apiVersion: v1
metadata:
  name: magruela-pod
  namespace: default
spec:
  volumes:
    - name: magruela-data
      persistentVolumeClaim:
        claimName: magruela-claim
    - name: local-data
      emptyDir: {}
  containers:
    - name: magruela-container
      image: 'fedora:latest'
      volumeMounts:
        - name: magruela-data
          mountPath: /magruela-data
        - name: local-data
          mountPath: /local-data
      command: ["/bin/sh"]
      args:
        - "-c"
        - >-
          while true; do
          date >> /local-data/date-log.txt;
          sleep 1;
          done
EOF

    kubectl \
        apply \
            --filename /tmp/magruela-pod.yaml

    >   pod/magruela-pod created


    kubectl \
        describe pod \
            magruela-pod

    >   Name:         magruela-pod
    >   Namespace:    default
    >   Node:         tiberius-20200901-tzufyez4qfkn-node-2/10.0.0.248
    >   Start Time:   Tue, 01 Sep 2020 11:51:38 +0000
    >   Labels:       <none>
    >   Annotations:  kubectl.kubernetes.io/last-applied-configuration:
    >                   {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{},"name":"magruela-pod","namespace":"default"},"spec":{"containers":[{"args":["...
    >   Status:       Pending
    >   IP:
    >   Containers:
    >     magruela-container:
    >       Container ID:
    >       Image:         fedora:latest
    >       Image ID:
    >       Port:          <none>
    >       Host Port:     <none>
    >       Command:
    >         /bin/sh
    >       Args:
    >         -c
    >         while true; do date >> /local-data/date-log.txt; sleep 1; done
    >       State:          Waiting
    >         Reason:       ContainerCreating
    >       Ready:          False
    >       Restart Count:  0
    >       Environment:    <none>
    >       Mounts:
    >         /local-data from local-data (rw)
    >         /magruela-data from magruela-data (rw)
    >         /var/run/secrets/kubernetes.io/serviceaccount from default-token-4dcpn (ro)
    >   Conditions:
    >     Type              Status
    >     Initialized       True
    >     Ready             False
    >     ContainersReady   False
    >     PodScheduled      True
    >   Volumes:
    >     magruela-data:
    >       Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
    >       ClaimName:  magruela-claim
    >       ReadOnly:   false
    >     local-data:
    >       Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    >       Medium:
    >       SizeLimit:  <unset>
    >     default-token-4dcpn:
    >       Type:        Secret (a volume populated by a Secret)
    >       SecretName:  default-token-4dcpn
    >       Optional:    false
    >   QoS Class:       BestEffort
    >   Node-Selectors:  <none>
    >   Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
    >                    node.kubernetes.io/unreachable:NoExecute for 300s
    >   Events:
    >     Type     Reason       Age               From                                            Message
    >     ----     ------       ----              ----                                            -------
    >     Normal   Scheduled    <unknown>         default-scheduler                               Successfully assigned default/magruela-pod to tiberius-20200901-tzufyez4qfkn-node-2
    >     Warning  FailedMount  8s (x6 over 24s)  kubelet, tiberius-20200901-tzufyez4qfkn-node-2  MountVolume.MountDevice failed for volume "magruela-volume" : rpc error: code = InvalidArgument desc = invalid OpenStack secrets: parameter 'os-authURL' requires exactly one of [os-password os-trustID] parameters


# -----------------------------------------------------
# Get the events for our Pod.
# https://stackoverflow.com/a/51931477
#[user@kubernator]

    kubectl \
        get event \
            --namespace 'default' \
            --field-selector 'involvedObject.name=magruela-pod'

    >   LAST SEEN   TYPE      REASON        OBJECT             MESSAGE
    >   <unknown>   Normal    Scheduled     pod/magruela-pod   Successfully assigned default/magruela-pod to tiberius-20200901-tzufyez4qfkn-node-2
    >   32s         Warning   FailedMount   pod/magruela-pod   MountVolume.MountDevice failed for volume "magruela-volume" : rpc error: code = InvalidArgument desc = invalid OpenStack secrets: parameter 'os-authURL' requires exactly one of [os-password os-trustID] parameters
    >   4m17s       Warning   FailedMount   pod/magruela-pod   Unable to attach or mount volumes: unmounted volumes=[magruela-data], unattached volumes=[default-token-4dcpn magruela-data local-data]: timed out waiting for the condition
    >   2m          Warning   FailedMount   pod/magruela-pod   Unable to attach or mount volumes: unmounted volumes=[magruela-data], unattached volumes=[magruela-data local-data default-token-4dcpn]: timed out waiting for the condition

# -----------------------------------------------------

Error message:

    MountVolume.MountDevice failed for volume "magruela-volume"
        rpc error:
            code = InvalidArgument
            desc = invalid OpenStack secrets: parameter 'os-authURL' requires exactly one of [os-password os-trustID] parameters

Suspected cause:

    https://github.com/kubernetes/cloud-provider-openstack/blob/master/pkg/cloudprovider/providers/openstack/openstack.go#L190

        type AuthOpts struct {
	        AuthURL          string `gcfg:"auth-url" mapstructure:"auth-url" name:"os-authURL" dependsOn:"os-password|os-trustID"`
	        UserID           string `gcfg:"user-id" mapstructure:"user-id" name:"os-userID" value:"optional" dependsOn:"os-password"`
	        Username         string `name:"os-userName" value:"optional" dependsOn:"os-password"`
            ....

    This limits the input to username/password or trustID/trustSecret

        name:"os-authURL" dependsOn:"os-password|os-trustID"

    To allow application credentialsd this should also allow 'application-credential-id'.

        name:"os-authURL" dependsOn:"os-password|os-trustID|os-application-credential-id"



