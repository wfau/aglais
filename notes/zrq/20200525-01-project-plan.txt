#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

    Robust system that users can login and use.
    With get/put notebooks to external repository like GitHub.
    With data staging space within the system.




    For the forward plan in May, I’ve added a line to all three of our detail sheets concerning a roadmap to EDR3 deployment.
    I realise we’re still learning a lot about various technologies and set-ups, but I’m concerned that with ~6 months to go
    to EDR3 we now need to have a clear idea of where we want to get to by the end of the year in order to have something useful
    for some general users (not all-singing, all-dancing multi-user: merely something that is stable and secure enough and
    easily accessible for single users, built on what we have now which broadly speaking is suitable I think).

    I’d like us to have a roadmap doc (no need for highly polished or length - a few pages max!) that details the top-level
    components, functionalities and administrative aspects that illustrate the look-and-feel of the platform we want to deliver
    on this timescale. I mentioned this to Dave last week and I understand that he will take the lead on a skeleton for us to
    work on together during May. I emphasise there’s no need for polish here: a short, rough working doc is all we need.


    Define 'robust'
        Passes acceptance tests
            Tests based on technical cases
                Resource limits
                    What happens when we run out of cpu
                        Try to allocate more than our OpenStack quota

                    What happens when we run out of memory
                    What happens when we run out of disk space
                        Local space on each node
                            On each ilesystem
                                /var
                                /tmp
                                swap
                        On the shared filesystem
                            Users quota
                            Global space
                    What happens when we run out of network
                        Can we use a proxy to throttle network traffic

                Compute limits
                    Test cases it should fail gracefully
                        Infinite wait - hangs
                        Infinite loop, just cpu
                        Infinite loop, allocates memory
                        Infinite loop, uses network
                        Infinite loop, uses space

                    Test cases it should pass cleanly
                        Scale cpu up to quota limit
                        Scale mem up to quota limit
                        Scale time up to quota limit
                        Scale space up to quota limit

            Tests based on science cases

                Simple benmchmarks

                    Pi calculation
                        Measure performance
                        Checksum the results

                    cvs to parquet transfom
                        One for each combination of filesystems
                            Measure performance
                            Use each filesystem
                            Checksum the results

                    We need more of these ...

                Complex analysis

                    Published

                        We need to have a set of curated analyses that we can put in examples and tests.
                        Can we get examples from the existing GDAF system ?
                            ....

                        Paper search for astronomy Spark analyses
                            ....


                    Unpublished

                        We can use unpublished analyses, but we can't publish details.
                        This makes it hard to use these as examp[les and unit tests.

                        Nigel & Dennis

                            https://www.esa.int/Science_Exploration/Space_Science/Gaia/Gaia_untangles_the_starry_strings_of_the_Milky_Way

                            "Untangling the Galaxy I: Local Structure and Star Formation History of the Milky Way"
                            by M. Kounkel and K. Covey is published in the Astronomical Journal.
                            https://arxiv.org/abs/1907.07709


                        Roger Mor
                            BGM FASt - binary.so
                                Include custom binaries in the Spark image.
                            BGM FASt - Python
                                Specific version of Python ?





            Library of example analysis tasks (#24)

                stv-hdbscan-2
                "This is a copy of the the Kounkel and Covey groups demo, with some small modifications to the code to get it working with a small dataset."
                Promote this to a curated test case ?



            Template form for benchmarks #41
            https://github.com/wfau/aglais/issues/41

                IF we run a benchmark, this is how we report the results.
                Makes it possible to compare results from different test runs.
                Did it get faster/slower, better/worse, and why ?


    Requirements

        Landing page

        Documentation
            Simple MD wiki pages ?
            Discovery - menus, contents, indexes
            Accuracy  - proof reading, code testing
            DeepLinking - Links from external pages to Zeppelin notebooks

        Login
            OAuth login using variety of providers, Google, GitHub etc.
            Option to use local username and password
            User account service.

                Name : Display name
                Mail : user@example.com
                User : identifier       <-- This is the unique identifier
                Pass : ########

        WorkSpace

            A workspace is a platform configuration for running a set of analyses.
            By default, users gets a copy of our standard workspace.
            The workspace contains a system configutation JSON document
            The Spark system is built from the system configutation.
                Cached images of standard configutations
                Power users can modify the configutation and build a new system image
                Automated build from JSON configuration document.
                This is NOT just a Spark/Kubernetes configuration renamed.
                Our code parses the JSON configuration to build a Spark/Kubernetes configuration for the image.
                We need to avoid straight pass though which would expose system config to end users.

            Workspace #1
                config - JSON document
                    Java
                        version
                        dependencies
                    Spark
                        version
                        dependencies
                    Python
                        version
                        dependencies
                    External binaries


            Workspace #2
                config - JSON document

            [Create new workspace]

                Workspace editor ...
                When we know more about what a workspace contains.

        DataSpace

            File browser UI


        Notebooks

            Notebooks in Zeppelin
            [GitHub]
                Import from GitHub
                    Select the repository, clone into local user space.
                    Execution controls - malware !
                Export to GitHub
                    Create a repository
                    Select a repository
                        Login to GitHub account
                        Remember the account details

                Sync with GitHub
                    Remember the GitHub location
                    Push/pull changes to/from git
                    How do we resolve conflicts ?

            [GitLab]
                Do all the same again for GitLab.
                If we design the GitHub version well and avoid hard codeing GitHub specifics, then this should be minor tweaks.

            [other]
                Wait for people to ask for this ...




        Curated examples
            Wiki page, and DeepLink into the notebooks
            How many of the Spark examples can we use ?

        External libraries

            AXS Astronomy extensions for Spark

                https://github.com/astronomy-commons/axs
                https://axs.readthedocs.io/en/latest/
                https://iopscience.iop.org/article/10.3847/1538-3881/ab2384

                This isn't just an 'external library', it is a full binary distribution of Spark.

                https://github.com/astronomy-commons/axs-spark
                    Mirror of Apache Spark with AXS patches
                    This branch is 2786 commits behind apache:master.

                    Comparing the branches
                        There isn’t anything to compare.
                        apache:master is up to date with all commits from astronomy-commons:master.

                    So does that mean that AXS patches have been merged into upstream ?



        Dependency version control #106
        https://github.com/wfau/aglais/issues/106

            How do we manage the version of Java
                How do we support different versions ?
                How hard is it to change the version ?
                How hard would it be to allow per user config ?

            How do we manage the version of Spark
                How do we support different versions ?
                How hard is it to change the version ?
                How hard would it be to allow per user config ?

            How do we manage the version of Python
                How do we support different versions ?
                How hard is it to change the version ?
                How hard would it be to allow per user config ?








