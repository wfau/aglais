#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

# -----------------------------------------------------

Experiments:

    Manila CSI version v1.18.0
    20200904-03-manila-csi.txt

    Test name : Harinabla

    Connecting to a dynamic share using application credentials
    FAIL - validation error.

    Connecting to a dynamic share using username/password
    PASS - works once we found the right secret to use.

# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --hostname kubernator \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --env "clustername=${CLUSTER_NAME:?}" \
        --volume "${HOME}/clouds.yaml:/etc/openstack/clouds.yaml:z" \
        atolmis/openstack-client \
        bash


# -----------------------------------------------------
# Get the connection details for our cluster.
#[user@kubernator]

    mkdir -p "${HOME}/.kube"
    openstack \
        --os-cloud "${cloudname:?}" \
        coe cluster config \
            "${clustername:?}" \
                --force \
                --dir "${HOME}/.kube"


    kubectl \
        cluster-info

    >   Kubernetes master is running at https://....
    >   Heapster is running at https://....
    >   CoreDNS is running at https://....


# -----------------------------------------------------
# Install YQ.
# TODO - add this to the kubernator image
#[user@kubernator]

    mkdir   "${HOME:?}/bin"
    wget -O "${HOME:?}/bin/yq" https://github.com/mikefarah/yq/releases/download/3.3.2/yq_linux_amd64
    chmod a+x "${HOME:?}/bin/yq"


# -----------------------------------------------------
# Create our Secret set using application credentials.
#[user@kubernator]

    osauthurl=$(
        yq r /etc/openstack/clouds.yaml \
            'clouds.gaia-prod.auth.auth_url'
        )

    osregion=$(
        yq r /etc/openstack/clouds.yaml \
            'clouds.gaia-prod.region_name'
        )

    oscredentialID=$(
        yq r /etc/openstack/clouds.yaml \
            'clouds.gaia-prod.auth.application_credential_id'
        )

    oscredentialsecret=$(
        yq r /etc/openstack/clouds.yaml \
            'clouds.gaia-prod.auth.application_credential_secret'
        )

    cat > "/tmp/harinabla-secrets.yaml" << EOF
apiVersion: v1
kind: Secret
metadata:
  name: harinabla-secrets
  namespace: default
stringData:
  os-authURL: "${osauthurl:?}"
  os-region: "${osregion:?}"
  os-applicationCredentialID: "${oscredentialID:?}"
  os-applicationCredentialSecret: "${oscredentialsecret:?}"
EOF

    kubectl create \
        --filename "/tmp/harinabla-secrets.yaml"

    kubectl describe \
        secret \
            harinabla-secrets


    >   Name:         harinabla-secrets
    >   Namespace:    default
    >   Labels:       <none>
    >   Annotations:  <none>
    >
    >   Type:  Opaque
    >
    >   Data
    >   ====
    >   os-applicationCredentialID:      32 bytes
    >   os-applicationCredentialSecret:  35 bytes
    >   os-authURL:                      47 bytes
    >   os-region:                       9 bytes


# -----------------------------------------------------
# Create our StorageClass, using our secrets.
#[user@kubernator]

    cat > "/tmp/harinabla-class.yaml" << EOF
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: harinabla-class
provisioner: cephfs.manila.csi.openstack.org
parameters:
  type: cephfsnativetype

  csi.storage.k8s.io/provisioner-secret-name: harinabla-secrets
  csi.storage.k8s.io/provisioner-secret-namespace: default
  csi.storage.k8s.io/node-stage-secret-name: harinabla-secrets
  csi.storage.k8s.io/node-stage-secret-namespace: default
  csi.storage.k8s.io/node-publish-secret-name: harinabla-secrets
  csi.storage.k8s.io/node-publish-secret-namespace: default
EOF

    kubectl create \
        --filename "/tmp/harinabla-class.yaml"

    kubectl describe \
        storageclass \
            harinabla-class

    >   Name:                  harinabla-class
    >   IsDefaultClass:        No
    >   Annotations:           <none>
    >   Provisioner:           cephfs.manila.csi.openstack.org
    >   Parameters:            csi.storage.k8s.io/node-publish-secret-name=harinabla-secrets,csi.storage.k8s.io/node-publish-secret-namespace=default,csi.storage.k8s.io/node-stage-secret-name=harinabla-secrets,csi.storage.k8s.io/node-stage-secret-namespace=default,csi.storage.k8s.io/provisioner-secret-name=harinabla-secrets,csi.storage.k8s.io/provisioner-secret-namespace=default,type=cephfsnativetype
    >   AllowVolumeExpansion:  <unset>
    >   MountOptions:          <none>
    >   ReclaimPolicy:         Delete
    >   VolumeBindingMode:     Immediate
    >   Events:                <none>


# -----------------------------------------------------
# Create a PersistentVolumeClaim that refers to our StorageClass.
#[user@kubernator]

    cat > "/tmp/harinabla-claim.yaml" << EOF
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: harinabla-claim
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 2Gi
  storageClassName: harinabla-class
EOF

    kubectl apply \
        --filename "/tmp/harinabla-claim.yaml"

    kubectl describe \
        PersistentVolumeClaim \
            harinabla-claim

    >   Name:          harinabla-claim
    >   Namespace:     default
    >   StorageClass:  harinabla-class
    >   Status:        Pending
    >   Volume:
    >   Labels:        <none>
    >   Annotations:   kubectl.kubernetes.io/last-applied-configuration:
    >                    {"apiVersion":"v1","kind":"PersistentVolumeClaim","metadata":{"annotations":{},"name":"harinabla-claim","namespace":"default"},"spec":{"ac...
    >                  volume.beta.kubernetes.io/storage-provisioner: cephfs.manila.csi.openstack.org
    >   Finalizers:    [kubernetes.io/pvc-protection]
    >   Capacity:
    >   Access Modes:
    >   VolumeMode:    Filesystem
    >   Mounted By:    <none>
    >   Events:
    >     Type     Reason                Age              From                                                                                                       Message
    >     ----     ------                ----             ----                                                                                                       -------
    >     Normal   ExternalProvisioning  0s (x3 over 0s)  persistentvolume-controller                                                                                waiting for a volume to be created, either by external provisioner "cephfs.manila.csi.openstack.org" or manually created by system administrator
    >     Normal   Provisioning          0s (x2 over 0s)  cephfs.manila.csi.openstack.org_csi-manila-cephfs-controllerplugin-0_6efaf702-6367-42ce-ac0d-bd662d082dd8  External provisioner is provisioning volume for claim "default/harinabla-claim"
    >     Warning  ProvisioningFailed    0s (x2 over 0s)  cephfs.manila.csi.openstack.org_csi-manila-cephfs-controllerplugin-0_6efaf702-6367-42ce-ac0d-bd662d082dd8  failed to provision volume with StorageClass "harinabla-class": rpc error: code = InvalidArgument desc = invalid OpenStack secrets: parameter 'os-authURL' requires exactly one of [os-password os-trustID] parameters


# -----------------------------------------------------
# Delete our PersistentVolumeClaim, StorageClass and Secret.
#[user@kubernator]

    kubectl \
        delete persistentvolumeclaim \
            harinabla-claim

    kubectl \
        delete storageclass \
            harinabla-class

    kubectl \
        delete secret \
            harinabla-secrets

# -----------------------------------------------------
# Create our Secret set using username and password.
#[user@kubernator]

    osdomain=default
    osproject=iris-gaia-prod

    osauthurl=$(
        yq r /etc/openstack/clouds.yaml \
            'clouds.gaia-prod-tester.auth.auth_url'
        )

    osregion=$(
        yq r /etc/openstack/clouds.yaml \
            'clouds.gaia-prod-tester.region_name'
        )

    osusername=$(
        yq r /etc/openstack/clouds.yaml \
            'clouds.gaia-prod-tester.auth.username'
        )

    ospassword=$(
        yq r /etc/openstack/clouds.yaml \
            'clouds.gaia-prod-tester.auth.password'
        )

    cat > "/tmp/harinabla-secrets.yaml" << EOF
apiVersion: v1
kind: Secret
metadata:
  name: harinabla-secrets
  namespace: default
stringData:
  os-authURL:     "${osauthurl:?}"
  os-region:      "${osregion:?}"
  os-domainID:    "${osdomain:?}"
  os-projectName: "${osproject:?}"
  os-userName:    "${osusername:?}"
  os-password:    "${ospassword:?}"
EOF

    kubectl create \
        --filename "/tmp/harinabla-secrets.yaml"

    kubectl describe \
        secret \
            harinabla-secrets

    >   ....
    >   ....
    >   Data
    >   ====
    >   os-authURL:      47 bytes
    >   os-domainID:     7 bytes
    >   os-password:     37 bytes
    >   os-projectName:  14 bytes
    >   os-region:       9 bytes
    >   os-userName:     17 bytes


# -----------------------------------------------------
# Create our StorageClass and PersistentVolumeClaim.
#[user@kubernator]

    kubectl apply \
        --filename "/tmp/harinabla-class.yaml"

    kubectl apply \
        --filename "/tmp/harinabla-claim.yaml"

    kubectl describe \
        persistentvolumeclaim \
            harinabla-claim


    >   ....
    >   ....
    >   Events:
    >     Type     Reason                Age              From                                                                                                       Message
    >     ----     ------                ----             ----                                                                                                       -------
    >     Normal   ExternalProvisioning  4s (x3 over 4s)  persistentvolume-controller                                                                                waiting for a volume to be created, either by external provisioner "cephfs.manila.csi.openstack.org" or manually created by system administrator
    >     Normal   Provisioning          2s (x3 over 4s)  cephfs.manila.csi.openstack.org_csi-manila-cephfs-controllerplugin-0_6efaf702-6367-42ce-ac0d-bd662d082dd8  External provisioner is provisioning volume for claim "default/harinabla-claim"
    >     Warning  ProvisioningFailed    2s (x3 over 3s)  cephfs.manila.csi.openstack.org_csi-manila-cephfs-controllerplugin-0_6efaf702-6367-42ce-ac0d-bd662d082dd8  failed to provision volume with StorageClass "harinabla-class": rpc error: code = Unauthenticated desc = failed to create Manila v2 client: failed to authenticate: Authentication failed


# -----------------------------------------------------
# Delete our PersistentVolumeClaim and StorageClass.
#[user@kubernator]

    kubectl \
        delete persistentvolumeclaim \
            harinabla-claim

    kubectl \
        delete storageclass \
            harinabla-class


# -----------------------------------------------------
# Create our StorageClass with os-trustee secrets.
# This comes from the original Manila provisioner examples from John.
#[user@kubernator]

    cat > "/tmp/harinabla-class.yaml" << EOF
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: harinabla-class
provisioner: cephfs.manila.csi.openstack.org
parameters:
  type: cephfsnativetype

  csi.storage.k8s.io/provisioner-secret-name: os-trustee
  csi.storage.k8s.io/provisioner-secret-namespace: kube-system
  csi.storage.k8s.io/node-stage-secret-name: os-trustee
  csi.storage.k8s.io/node-stage-secret-namespace: kube-system
  csi.storage.k8s.io/node-publish-secret-name: os-trustee
  csi.storage.k8s.io/node-publish-secret-namespace: kube-system
EOF

    kubectl create \
        --filename "/tmp/harinabla-class.yaml"

    kubectl describe \
        storageclass \
            harinabla-class

    >   Name:                  harinabla-class
    >   IsDefaultClass:        No
    >   Annotations:           <none>
    >   Provisioner:           cephfs.manila.csi.openstack.org
    >   Parameters:            csi.storage.k8s.io/node-publish-secret-name=os-trustee,csi.storage.k8s.io/node-publish-secret-namespace=kube-system,csi.storage.k8s.io/node-stage-secret-name=os-trustee,csi.storage.k8s.io/node-stage-secret-namespace=kube-system,csi.storage.k8s.io/provisioner-secret-name=os-trustee,csi.storage.k8s.io/provisioner-secret-namespace=kube-system,type=cephfsnativetype
    >   AllowVolumeExpansion:  <unset>
    >   MountOptions:          <none>
    >   ReclaimPolicy:         Delete
    >   VolumeBindingMode:     Immediate
    >   Events:                <none>


# -----------------------------------------------------
# Create a PersistentVolumeClaim that refers to our StorageClass.
#[user@kubernator]

    cat > "/tmp/harinabla-claim.yaml" << EOF
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: harinabla-claim
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 2Gi
  storageClassName: harinabla-class
EOF

    kubectl apply \
        --filename "/tmp/harinabla-claim.yaml"

    kubectl describe \
        PersistentVolumeClaim \
            harinabla-claim

    >   ....
    >   ....
    >   Events:
    >     Type     Reason                 Age                    From                                                                                                       Message
    >     ----     ------                 ----                   ----                                                                                                       -------
    >     Normal   ExternalProvisioning   2m28s (x2 over 2m28s)  persistentvolume-controller                                                                                waiting for a volume to be created, either by external provisioner "cephfs.manila.csi.openstack.org" or manually created by system administrator
    >     Warning  ProvisioningFailed     2m18s                  cephfs.manila.csi.openstack.org_csi-manila-cephfs-controllerplugin-0_6efaf702-6367-42ce-ac0d-bd662d082dd8  failed to provision volume with StorageClass "harinabla-class": rpc error: code = DeadlineExceeded desc = context deadline exceeded
    >     Normal   Provisioning           2m17s (x2 over 2m28s)  cephfs.manila.csi.openstack.org_csi-manila-cephfs-controllerplugin-0_6efaf702-6367-42ce-ac0d-bd662d082dd8  External provisioner is provisioning volume for claim "default/harinabla-claim"
    >     Normal   ProvisioningSucceeded  2m16s                  cephfs.manila.csi.openstack.org_csi-manila-cephfs-controllerplugin-0_6efaf702-6367-42ce-ac0d-bd662d082dd8  Successfully provisioned volume pvc-260e0edd-1485-4605-aaad-ce6e43d1a2f4


    >   ....
    >   ....
    >   I0906 00:33:02.367018       1 controller.go:1281] provision "default/harinabla-claim" class "harinabla-class": volume "pvc-260e0edd-1485-4605-aaad-ce6e43d1a2f4" provisioned
    >   I0906 00:33:02.367147       1 controller.go:1298] provision "default/harinabla-claim" class "harinabla-class": succeeded
    >   I0906 00:33:02.367165       1 volume_store.go:154] Saving volume pvc-260e0edd-1485-4605-aaad-ce6e43d1a2f4
    >   I0906 00:33:02.371908       1 volume_store.go:157] Volume pvc-260e0edd-1485-4605-aaad-ce6e43d1a2f4 saved
    >   I0906 00:33:02.371957       1 controller.go:1014] Claim processing succeeded, removing PVC 260e0edd-1485-4605-aaad-ce6e43d1a2f4 from claims in progress
    >   I0906 00:33:02.371981       1 event.go:255] Event(v1.ObjectReference{Kind:"PersistentVolumeClaim", Namespace:"default", Name:"harinabla-claim", UID:"260e0edd-1485-4605-aaad-ce6e43d1a2f4", APIVersion:"v1", ResourceVersion:"731733", FieldPath:""}): type: 'Normal' reason: 'ProvisioningSucceeded' Successfully provisioned volume pvc-260e0edd-1485-4605-aaad-ce6e43d1a2f4

    #
    # OK - so the right secret to use was 'kube-system/os-trustee'.
    # Which is not findable !
    #
    # The only refernces I can find are here:
    #   https://github.com/kubernetes/cloud-provider-openstack/blob/release-1.17/docs/using-manila-provisioner.md
    # Which refers to "os-trustID, os-trusteeID and os-trusteePassword", but it doesn't say what they are or where to get them.
    #
    # and here:
    # https://clouddocs.web.cern.ch/containers/tutorials/cephfs.html
    # Which refers to "osSecretName: os-trustee in the kube-system namespace", but it doesn't say what they are.
    #

    #
    # OK - try going back and using these credentials in the static allocation test.
    #


# -----------------------------------------------------
# Create a Pod that mounts the volume.
#[user@kubernator]


    cat > /tmp/harinabla-pod.yaml << EOF
kind: Pod
apiVersion: v1
metadata:
  name: harinabla-pod
  namespace: default
spec:
  volumes:
    - name: share-data
      persistentVolumeClaim:
        claimName: harinabla-claim
    - name: local-data
      emptyDir: {}
  containers:
    - name: harinabla-container
      image: 'fedora:latest'
      volumeMounts:
        - name: share-data
          mountPath: /share-data
        - name: local-data
          mountPath: /local-data
      command: ["/bin/sh"]
      args:
        - "-c"
        - >-
          while true; do
          date >> /share-data/\${HOSTNAME}.log;
          sleep 1;
          done
EOF

    kubectl \
        apply \
            --filename /tmp/harinabla-pod.yaml

    kubectl \
        describe pod \
            harinabla-pod

    >   ....
    >   ....
    >                    node.kubernetes.io/unreachable:NoExecute for 300s
    >   Events:
    >     Type    Reason     Age        From                                            Message
    >     ----    ------     ----       ----                                            -------
    >     Normal  Scheduled  <unknown>  default-scheduler                               Successfully assigned default/harinabla-pod to tiberius-20200904-nj46yxjgkhty-node-3
    >     Normal  Pulling    13s        kubelet, tiberius-20200904-nj46yxjgkhty-node-3  Pulling image "fedora:latest"
    >     Normal  Pulled     6s         kubelet, tiberius-20200904-nj46yxjgkhty-node-3  Successfully pulled image "fedora:latest"
    >     Normal  Created    5s         kubelet, tiberius-20200904-nj46yxjgkhty-node-3  Created container harinabla-container
    >     Normal  Started    5s         kubelet, tiberius-20200904-nj46yxjgkhty-node-3  Started container harinabla-container


# -----------------------------------------------------
# Login to our Pod to check.
#[user@kubernator]

    kubectl exec \
        --tty \
        --stdin \
        harinabla-pod \
        -- \
            /bin/bash

            tail -f /share-data/${HOSTNAME}.log

    >   ....
    >   ....
    >   Sun Sep  6 01:30:04 UTC 2020
    >   Sun Sep  6 01:30:05 UTC 2020
    >   Sun Sep  6 01:30:06 UTC 2020
    >   Sun Sep  6 01:30:07 UTC 2020


# -----------------------------------------------------
# -----------------------------------------------------
# Describe all the components
#[user@kubernator]

    kubectl describe \
        secret \
            harinabla-secrets

    >   Name:         harinabla-secrets
    >   Namespace:    default
    >   Labels:       <none>
    >   Annotations:  <none>
    >
    >   Type:  Opaque
    >
    >   Data
    >   ====
    >   os-authURL:      47 bytes
    >   os-domainID:     7 bytes
    >   os-password:     37 bytes
    >   os-projectName:  14 bytes
    >   os-region:       9 bytes
    >   os-userName:     17 bytes


    kubectl describe \
        storageclass \
            harinabla-class

    >   Name:                  harinabla-class
    >   IsDefaultClass:        No
    >   Annotations:           <none>
    >   Provisioner:           cephfs.manila.csi.openstack.org
    >   Parameters:            csi.storage.k8s.io/node-publish-secret-name=os-trustee,csi.storage.k8s.io/node-publish-secret-namespace=kube-system,csi.storage.k8s.io/node-stage-secret-name=os-trustee,csi.storage.k8s.io/node-stage-secret-namespace=kube-system,csi.storage.k8s.io/provisioner-secret-name=os-trustee,csi.storage.k8s.io/provisioner-secret-namespace=kube-system,type=cephfsnativetype
    >   AllowVolumeExpansion:  <unset>
    >   MountOptions:          <none>
    >   ReclaimPolicy:         Delete
    >   VolumeBindingMode:     Immediate
    >   Events:                <none>


    kubectl describe \
        persistentvolumeclaim \
            harinabla-claim

    >   Name:          harinabla-claim
    >   Namespace:     default
    >   StorageClass:  harinabla-class
    >   Status:        Bound
    >   Volume:        pvc-260e0edd-1485-4605-aaad-ce6e43d1a2f4
    >   Labels:        <none>
    >   Annotations:   kubectl.kubernetes.io/last-applied-configuration:
    >                    {"apiVersion":"v1","kind":"PersistentVolumeClaim","metadata":{"annotations":{},"name":"harinabla-claim","namespace":"default"},"spec":{"ac...
    >                  pv.kubernetes.io/bind-completed: yes
    >                  pv.kubernetes.io/bound-by-controller: yes
    >                  volume.beta.kubernetes.io/storage-provisioner: cephfs.manila.csi.openstack.org
    >   Finalizers:    [kubernetes.io/pvc-protection]
    >   Capacity:      2Gi
    >   Access Modes:  RWX
    >   VolumeMode:    Filesystem
    >   Mounted By:    harinabla-pod
    >   Events:        <none>


    kubectl describe \
        pod \
            harinabla-pod

    >   Name:         harinabla-pod
    >   Namespace:    default
    >   Node:         tiberius-20200904-nj46yxjgkhty-node-3/10.0.0.176
    >   Start Time:   Sun, 06 Sep 2020 01:22:55 +0000
    >   Labels:       <none>
    >   Annotations:  kubectl.kubernetes.io/last-applied-configuration:
    >                   {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{},"name":"harinabla-pod","namespace":"default"},"spec":{"containers":[{"args":[...
    >   Status:       Running
    >   IP:           10.100.4.8
    >   Containers:
    >     harinabla-container:
    >       Container ID:  docker://06002ca9243675608f05495c62af612aa3e15ab1ac3c2f6c342441d04b503410
    >       Image:         fedora:latest
    >       Image ID:      docker-pullable://docker.io/fedora@sha256:d6a6d60fda1b22b6d5fe3c3b2abe2554b60432b7b215adc11a2b5fae16f50188
    >       Port:          <none>
    >       Host Port:     <none>
    >       Command:
    >         /bin/sh
    >       Args:
    >         -c
    >         while true; do date >> /share-data/${HOSTNAME}.log; sleep 1; done
    >       State:          Running
    >         Started:      Sun, 06 Sep 2020 01:23:06 +0000
    >       Ready:          True
    >       Restart Count:  0
    >       Environment:    <none>
    >       Mounts:
    >         /local-data from local-data (rw)
    >         /share-data from share-data (rw)
    >         /var/run/secrets/kubernetes.io/serviceaccount from default-token-f6s86 (ro)
    >   Conditions:
    >     Type              Status
    >     Initialized       True
    >     Ready             True
    >     ContainersReady   True
    >     PodScheduled      True
    >   Volumes:
    >     share-data:
    >       Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
    >       ClaimName:  harinabla-claim
    >       ReadOnly:   false
    >     local-data:
    >       Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    >       Medium:
    >       SizeLimit:  <unset>
    >     default-token-f6s86:
    >       Type:        Secret (a volume populated by a Secret)
    >       SecretName:  default-token-f6s86
    >       Optional:    false
    >   QoS Class:       BestEffort
    >   Node-Selectors:  <none>
    >   Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
    >                    node.kubernetes.io/unreachable:NoExecute for 300s
    >   Events:
    >     Type    Reason     Age        From                                            Message
    >     ----    ------     ----       ----                                            -------
    >     Normal  Scheduled  <unknown>  default-scheduler                               Successfully assigned default/harinabla-pod to tiberius-20200904-nj46yxjgkhty-node-3
    >     Normal  Pulling    24m        kubelet, tiberius-20200904-nj46yxjgkhty-node-3  Pulling image "fedora:latest"
    >     Normal  Pulled     24m        kubelet, tiberius-20200904-nj46yxjgkhty-node-3  Successfully pulled image "fedora:latest"
    >     Normal  Created    24m        kubelet, tiberius-20200904-nj46yxjgkhty-node-3  Created container harinabla-container
    >     Normal  Started    24m        kubelet, tiberius-20200904-nj46yxjgkhty-node-3  Started container harinabla-container








