#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#


    Target:

        Run the Ansible deploy
        Updated to move more into the create-all script.

    Result:

        Success


# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --env "clouduser=${AGLAIS_USER:?}" \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/experiments/openstack:/openstack:ro,z" \
        --volume "${AGLAIS_CODE:?}/experiments/hadoop-yarn:/hadoop-yarn:ro,z" \
        atolmis/ansible-client:latest \
        bash

# -----------------------------------------------------
# Delete everything.
#[root@ansibler]

    /openstack/bin/delete-all.sh \
        "${cloudname:?}"

    >   ....
    >   ....


# -----------------------------------------------------
# Run the main Ansible deployment.
#[root@ansibler]

    /hadoop-yarn/bin/create-all.sh \
        "${cloudname:?}"

    >   ....
    >   ....


# -----------------------------------------------------
# Run the SparkPi example from the Spark install instructtions.
# https://spark.apache.org/docs/3.0.0-preview2/running-on-yarn.html#launching-spark-on-yarn
#[root@ansibler]

    ssh master01 \
        '
        cd "${SPARK_HOME:?}"

        spark-submit \
            --class org.apache.spark.examples.SparkPi \
            --master yarn \
            --deploy-mode cluster \
            --driver-memory 1g \
            --executor-memory 1g \
            --executor-cores 1 \
            examples/jars/spark-examples*.jar \
                10
        '

    >   2020-11-17 12:26:16,792 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
    >   2020-11-17 12:26:16,855 INFO client.RMProxy: Connecting to ResourceManager at master01/10.10.0.55:8032
    >   2020-11-17 12:26:17,130 INFO yarn.Client: Requesting a new application from cluster with 8 NodeManagers
    >   ....
    >   ....
    >   2020-11-17 12:26:35,887 INFO yarn.Client: Application report for application_1605610085942_0001 (state: RUNNING)
    >   2020-11-17 12:26:36,890 INFO yarn.Client: Application report for application_1605610085942_0001 (state: RUNNING)
    >   2020-11-17 12:26:37,892 INFO yarn.Client: Application report for application_1605610085942_0001 (state: FINISHED)
    >   2020-11-17 12:26:37,892 INFO yarn.Client:
    >   	 client token: N/A
    >   	 diagnostics: N/A
    >   	 ApplicationMaster host: worker01
    >   	 ApplicationMaster RPC port: 46357
    >   	 queue: default
    >   	 start time: 1605615982579
    >   	 final status: SUCCEEDED
    >   	 tracking URL: http://master01:8088/proxy/application_1605610085942_0001/
    >   	 user: fedora
    >   2020-11-17 12:26:37,901 INFO util.ShutdownHookManager: Shutdown hook called
    >   2020-11-17 12:26:37,904 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-bed6bd12-97ea-4e5e-b60f-dc25479d06dc
    >   2020-11-17 12:26:37,906 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-14e38578-9d2e-4d8e-be2f-f2ca19e3c121


# -----------------------------------------------------
# Login to the worker node to test the mount.
#[root@ansibler]

    ssh worker01 \
        '
        date
        hostname
        echo "----"
        df -h  /data/gaia/dr2
        '

    >   Tue Nov 17 12:27:25 UTC 2020
    >   aglais-20201117-worker01.novalocal
    >   ----
    >   Filesystem      Size  Used Avail Use% Mounted on
    >   ceph-fuse       512G  473G   40G  93% /data/gaia/dr2








