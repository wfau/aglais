#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

    # Deleted old cluster.
    # notes/zrq/20200718-03-openstack-delete.txt

    # Created new cluster.
    # notes/zrq/20200718-04-terraform-create.txt

    # Run the K8s dashboard.
    # notes/zrq/20200706-03-k8s-dashboard.txt


# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --hostname kubernator \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --env "clustername=${MAGNUM_CLUSTER:?}" \
        --volume "${HOME}/clouds.yaml:/etc/openstack/clouds.yaml:z" \
        --volume "${AGLAIS_CODE}/experiments/zrq/kubernetes:/kubernetes:z" \
        --volume "${ZEPPELIN_CODE}:/zeppelin:z" \
        atolmis/openstack-client \
        bash


# -----------------------------------------------------
# Get the connection details for our cluster.
#[user@kubernator]

    mkdir -p "${HOME}/.kube/${clustername:?}"
    openstack \
        --os-cloud "${cloudname:?}-super" \
        coe cluster config \
            "${clustername:?}" \
                --force \
                --dir "${HOME}/.kube/${clustername:?}"

    >   'SHELL'


# -----------------------------------------------------
# Check kubectl can get the connection details for our cluster.
#[user@kubernator]

    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        cluster-info

    >   Kubernetes master is running at ....
    >   Heapster is running at ....
    >   CoreDNS is running at ....


# -----------------------------------------------------
# Install config editing tools.
#[user@kubernator]

    # TODO - add this to the kubernator image
    mkdir -p "${HOME:?}/bin"
    wget  -O "${HOME:?}/bin/yq" https://github.com/mikefarah/yq/releases/download/3.3.2/yq_linux_amd64
    chmod a+x "${HOME:?}/bin/yq"


# -----------------------------------------------------
# Update our Zeppelin deployment template.
#[user@kubernator]

    #
    # Skipping this - it isn't used by kubectl.
    #

#    zpimage='aglais/zeppelin:latest'
#    dkimage='aglais/zeppelin:latest'
#    spimage='aglais/spark:latest'
#
#    filepath=/zeppelin/conf
#    filename=zeppelin-site.xml
#    backup=${filepath:?}/${filename:?}.backup
#    target=${filepath:?}/${filename:?}.template
#
#    mv --force "${target:?}" "${backup:?}"
#
#    xmlstarlet edit \
#         --update "//property[name='zeppelin.k8s.container.image']/value" \
#         --value  "${zpimage:?}" \
#         --update "//property[name='zeppelin.k8s.spark.container.image']/value" \
#         --value  "${spimage:?}" \
#         --update "//property[name='zeppelin.docker.container.image']/value" \
#         --value  "${dkimage:?}" \
#        "${original:?}" \
#    | tee "${template:?}"
#
    #
    # This messes with the formatting in the dcoument.
    # 1. Deletes blank lines.
    # 2. Changes tabs to space.
    # 3. Changes <value></value> to </value>

# -----------------------------------------------------
# Copy our Zeppelin server configuration.
#[user@kubernator]

    zpimage='aglais/zeppelin:latest'
    dkimage='aglais/zeppelin:latest'
    spimage='aglais/pyspark-mod:latest'

    source=/zeppelin/k8s/zeppelin-server.yaml
    deploy=/tmp/zeppelin-server.yaml

    cp "${source:?}" "${deploy:?}"

    yq write \
        --inplace \
        --doc 0 \
        "${deploy:?}" \
        'data.ZEPPELIN_K8S_CONTAINER_IMAGE' \
            "${zpimage:?}"

    yq write \
        --inplace \
        --doc 0 \
        "${deploy:?}" \
        'data.ZEPPELIN_K8S_SPARK_CONTAINER_IMAGE' \
            "${spimage:?}"

    yq write \
        --inplace \
        --doc 2 \
        "${deploy:?}" \
        'spec.template.spec.containers.[0].image' \
            "${zpimage:?}"


    diff \
        --ignore-all-space \
        "${source:?}" \
        "${deploy:?}"


    >   31,32c31,32
    >   <   ZEPPELIN_K8S_SPARK_CONTAINER_IMAGE: spark:2.4.5
    >   <   ZEPPELIN_K8S_CONTAINER_IMAGE: apache/zeppelin:0.9.0-SNAPSHOT
    >   ---
    >   >   ZEPPELIN_K8S_SPARK_CONTAINER_IMAGE: aglais/pyspark-mod:latest
    >   >   ZEPPELIN_K8S_CONTAINER_IMAGE: aglais/zeppelin:latest
    >   118c118
    >   <         image: apache/zeppelin:0.9.0-SNAPSHOT
    >   ---
    >   >           image: aglais/zeppelin:latest
    >   ....
    >   ....

    # Some extra changes due to the way that jq outputs YAML.
    # Note - the jq output is syntactically more correct.

# -----------------------------------------------------
# Deploy Zeppelin using our template.
#[user@kubernator]

    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        apply \
            --filename "${deploy:?}"

    >   configmap/zeppelin-server-conf-map created
    >   configmap/zeppelin-server-conf created
    >   deployment.apps/zeppelin-server created
    >   service/zeppelin-server created
    >   serviceaccount/zeppelin-server created
    >   role.rbac.authorization.k8s.io/zeppelin-server-role created
    >   rolebinding.rbac.authorization.k8s.io/zeppelin-server-role-binding created


# -----------------------------------------------------
# Expose Zeppelin with a LoadBalancer.
# The LoadBalancer provides access to HTTP on port 80.
#[user@kubernator]

    cat > /tmp/balancer.yaml << EOF
---
kind: Service
apiVersion: v1
metadata:
  name: zeppelin-external
spec:
  ports:
    - name: http
      port: 80
  selector:
    app.kubernetes.io/name: zeppelin-server
  type: LoadBalancer
EOF

    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        apply \
            --filename /tmp/balancer.yaml

    >   service/zeppelin-external created


# -----------------------------------------------------
# Get the external address.
#[user@kubernator]

    watch
        kubectl \
            --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
            get service \
                zeppelin-external

    >   NAME                TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
    >   zeppelin-external   LoadBalancer   10.254.201.110   <pending>     80:31170/TCP   7s

    >   NAME                TYPE           CLUSTER-IP       EXTERNAL-IP       PORT(S)        AGE
    >   zeppelin-external   LoadBalancer   10.254.201.110   128.232.227.159   80:31170/TCP   118s


    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        get service \
            --output json \
            zeppelin-external \
    | jq -r '.status.loadBalancer.ingress[0].ip'

    >   128.232.227.159


# -----------------------------------------------------
# -----------------------------------------------------
# Connect to the endpoint, logged in as anonymous.
#[user@desktop]

    firefox http://128.232.227.159/ &


# -----------------------------------------------------
# -----------------------------------------------------
# Create a new MD note.
#[anon-zeppelin]

    %md
    ## Welcome to my world

    #
    # Yay - works :-)
    # Takes several seconds to start the interpreter.
    # Possibly mitigated by having a local repository.
    #


# -----------------------------------------------------
# Create a new Python note.
#[anon-zeppelin]

    %python
    print (1 + 1)

    #
    # Yay - works :-)
    # Now that the image is downloaded delay is minimal.
    #


# -----------------------------------------------------
# Create a PySpark note.
#[anon-zeppelin]

%spark.pyspark
import random
NUM_SAMPLES = 1000

def inside(p):
    x, y = random.random(), random.random()
    return x*x + y*y < 1

count = sc.parallelize(
    range(
        0,
        NUM_SAMPLES
        )
    ).filter(
        inside
        ).count()

guess = 4.0 * count / NUM_SAMPLES
print("Pi is roughly {}".format(guess))

    >   Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
    >   : org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times,
    >       most recent failure:
    >           Lost task 0.3 in stage 0.0 (TID 6, 10.100.1.14, executor 1):
    >               org.apache.spark.api.python.PythonException: Traceback (most recent call last):....
    >   ....
    >   "Exception: Python in worker has different version 2.7 than that in driver 3.7,
    >   PySpark cannot run with different minor versions.Please check environment variables
    >   PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set."


    #
    # Two instances of PySpark container image.
    # One has Python 2.7, the other has Python 3.7.
    #


# -----------------------------------------------------
# Check our active pods.
#[user@kubernator]

    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        get pods

    >   NAME                               READY   STATUS    RESTARTS   AGE
    >   md-vyritr                          1/1     Running   0          18m
    >   python-ukfdfo                      1/1     Running   0          16m
    >   spark-zwwxrb                       1/1     Running   0          14m
    >   zeppelin-a82feb73906cfda8-exec-1   1/1     Running   0          13m
    >   zeppelin-server-d78dc55f9-9rmwl    3/3     Running   0          28m

    # Python interpreter

    podname=python-ukfdfo
    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        get pod \
            --output json \
            "${podname:?}" \
    | jq -r '.spec.containers[].image'

    >   aglais/zeppelin:latest


    # Spark interpreter

    podname=spark-zwwxrb
    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        get pod \
            --output json \
            "${podname:?}" \
    | jq -r '.spec.containers[].image'

    >   aglais/zeppelin:latest

    # Spark worker

    podname=zeppelin-a82feb73906cfda8-exec-1
    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        get pod \
            --output json \
            "${podname:?}" \
    | jq -r '.spec.containers[].image'

    >   aglais/pyspark-mod:latest


# -----------------------------------------------------
# Check the default Python version on the Spark pods.
#[user@kubernator]

    # Spark interpreter

    podname=spark-zwwxrb
    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        exec \
            "${podname:?}" \
            -- \
            python \
                --version

    >   Python 3.7.3

    # Spark worker

    podname=zeppelin-a82feb73906cfda8-exec-1
    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        exec \
            "${podname:?}" \
            -- \
            python \
                --version

    >   Python 2.7.16


# -----------------------------------------------------
# Check the Python config on the Spark worker.
#[user@kubernator]

    podname=zeppelin-a82feb73906cfda8-exec-1
    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        exec \
            "${podname:?}" \
            -- \
            which \
                python

    >   /usr/bin/python


    podname=zeppelin-a82feb73906cfda8-exec-1
    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        exec \
            "${podname:?}" \
            -- \
            ls -al $(\
                which \
                    python \
                )

    >   lrwxrwxrwx. 1 root root 7 Mar  4  2019 /usr/bin/python -> python2


    podname=zeppelin-a82feb73906cfda8-exec-1
    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        exec \
            "${podname:?}" \
            -- \
                ls -al /usr/bin

    >   ....
    >   ....
    >   -rwxr-xr-x. 1 root root      4392 Mar 31  2019 ptargrep
    >   -rwxr-xr-x. 1 root root     76704 Feb 28  2019 ptx
    >   -rwxr-xr-x. 1 root root      7806 Mar 26  2019 py3clean
    >   -rwxr-xr-x. 1 root root     12113 Mar 26  2019 py3compile
    >   lrwxrwxrwx. 1 root root        31 Mar 26  2019 py3versions -> ../share/python3/py3versions.py
    >   lrwxrwxrwx. 1 root root        26 Mar  8  2019 pybuild -> ../share/dh-python/pybuild
    >   -rwxr-xr-x. 1 root root      4124 Mar  4  2019 pyclean
    >   -rwxr-xr-x. 1 root root     11895 Mar  4  2019 pycompile
    >   lrwxrwxrwx. 1 root root         6 Mar  4  2019 pydoc -> pydoc2
    >   lrwxrwxrwx. 1 root root         8 Mar  4  2019 pydoc2 -> pydoc2.7
    >   -rwxr-xr-x. 1 root root        79 Oct 10  2019 pydoc2.7
    >   lrwxrwxrwx. 1 root root         8 Mar 26  2019 pydoc3 -> pydoc3.7
    >   -rwxr-xr-x. 1 root root        79 Dec 20  2019 pydoc3.7
    >   lrwxrwxrwx. 1 root root        10 Mar  4  2019 pygettext -> pygettext2
    >   lrwxrwxrwx. 1 root root        12 Mar  4  2019 pygettext2 -> pygettext2.7
    >   -rwxr-xr-x. 1 root root     22082 Oct 10  2019 pygettext2.7
    >   lrwxrwxrwx. 1 root root        12 Mar 26  2019 pygettext3 -> pygettext3.7
    >   -rwxr-xr-x. 1 root root     21547 Dec 20  2019 pygettext3.7
    >   lrwxrwxrwx. 1 root root         7 Mar  4  2019 python -> python2
    >   lrwxrwxrwx. 1 root root        14 Mar  4  2019 python-config -> python2-config
    >   lrwxrwxrwx. 1 root root         9 Mar  4  2019 python2 -> python2.7
    >   lrwxrwxrwx. 1 root root        16 Mar  4  2019 python2-config -> python2.7-config
    >   -rwxr-xr-x. 1 root root   3689352 Oct 10  2019 python2.7
    >   lrwxrwxrwx. 1 root root        33 Oct 10  2019 python2.7-config -> x86_64-linux-gnu-python2.7-config
    >   lrwxrwxrwx. 1 root root         9 Mar 26  2019 python3 -> python3.7
    >   lrwxrwxrwx. 1 root root        16 Mar 26  2019 python3-config -> python3.7-config
    >   -rwxr-xr-x. 2 root root   4877888 Dec 20  2019 python3.7
    >   lrwxrwxrwx. 1 root root        33 Dec 20  2019 python3.7-config -> x86_64-linux-gnu-python3.7-config
    >   -rwxr-xr-x. 2 root root   4877888 Dec 20  2019 python3.7m
    >   lrwxrwxrwx. 1 root root        34 Dec 20  2019 python3.7m-config -> x86_64-linux-gnu-python3.7m-config
    >   lrwxrwxrwx. 1 root root        10 Mar 26  2019 python3m -> python3.7m
    >   lrwxrwxrwx. 1 root root        17 Mar 26  2019 python3m-config -> python3.7m-config
    >   lrwxrwxrwx. 1 root root        29 Mar  4  2019 pyversions -> ../share/python/pyversions.py
    >   lrwxrwxrwx. 1 root root        23 Mar 21  2019 ranlib -> x86_64-linux-gnu-ranlib
    >   lrwxrwxrwx. 1 root root        24 Mar 21  2019 readelf -> x86_64-linux-gnu-readelf
    >   ....
    >   ....


# -----------------------------------------------------
# Check the shell environment on the Spark worker.
#[user@kubernator]

    podname=zeppelin-a82feb73906cfda8-exec-1
    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        exec \
            "${podname:?}" \
            -- \
                bash \
                    -c set
    >   BASH=/bin/bash
    >   BASHOPTS=checkwinsize:cmdhist:complete_fullquote:extquote:force_fignore:globasciiranges:hostcomplete:interactive_comments:progcomp:promptvars:sourcepath
    >   BASH_ALIASES=()
    >   BASH_ARGC=()
    >   BASH_ARGV=()
    >   BASH_CMDS=()
    >   BASH_EXECUTION_STRING=set
    >   BASH_LINENO=()
    >   BASH_SOURCE=()
    >   BASH_VERSINFO=([0]="5" [1]="0" [2]="3" [3]="1" [4]="release" [5]="x86_64-pc-linux-gnu")
    >   BASH_VERSION='5.0.3(1)-release'
    >   DEBIAN_FRONTEND=noninteractive
    >   DIRSTACK=()
    >   EUID=185
    >   GROUPS=()
    >   HOME=/opt/spark
    >   HOSTNAME=zeppelin-a82feb73906cfda8-exec-1
    >   HOSTTYPE=x86_64
    >   IFS=$' \t\n'
    >   JAVA_BASE_URL=https://github.com/AdoptOpenJDK/openjdk8-upstream-binaries/releases/download/jdk8u262-b10/OpenJDK8U-jre_
    >   JAVA_HOME=/usr/local/openjdk-8
    >   JAVA_URL_VERSION=8u262b10
    >   JAVA_VERSION=8u262
    >   KUBERNETES_PORT=tcp://10.254.0.1:443
    >   KUBERNETES_PORT_443_TCP=tcp://10.254.0.1:443
    >   KUBERNETES_PORT_443_TCP_ADDR=10.254.0.1
    >   KUBERNETES_PORT_443_TCP_PORT=443
    >   KUBERNETES_PORT_443_TCP_PROTO=tcp
    >   KUBERNETES_SERVICE_HOST=10.254.0.1
    >   KUBERNETES_SERVICE_PORT=443
    >   KUBERNETES_SERVICE_PORT_HTTPS=443
    >   LANG=C.UTF-8
    >   MACHTYPE=x86_64-pc-linux-gnu
    >   OPTERR=1
    >   OPTIND=1
    >   OSTYPE=linux-gnu
    >   PATH=/usr/local/openjdk-8/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
    >   PPID=0
    >   PS4='+ '
    >   PWD=/opt/spark/work-dir
    >   SHELL=/bin/false
    >   SHELLOPTS=braceexpand:hashall:interactive-comments
    >   SHLVL=1
    >   SPARK_APPLICATION_ID=spark-application-1595855930170
    >   SPARK_CONF_DIR=/opt/spark/conf
    >   SPARK_DRIVER_URL=spark://CoarseGrainedScheduler@spark-zwwxrb.default.svc:22321
    >   SPARK_EXECUTOR_CORES=1
    >   SPARK_EXECUTOR_ID=1
    >   SPARK_EXECUTOR_MEMORY=1g
    >   SPARK_EXECUTOR_POD_IP=10.100.1.14
    >   SPARK_HOME=/opt/spark
    >   SPARK_JAVA_OPT_0=-Dspark.blockManager.port=22322
    >   SPARK_JAVA_OPT_1=-Dspark.driver.port=22321
    >   SPARK_LOCAL_DIRS=/var/data/spark-9454b4d0-b095-4bc3-b087-e281402a3e73
    >   SPARK_USER=zeppelin
    >   TERM=dumb
    >   UID=185
    >   ZEPPELIN_EXTERNAL_PORT=tcp://10.254.201.110:80
    >   ZEPPELIN_EXTERNAL_PORT_80_TCP=tcp://10.254.201.110:80
    >   ZEPPELIN_EXTERNAL_PORT_80_TCP_ADDR=10.254.201.110
    >   ZEPPELIN_EXTERNAL_PORT_80_TCP_PORT=80
    >   ZEPPELIN_EXTERNAL_PORT_80_TCP_PROTO=tcp
    >   ZEPPELIN_EXTERNAL_SERVICE_HOST=10.254.201.110
    >   ZEPPELIN_EXTERNAL_SERVICE_PORT=80
    >   ZEPPELIN_EXTERNAL_SERVICE_PORT_HTTP=80
    >   ZEPPELIN_SERVER_PORT=tcp://10.254.95.55:80
    >   ZEPPELIN_SERVER_PORT_12320_TCP=tcp://10.254.95.55:12320
    >   ZEPPELIN_SERVER_PORT_12320_TCP_ADDR=10.254.95.55
    >   ZEPPELIN_SERVER_PORT_12320_TCP_PORT=12320
    >   ZEPPELIN_SERVER_PORT_12320_TCP_PROTO=tcp
    >   ZEPPELIN_SERVER_PORT_80_TCP=tcp://10.254.95.55:80
    >   ZEPPELIN_SERVER_PORT_80_TCP_ADDR=10.254.95.55
    >   ZEPPELIN_SERVER_PORT_80_TCP_PORT=80
    >   ZEPPELIN_SERVER_PORT_80_TCP_PROTO=tcp
    >   ZEPPELIN_SERVER_SERVICE_HOST=10.254.95.55
    >   ZEPPELIN_SERVER_SERVICE_PORT=80
    >   ZEPPELIN_SERVER_SERVICE_PORT_HTTP=80
    >   ZEPPELIN_SERVER_SERVICE_PORT_RPC=12320
    >   _=bash


# -----------------------------------------------------
# Really nasty heck - move the symlink.
#[user@kubernator]

    podname=zeppelin-a82feb73906cfda8-exec-1
    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        exec \
            "${podname:?}" \
            -- \
                bash -c \
                    '
                    cd /usr/bin ;
                    rm python ;
                    ln -s python3 python ;
                    ls -al
                    '


    >   rm: cannot remove 'python': Permission denied
    >   ln: failed to create symbolic link 'python': File exists
    >   ....
    >   ....
    >   lrwxrwxrwx. 1 root root         7 Mar  4  2019 python -> python2
    >   ....
    >   ....


# -----------------------------------------------------
# Login to the pod and see what we can find ...
# https://kubernetes.io/docs/tasks/debug-application-cluster/get-shell-running-container/
#[user@kubernator]

    podname=zeppelin-a82feb73906cfda8-exec-1
    kubectl \
        --kubeconfig "${HOME}/.kube/${clustername:?}/config" \
        exec \
            --stdin \
            "${podname:?}" \
            -- \
                /bin/bash

    cat /opt/entrypoint.sh

    >   ....
    >   if [ "$PYSPARK_MAJOR_PYTHON_VERSION" == "2" ]; then
    >       pyv="$(python -V 2>&1)"
    >       export PYTHON_VERSION="${pyv:7}"
    >       export PYSPARK_PYTHON="python"
    >       export PYSPARK_DRIVER_PYTHON="python"
    >   elif [ "$PYSPARK_MAJOR_PYTHON_VERSION" == "3" ]; then
    >       pyv3="$(python3 -V 2>&1)"
    >       export PYTHON_VERSION="${pyv3:7}"
    >       export PYSPARK_PYTHON="python3"
    >       export PYSPARK_DRIVER_PYTHON="python3"
    >   fi
    >   ....

    echo "Test [${PYSPARK_MAJOR_PYTHON_VERSION}]"

    >   Test []

    #
    # If PYSPARK_MAJOR_PYTHON_VERSION is not set .. then Spark just uses the default python ?
    # Which is python2 on the worker nodes.
    #





