#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --hostname kubernator \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --env "clustername=${CLUSTER_NAME:?}" \
        --volume "${HOME}/clouds.yaml:/etc/openstack/clouds.yaml:z" \
        --volume "${AGLAIS_CODE}/experiments/zrq/kubernetes:/kubernetes:z" \
        atolmis/openstack-client \
        bash


# -----------------------------------------------------
# Get the connection details for our cluster.
#[user@kubernator]

    mkdir -p "${HOME}/.kube"
    openstack \
        --os-cloud "${cloudname:?}-super" \
        coe cluster config \
            "${clustername:?}" \
                --force \
                --dir "${HOME}/.kube"

    kubectl \
        cluster-info


    >   Kubernetes master is running at https://....
    >   Heapster is running at https://....
    >   CoreDNS is running at https://....


# -----------------------------------------------------
# List the active Pods.
#[user@kubernator]

    kubectl \
        get Pod

    >   NAME                                                         READY   STATUS    RESTARTS   AGE
    >   augusta-20200814-ingress-nginx-controller-779bf4dbc7-vffmt   1/1     Running   0          9h
    >   spark-ktcijc                                                 1/1     Running   0          5m41s
    >   valeria-20200814-kubernetes-dashboard-5f5644bc46-tbqp9       2/2     Running   0          9h
    >   zeppelin-97c0ff73ec7adc58-exec-1                             1/1     Running   0          5m26s
    >   zeppelin-97c0ff73ec7adc58-exec-2                             1/1     Running   0          5m26s
    >   zeppelin-97c0ff73ec7adc58-exec-3                             1/1     Running   0          5m26s
    >   zeppelin-97c0ff73ec7adc58-exec-4                             1/1     Running   0          5m26s
    >   zeppelin-97c0ff73ec7adc58-exec-5                             1/1     Running   0          5m26s
    >   zeppelin-97c0ff73ec7adc58-exec-6                             1/1     Running   0          5m22s
    >   zeppelin-server-d78dc55f9-6qm5s                              3/3     Running   0          9h


# -----------------------------------------------------
# Tail the log for the Spark controller.
#[user@kubernator]

    driverpod=$(
        kubectl \
            --output json \
            get Pod \
        | jq -r '.items[].metadata | select(.name | test("^spark.")) | .name '
        )

    kubectl logs -f \
        "${driverpod:?}"




# -----------------------------------------------------
# Tail the log for a Spark executor.
#[user@kubernator]

    workerpod=$(
        kubectl \
            --output json \
            get Pod \
        | jq -r '
            [
            .items[].metadata |
                select(
                    .name
                  | test(
                    "^zeppelin."
                    )
                )
            ] |
            .[0].name
            '
        )

    kubectl logs -f \
        "${workerpod:?}"


    >   ....
    >   ....
    >   20/08/14 10:57:03 WARN TransportResponseHandler: Ignoring response for RPC 6882001857432005368 from spark-rroyih.default.svc/10.100.5.27:22321 (81 bytes) since it is not outstanding
    >   20/08/14 10:57:03 WARN TransportResponseHandler: Ignoring response for RPC 6452963422864536022 from spark-rroyih.default.svc/10.100.5.27:22321 (81 bytes) since it is not outstanding
    >   20/08/14 10:57:18 WARN Executor: Issue communicating with driver in heartbeater
    >   org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
    >   	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
    >   	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
    >   	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
    >   	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
    >   	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
    >   	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
    >   	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:911)
    >   	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:205)
    >   	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
    >   	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)
    >   	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
    >   	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
    >   	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
    >   	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
    >   	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
    >   	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    >   	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    >   	at java.lang.Thread.run(Thread.java:748)
    >   Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
    >   	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
    >   	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
    >   	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:294)
    >   	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
    >   	... 13 more

    #
    # All of the worker nodes showing the same error.
    # None of them are able to contact the driver.
    #

    # Same error messages
    # https://community.cloudera.com/t5/Support-Questions/spark-application-communicating-with-driver-in-heartbeater/td-p/180506

        "This is just a warning message, but each failure increments heartbeat failure count
        and when we hit the maximum failures the executor will fail and exit with error."

    #
    # Worker and driver nodes stuck waiting for each other.
    # Once it gets here - abort doesn't work.
    # No way to cancel the jop from the GUI.
    # User is left with a stuck system.
    #







