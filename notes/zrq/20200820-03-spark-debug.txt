#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

    Try csv files in S3 - FAIL
    Is S3 the problem ?
        - try copy the data to Ceph ?


    Submit jobs to Spark directly
    https://spark.apache.org/docs/latest/submitting-applications.html

        ./bin/spark-submit \
            --class org.apache.spark.examples.SparkPi \
            --master k8s://xx.yy.zz.ww:443 \
            --deploy-mode cluster \
            --executor-memory 20G \
            --num-executors 50 \
            http://path/to/examples.jar \
            1000


    Submit jobs via the Zeppelin REST API.

    Add user accounts to Zeppelin config.

    Try more complex select tasks.

    Try some of Nigel's examples.


# -----------------------------------------------------

    Looking at the Spark GUI

        The active executors are not showing any tasks







