#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

    #
    # Continuing from prev notes ...
    # 


# -----------------------------------------------------
# Run the initial part of our deplyment.
#[root@ansibler]

    ansible-playbook \
        --inventory "hosts.yml" \
        "combined-01.yml"

    >   ....
    >   ....


# -----------------------------------------------------
# Run the Hadoop part of our deplyment.
#[root@ansibler]

    ansible-playbook \
        --inventory "hosts.yml" \
        "combined-02.yml"

    >   ....
    >   ....


# -----------------------------------------------------
# Check the status of our HDFS filesystem.
#[root@ansibler]

    #
    # https://github.com/wfau/aglais/blob/master/notes/stv/20191209-openstack-deployment.txt#L601
    # Leave safe mode. (Without this we get exceptions when running yarn jobs)
    #   hdfs dfsadmin -safemode leave
    #

    ssh master01 \
        '
        hdfs dfsadmin -safemode get 
        '

    >   2020-04-09 13:50:14,327 ERROR conf.Configuration: error parsing conf yarn-site.xml
    >   com.ctc.wstx.exc.WstxParsingException: String '--' not allowed in comment (missing '>'?)
    >    at [row,col,system-id]: [103,5,"file:/opt/hadoop-3.2.1/etc/hadoop/yarn-site.xml"]
    >   	at com.ctc.wstx.sr.StreamScanner.constructWfcException(StreamScanner.java:621)
    >   	at com.ctc.wstx.sr.StreamScanner.throwParseError(StreamScanner.java:491)
    >   	at com.ctc.wstx.sr.StreamScanner.throwParseError(StreamScanner.java:475)
    >   ....

    #
    # Fixed a typo in the XML and re-deployed.
    # ....

    ansible-playbook \
        --inventory "hosts.yml" \
        "16-config-yarn-masters.yml"

    
    ssh master01 \
        '
        hdfs dfsadmin -safemode get 
        '

    >   safemode: Call From aglais-20200408-master01.novalocal/10.10.0.13 to master01:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused


# -----------------------------------------------------
# Format the HDFS NameNode on master01.
#[root@ansibler]

    ssh master01 \
        '
        hdfs namenode -format
        '
        
    >   2020-04-09 14:16:00,152 INFO namenode.NameNode: STARTUP_MSG: 
    >   /..
    >   STARTUP_MSG: Starting NameNode
    >   STARTUP_MSG:   host = aglais-20200408-master01.novalocal/10.10.0.13
    >   STARTUP_MSG:   args = [-format]
    >   STARTUP_MSG:   version = 3.2.1
    >   STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:....
    >   STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z
    >   STARTUP_MSG:   java = 13.0.2
    >   ************************************************************/
    >   2020-04-09 14:16:00,163 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
    >   2020-04-09 14:16:00,273 INFO namenode.NameNode: createNameNode [-format]
    >   2020-04-09 14:16:00,706 INFO common.Util: Assuming 'file' scheme for path /var/local/hadoop/namenode/fsimage in configuration.
    >   Formatting using clusterid: CID-0fdd17da-8ed3-4b8b-9c54-231452bbd671
    >   2020-04-09 14:16:00,706 INFO common.Util: Assuming 'file' scheme for path /var/local/hadoop/namenode/fsimage in configuration.
    >   2020-04-09 14:16:00,742 INFO namenode.FSEditLog: Edit logging is async:true
    >   2020-04-09 14:16:00,754 INFO namenode.FSNamesystem: KeyProvider: null
    >   2020-04-09 14:16:00,755 INFO namenode.FSNamesystem: fsLock is fair: true
    >   2020-04-09 14:16:00,755 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
    >   2020-04-09 14:16:00,784 INFO namenode.FSNamesystem: fsOwner             = fedora (auth:SIMPLE)
    >   2020-04-09 14:16:00,784 INFO namenode.FSNamesystem: supergroup          = supergroup
    >   2020-04-09 14:16:00,784 INFO namenode.FSNamesystem: isPermissionEnabled = true
    >   2020-04-09 14:16:00,784 INFO namenode.FSNamesystem: HA Enabled: false
    >   2020-04-09 14:16:00,829 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
    >   2020-04-09 14:16:00,858 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
    >   2020-04-09 14:16:00,858 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
    >   2020-04-09 14:16:00,861 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
    >   2020-04-09 14:16:00,862 INFO blockmanagement.BlockManager: The block deletion will start around 2020 Apr 09 14:16:00
    >   2020-04-09 14:16:00,863 INFO util.GSet: Computing capacity for map BlocksMap
    >   2020-04-09 14:16:00,863 INFO util.GSet: VM type       = 64-bit
    >   2020-04-09 14:16:00,864 INFO util.GSet: 2.0% max memory 1.5 GB = 29.8 MB
    >   2020-04-09 14:16:00,864 INFO util.GSet: capacity      = 2^22 = 4194304 entries
    >   2020-04-09 14:16:00,885 INFO blockmanagement.BlockManager: Storage policy satisfier is disabled
    >   2020-04-09 14:16:00,885 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false
    >   2020-04-09 14:16:00,890 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
    >   2020-04-09 14:16:00,890 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
    >   2020-04-09 14:16:00,890 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
    >   2020-04-09 14:16:00,890 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
    >   2020-04-09 14:16:00,891 INFO blockmanagement.BlockManager: defaultReplication         = 2
    >   2020-04-09 14:16:00,891 INFO blockmanagement.BlockManager: maxReplication             = 512
    >   2020-04-09 14:16:00,891 INFO blockmanagement.BlockManager: minReplication             = 1
    >   2020-04-09 14:16:00,891 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
    >   2020-04-09 14:16:00,891 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
    >   2020-04-09 14:16:00,891 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
    >   2020-04-09 14:16:00,891 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
    >   2020-04-09 14:16:00,907 INFO namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911
    >   2020-04-09 14:16:00,907 INFO namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215
    >   2020-04-09 14:16:00,907 INFO namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215
    >   2020-04-09 14:16:00,908 INFO namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215
    >   2020-04-09 14:16:00,916 INFO util.GSet: Computing capacity for map INodeMap
    >   2020-04-09 14:16:00,916 INFO util.GSet: VM type       = 64-bit
    >   2020-04-09 14:16:00,916 INFO util.GSet: 1.0% max memory 1.5 GB = 14.9 MB
    >   2020-04-09 14:16:00,917 INFO util.GSet: capacity      = 2^21 = 2097152 entries
    >   2020-04-09 14:16:00,919 INFO namenode.FSDirectory: ACLs enabled? false
    >   2020-04-09 14:16:00,919 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true
    >   2020-04-09 14:16:00,919 INFO namenode.FSDirectory: XAttrs enabled? true
    >   2020-04-09 14:16:00,919 INFO namenode.NameNode: Caching file names occurring more than 10 times
    >   2020-04-09 14:16:00,923 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
    >   2020-04-09 14:16:00,924 INFO snapshot.SnapshotManager: SkipList is disabled
    >   2020-04-09 14:16:00,927 INFO util.GSet: Computing capacity for map cachedBlocks
    >   2020-04-09 14:16:00,927 INFO util.GSet: VM type       = 64-bit
    >   2020-04-09 14:16:00,927 INFO util.GSet: 0.25% max memory 1.5 GB = 3.7 MB
    >   2020-04-09 14:16:00,927 INFO util.GSet: capacity      = 2^19 = 524288 entries
    >   2020-04-09 14:16:00,933 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
    >   2020-04-09 14:16:00,933 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
    >   2020-04-09 14:16:00,933 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
    >   2020-04-09 14:16:00,936 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
    >   2020-04-09 14:16:00,936 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
    >   2020-04-09 14:16:00,937 INFO util.GSet: Computing capacity for map NameNodeRetryCache
    >   2020-04-09 14:16:00,937 INFO util.GSet: VM type       = 64-bit
    >   2020-04-09 14:16:00,938 INFO util.GSet: 0.029999999329447746% max memory 1.5 GB = 457.7 KB
    >   2020-04-09 14:16:00,938 INFO util.GSet: capacity      = 2^16 = 65536 entries
    >   2020-04-09 14:16:00,958 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1954636092-10.10.0.13-1586441760951
    >   2020-04-09 14:16:00,967 INFO common.Storage: Storage directory /var/local/hadoop/namenode/fsimage has been successfully formatted.
    >   2020-04-09 14:16:01,002 INFO namenode.FSImageFormatProtobuf: Saving image file /var/local/hadoop/namenode/fsimage/current/fsimage.ckpt_0000000000000000000 using no compression
    >   2020-04-09 14:16:01,087 INFO namenode.FSImageFormatProtobuf: Image file /var/local/hadoop/namenode/fsimage/current/fsimage.ckpt_0000000000000000000 of size 401 bytes saved in 0 seconds .
    >   2020-04-09 14:16:01,095 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
    >   2020-04-09 14:16:01,109 INFO namenode.FSImage: FSImageSaver clean checkpoint: txid=0 when meet shutdown.
    >   2020-04-09 14:16:01,110 INFO namenode.NameNode: SHUTDOWN_MSG: 
    >   /..
    >   SHUTDOWN_MSG: Shutting down NameNode at aglais-20200408-master01.novalocal/10.10.0.13
    >   ************************************************************/


# -----------------------------------------------------
# Start the HDFS daemon on master01.
#[fedora@master01]

    ssh master01 \
        '
        hdfs --daemon start namenode
        '

    >   -


# -----------------------------------------------------
# -----------------------------------------------------
# Use podman exec to open a new terminal logged in to our ansible-client.
# https://github.com/containers/libpod/blob/master/docs/source/markdown/podman-ps.1.md
#[user@desktop]

    ansiblerid=$(    
        podman ps --filter 'name=ansibler' --format "{{.ID}}"
        )

    podman exec -it ${ansiblerid:?} bash

    >   [root@ansibler]


# -----------------------------------------------------
# Tail the log file.
#[root@ansibler]

    ssh master01 \
        '
        pushd '/var/local/hadoop/logs/'
            tail -f hadoop-fedora-namenode-$(hostname).log
        '

    >   ....
    >   2020-04-09 17:58:07,130 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
    >   2020-04-09 17:58:07,130 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
    >   2020-04-09 17:58:07,130 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 29 msec
    >   2020-04-09 17:58:07,132 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
    >   2020-04-09 17:58:07,132 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
    >   2020-04-09 17:58:07,144 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 11 milliseconds
    >   name space=1
    >   storage space=0
    >   storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
    >   2020-04-09 17:58:07,147 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
    >   ....


# -----------------------------------------------------
# -----------------------------------------------------
# Start the HDFS daemon on  our worker nodes.
#[root@ansibler]

    ssh worker01 \
        '
        hdfs --daemon start datanode
        '


    ssh worker02 \
        '
        hdfs --daemon start datanode
        '


# -----------------------------------------------------
# -----------------------------------------------------
# Connect a new terminal and tail the DataNode log files.
#[user@desktop]

    ansiblerid=$(    
        podman ps --filter 'name=ansibler' --format "{{.ID}}"
        )

    podman exec -it ${ansiblerid:?} bash

        ssh worker01 \
            '
            tail -f /var/local/hadoop/logs/hadoop-fedora-datanode-$(hostname).log
            '
        
    >   ....
    >   2020-04-09 18:01:46,051 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-871325164-10.10.0.9-1586455064315: 7ms
    >   2020-04-09 18:01:46,053 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-871325164-10.10.0.9-1586455064315 on volume /data-01/hdfs/data
    >   2020-04-09 18:01:46,054 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data-01/hdfs/data, DS-91ff8be1-4b02-4b1b-9d9b-b9957f26c8f5): finished scanning block pool BP-871325164-10.10.0.9-1586455064315
    >   2020-04-09 18:01:46,079 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data-01/hdfs/data, DS-91ff8be1-4b02-4b1b-9d9b-b9957f26c8f5): no suitable block pools found to scan.  Waiting 1814399974 ms.
    >   2020-04-09 18:01:46,079 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 4/9/20, 9:15 PM with interval of 21600000ms
    >   2020-04-09 18:01:46,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-871325164-10.10.0.9-1586455064315 (Datanode Uuid 3496c58c-c7f6-4edd-8e47-c879c05d78f2) service to master01/10.10.0.9:9000 beginning handshake with NN
    >   2020-04-09 18:01:46,132 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-871325164-10.10.0.9-1586455064315 (Datanode Uuid 3496c58c-c7f6-4edd-8e47-c879c05d78f2) service to master01/10.10.0.9:9000 successfully registered with NN
    >   2020-04-09 18:01:46,132 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master01/10.10.0.9:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
    >   2020-04-09 18:01:46,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xd7423f86526c509d,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 48 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
    >   2020-04-09 18:01:46,236 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-871325164-10.10.0.9-1586455064315
    >   ....

        ssh worker02 \
            '
            tail -f /var/local/hadoop/logs/hadoop-fedora-datanode-$(hostname).log
            '

    >   ....
    >   2020-04-09 18:02:01,133 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-871325164-10.10.0.9-1586455064315: 6ms
    >   2020-04-09 18:02:01,134 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-871325164-10.10.0.9-1586455064315 on volume /data-01/hdfs/data
    >   2020-04-09 18:02:01,135 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data-01/hdfs/data, DS-e8c5f719-70a0-4643-a6b7-4253f0825ef6): finished scanning block pool BP-871325164-10.10.0.9-1586455064315
    >   2020-04-09 18:02:01,155 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 4/9/20, 11:47 PM with interval of 21600000ms
    >   2020-04-09 18:02:01,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-871325164-10.10.0.9-1586455064315 (Datanode Uuid a201be51-3ea6-4ae2-ab38-7f1904bdf2ea) service to master01/10.10.0.9:9000 beginning handshake with NN
    >   2020-04-09 18:02:01,174 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/data-01/hdfs/data, DS-e8c5f719-70a0-4643-a6b7-4253f0825ef6): no suitable block pools found to scan.  Waiting 1814399960 ms.
    >   2020-04-09 18:02:01,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-871325164-10.10.0.9-1586455064315 (Datanode Uuid a201be51-3ea6-4ae2-ab38-7f1904bdf2ea) service to master01/10.10.0.9:9000 successfully registered with NN
    >   2020-04-09 18:02:01,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master01/10.10.0.9:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
    >   2020-04-09 18:02:01,230 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xcdc1ea630f157f83,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 16 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
    >   2020-04-09 18:02:01,230 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-871325164-10.10.0.9-1586455064315
    >   ....


# -----------------------------------------------------
# -----------------------------------------------------
# Create another terminal and login to the other (spare) master node.
#[user@desktop]

    ansiblerid=$(    
        podman ps --filter 'name=ansibler' --format "{{.ID}}"
        )

    podman exec -it ${ansiblerid:?} bash

        ssh master02

# -----------------------------------------------------
# Check the HDFS status.
#[fedora@master02]

    hdfs dfsadmin -report

    >   Configured Capacity: 2199023255552 (2 TB)
    >   Present Capacity: 2194692120576 (2.00 TB)
    >   DFS Remaining: 2194692112384 (2.00 TB)
    >   DFS Used: 8192 (8 KB)
    >   DFS Used%: 0.00%
    >   Replicated Blocks:
    >   	Under replicated blocks: 0
    >   	Blocks with corrupt replicas: 0
    >   	Missing blocks: 0
    >   	Missing blocks (with replication factor 1): 0
    >   	Low redundancy blocks with highest priority to recover: 0
    >   	Pending deletion blocks: 0
    >   Erasure Coded Block Groups: 
    >   	Low redundancy block groups: 0
    >   	Block groups with corrupt internal blocks: 0
    >   	Missing block groups: 0
    >   	Low redundancy blocks with highest priority to recover: 0
    >   	Pending deletion blocks: 0
    >   
    >   -------------------------------------------------
    >   Live datanodes (2):
    >   
    >   Name: 10.10.0.23:9866 (worker02)
    >   Hostname: worker02
    >   Decommission Status : Normal
    >   Configured Capacity: 1099511627776 (1 TB)
    >   DFS Used: 4096 (4 KB)
    >   Non DFS Used: 17297408 (16.50 MB)
    >   DFS Remaining: 1097346056192 (1021.98 GB)
    >   DFS Used%: 0.00%
    >   DFS Remaining%: 99.80%
    >   Configured Cache Capacity: 0 (0 B)
    >   Cache Used: 0 (0 B)
    >   Cache Remaining: 0 (0 B)
    >   Cache Used%: 100.00%
    >   Cache Remaining%: 0.00%
    >   Xceivers: 1
    >   Last contact: Thu Apr 09 18:10:55 UTC 2020
    >   Last Block Report: Thu Apr 09 18:02:01 UTC 2020
    >   Num of Blocks: 0
    >   
    >   
    >   Name: 10.10.0.4:9866 (worker01)
    >   Hostname: worker01
    >   Decommission Status : Normal
    >   Configured Capacity: 1099511627776 (1 TB)
    >   DFS Used: 4096 (4 KB)
    >   Non DFS Used: 17297408 (16.50 MB)
    >   DFS Remaining: 1097346056192 (1021.98 GB)
    >   DFS Used%: 0.00%
    >   DFS Remaining%: 99.80%
    >   Configured Cache Capacity: 0 (0 B)
    >   Cache Used: 0 (0 B)
    >   Cache Remaining: 0 (0 B)
    >   Cache Used%: 100.00%
    >   Cache Remaining%: 0.00%
    >   Xceivers: 1
    >   Last contact: Thu Apr 09 18:10:55 UTC 2020
    >   Last Block Report: Thu Apr 09 18:01:46 UTC 2020
    >   Num of Blocks: 0
    
    
# -----------------------------------------------------
# Download some test data.
#[fedora@master02]

    sudo dnf install -y wget

    >   ....
    >   Installed:
    >     wget-1.20.3-1.fc30.x86_64


    wget http://cdn.gea.esac.esa.int/Gaia/gdr2/gaia_source/csv/

    >   wget http://cdn.gea.esac.esa.int/Gaia/gdr2/gaia_source/csv/
    >   --2020-04-09 18:13:27--  http://cdn.gea.esac.esa.int/Gaia/gdr2/gaia_source/csv/
    >   Resolving cdn.gea.esac.esa.int (cdn.gea.esac.esa.int)... 185.93.1.7
    >   Connecting to cdn.gea.esac.esa.int (cdn.gea.esac.esa.int)|185.93.1.7|:80... connected.
    >   HTTP request sent, awaiting response... 200 OK
    >   Length: unspecified [text/html]
    >   Saving to: ‘index.html’
    >   
    >   index.html  [   <=>   ]   9.63M  5.51MB/s    in 1.7s    
    >   
    >   2020-04-09 18:13:29 (5.51 MB/s) - ‘index.html’ saved [10093850]

    
    head index.html

    >   <html>
    >   <head><title>Index of /Gaia/gdr2/gaia_source/csv/</title></head>
    >   <body>
    >   <h1>Index of /Gaia/gdr2/gaia_source/csv/</h1><hr><pre><a href="../">../</a>
    >   <a href="GaiaSource_1000172165251650944_1000424567594791808.csv.gz">GaiaSource_1000172165251650944_1000424567594791..&gt;</a> 16-Apr-2018 07:32             5347523
    >   <a href="GaiaSource_1000424601954531200_1000677322125743488.csv.gz">GaiaSource_1000424601954531200_1000677322125743..&gt;</a> 16-Apr-2018 07:32             5024698
    >   <a href="GaiaSource_1000677386549270528_1000959999693425920.csv.gz">GaiaSource_1000677386549270528_1000959999693425..&gt;</a> 16-Apr-2018 07:32             5976430
    >   <a href="GaiaSource_1000960034052654336_1001215258190537216.csv.gz">GaiaSource_1000960034052654336_1001215258190537..&gt;</a> 16-Apr-2018 07:32             6102333
    >   ....


    tail index.html

    >   ....
    >   <a href="GaiaSource_999299767199192704_999535170063180672.csv.gz">GaiaSource_999299767199192704_99953517006318067..&gt;</a> 16-Apr-2018 10:19             7062102
    >   <a href="GaiaSource_999535200126184320_999716967439074432.csv.gz">GaiaSource_999535200126184320_99971696743907443..&gt;</a> 16-Apr-2018 10:19             5795991
    >   <a href="GaiaSource_999717001796824064_999922369954904960.csv.gz">GaiaSource_999717001796824064_99992236995490496..&gt;</a> 16-Apr-2018 10:19             5240860
    >   <a href="GaiaSource_999922404314639104_1000172126596665472.csv.gz">GaiaSource_999922404314639104_10001721265966654..&gt;</a> 16-Apr-2018 10:19             5375567
    >   <a href="MD5SUM.txt">MD5SUM.txt</a>                                         22-Jun-2018 13:13             5623335
    >   <a href="_citation.txt">_citation.txt</a>                                      22-May-2018 15:39                 171
    >   <a href="_disclaimer.txt">_disclaimer.txt</a>                                    22-May-2018 15:39                 921
    >   </pre><hr></body>
    >   </html>


    sed -n '
        s/^<a href="\(GaiaSource[^"]*\)">.*/\1/p
        ' index.html \
    | tee files.txt


    >   GaiaSource_1000172165251650944_1000424567594791808.csv.gz
    >   GaiaSource_1000424601954531200_1000677322125743488.csv.gz
    >   GaiaSource_1000677386549270528_1000959999693425920.csv.gz
    >   GaiaSource_1000960034052654336_1001215258190537216.csv.gz
    >   ....
    >   ....
    >   GaiaSource_999299767199192704_999535170063180672.csv.gz
    >   GaiaSource_999535200126184320_999716967439074432.csv.gz
    >   GaiaSource_999717001796824064_999922369954904960.csv.gz
    >   GaiaSource_999922404314639104_1000172126596665472.csv.gz


    head files.txt
    
    >   GaiaSource_1000172165251650944_1000424567594791808.csv.gz
    >   GaiaSource_1000424601954531200_1000677322125743488.csv.gz
    >   GaiaSource_1000677386549270528_1000959999693425920.csv.gz
    >   GaiaSource_1000960034052654336_1001215258190537216.csv.gz
    >   ....
    

    tail files.txt
    
    >   ....
    >   GaiaSource_999299767199192704_999535170063180672.csv.gz
    >   GaiaSource_999535200126184320_999716967439074432.csv.gz
    >   GaiaSource_999717001796824064_999922369954904960.csv.gz
    >   GaiaSource_999922404314639104_1000172126596665472.csv.gz


    mkdir downloads
    pushd downloads

        for filename in $(head -n 10 ${HOME:?}/files.txt)
        do
            wget "http://cdn.gea.esac.esa.int/Gaia/gdr2/gaia_source/csv/${filename}"
        done
    
    popd



    >   --2020-04-09 18:22:32--  http://cdn.gea.esac.esa.int/Gaia/gdr2/gaia_source/csv/GaiaSource_1000172165251650944_1000424567594791808.csv.gz
    >   Resolving cdn.gea.esac.esa.int (cdn.gea.esac.esa.int)... 185.59.221.24
    >   Connecting to cdn.gea.esac.esa.int (cdn.gea.esac.esa.int)|185.59.221.24|:80... connected.
    >   HTTP request sent, awaiting response... 200 OK
    >   Length: 5347523 (5.1M) [application/octet-stream]
    >   Saving to: ‘GaiaSource_1000172165251650944_1000424567594791808.csv.gz’
    >   
    >   GaiaSource_1000172165251650944_1000424567594791808.csv.gz   100%[===>]   5.10M  10.2MB/s    in 0.5s    
    >   
    >   2020-04-09 18:22:32 (10.2 MB/s) - ‘GaiaSource_1000172165251650944_1000424567594791808.csv.gz’ saved [5347523/5347523]
    >   ....
    >   ....


    ls -alh downloads/

    >   total 55M
    >   drwxrwxr-x. 2 fedora fedora 4.0K Apr  9 18:22 .
    >   drwx------. 5 fedora fedora 4.0K Apr  9 18:22 ..
    >   -rw-rw-r--. 1 fedora fedora 5.1M Apr 16  2018 GaiaSource_1000172165251650944_1000424567594791808.csv.gz
    >   -rw-rw-r--. 1 fedora fedora 4.8M Apr 16  2018 GaiaSource_1000424601954531200_1000677322125743488.csv.gz
    >   -rw-rw-r--. 1 fedora fedora 5.7M Apr 16  2018 GaiaSource_1000677386549270528_1000959999693425920.csv.gz
    >   -rw-rw-r--. 1 fedora fedora 5.9M Apr 16  2018 GaiaSource_1000960034052654336_1001215258190537216.csv.gz
    >   -rw-rw-r--. 1 fedora fedora 5.9M Apr 16  2018 GaiaSource_1001215288252921728_1001455428465395840.csv.gz
    >   -rw-rw-r--. 1 fedora fedora 6.3M Apr 16  2018 GaiaSource_1001455467121397632_1001731032222989696.csv.gz
    >   -rw-rw-r--. 1 fedora fedora 5.4M Apr 16  2018 GaiaSource_1001731062285590912_1001962891736267904.csv.gz
    >   -rw-rw-r--. 1 fedora fedora 6.0M Apr 16  2018 GaiaSource_1001962921802480896_1002270686272717312.csv.gz
    >   -rw-rw-r--. 1 fedora fedora 3.3M Apr 16  2018 GaiaSource_100222516391441280_100632114537641344.csv.gz
    >   -rw-rw-r--. 1 fedora fedora 6.8M Apr 16  2018 GaiaSource_1002270754991788288_1002616826277079168.csv.gz


# -----------------------------------------------------
# Transfer the files into HDFS.
#[fedora@master02]


    hdfs dfs -mkdir /Gaia
    hdfs dfs -mkdir /Gaia/gdr2
    hdfs dfs -mkdir /Gaia/gdr2/gaia_source
    hdfs dfs -mkdir /Gaia/gdr2/gaia_source/csv
    
    for filename in $(head -n 10 ${HOME:?}/files.txt)
    do
        hdfs dfs -put "downloads/${filename}" /Gaia/gdr2/gaia_source/csv/
    done

    >   ....
    >   ....


# -----------------------------------------------------
# List the files in HDFS.
#[fedora@master02]

    hdfs dfs -ls /Gaia/gdr2/gaia_source/csv/

    >   Found 10 items
    >   -rw-r--r--   3 fedora supergroup    5347523 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1000172165251650944_1000424567594791808.csv.gz
    >   -rw-r--r--   3 fedora supergroup    5024698 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1000424601954531200_1000677322125743488.csv.gz
    >   -rw-r--r--   3 fedora supergroup    5976430 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1000677386549270528_1000959999693425920.csv.gz
    >   -rw-r--r--   3 fedora supergroup    6102333 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1000960034052654336_1001215258190537216.csv.gz
    >   -rw-r--r--   3 fedora supergroup    6143061 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1001215288252921728_1001455428465395840.csv.gz
    >   -rw-r--r--   3 fedora supergroup    6517254 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1001455467121397632_1001731032222989696.csv.gz
    >   -rw-r--r--   3 fedora supergroup    5591548 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1001731062285590912_1001962891736267904.csv.gz
    >   -rw-r--r--   3 fedora supergroup    6225326 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1001962921802480896_1002270686272717312.csv.gz
    >   -rw-r--r--   3 fedora supergroup    3445051 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_100222516391441280_100632114537641344.csv.gz
    >   -rw-r--r--   3 fedora supergroup    7090884 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1002270754991788288_1002616826277079168.csv.gz


# -----------------------------------------------------
# List the files in HDFS from each of the workers.
#[fedora@master02]

    ssh worker01 \
        '
        hdfs dfs -ls /Gaia/gdr2/gaia_source/csv/
        '

    >   Found 10 items
    >   -rw-r--r--   3 fedora supergroup    5347523 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1000172165251650944_1000424567594791808.csv.gz
    >   -rw-r--r--   3 fedora supergroup    5024698 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1000424601954531200_1000677322125743488.csv.gz
    >   -rw-r--r--   3 fedora supergroup    5976430 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1000677386549270528_1000959999693425920.csv.gz
    >   -rw-r--r--   3 fedora supergroup    6102333 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1000960034052654336_1001215258190537216.csv.gz
    >   -rw-r--r--   3 fedora supergroup    6143061 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1001215288252921728_1001455428465395840.csv.gz
    >   -rw-r--r--   3 fedora supergroup    6517254 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1001455467121397632_1001731032222989696.csv.gz
    >   -rw-r--r--   3 fedora supergroup    5591548 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1001731062285590912_1001962891736267904.csv.gz
    >   -rw-r--r--   3 fedora supergroup    6225326 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1001962921802480896_1002270686272717312.csv.gz
    >   -rw-r--r--   3 fedora supergroup    3445051 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_100222516391441280_100632114537641344.csv.gz
    >   -rw-r--r--   3 fedora supergroup    7090884 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1002270754991788288_1002616826277079168.csv.gz


    ssh worker02 \
        '
        hdfs dfs -ls /Gaia/gdr2/gaia_source/csv/
        '

    >   -rw-r--r--   3 fedora supergroup    5347523 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1000172165251650944_1000424567594791808.csv.gz
    >   -rw-r--r--   3 fedora supergroup    5024698 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1000424601954531200_1000677322125743488.csv.gz
    >   -rw-r--r--   3 fedora supergroup    5976430 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1000677386549270528_1000959999693425920.csv.gz
    >   -rw-r--r--   3 fedora supergroup    6102333 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1000960034052654336_1001215258190537216.csv.gz
    >   -rw-r--r--   3 fedora supergroup    6143061 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1001215288252921728_1001455428465395840.csv.gz
    >   -rw-r--r--   3 fedora supergroup    6517254 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1001455467121397632_1001731032222989696.csv.gz
    >   -rw-r--r--   3 fedora supergroup    5591548 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1001731062285590912_1001962891736267904.csv.gz
    >   -rw-r--r--   3 fedora supergroup    6225326 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1001962921802480896_1002270686272717312.csv.gz
    >   -rw-r--r--   3 fedora supergroup    3445051 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_100222516391441280_100632114537641344.csv.gz
    >   -rw-r--r--   3 fedora supergroup    7090884 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1002270754991788288_1002616826277079168.csv.gz


    ssh master01 \
        '
        hdfs dfs -ls /Gaia/gdr2/gaia_source/csv/
        '

    >   -rw-r--r--   3 fedora supergroup    5347523 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1000172165251650944_1000424567594791808.csv.gz
    >   -rw-r--r--   3 fedora supergroup    5024698 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1000424601954531200_1000677322125743488.csv.gz
    >   -rw-r--r--   3 fedora supergroup    5976430 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1000677386549270528_1000959999693425920.csv.gz
    >   -rw-r--r--   3 fedora supergroup    6102333 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1000960034052654336_1001215258190537216.csv.gz
    >   -rw-r--r--   3 fedora supergroup    6143061 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1001215288252921728_1001455428465395840.csv.gz
    >   -rw-r--r--   3 fedora supergroup    6517254 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1001455467121397632_1001731032222989696.csv.gz
    >   -rw-r--r--   3 fedora supergroup    5591548 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1001731062285590912_1001962891736267904.csv.gz
    >   -rw-r--r--   3 fedora supergroup    6225326 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1001962921802480896_1002270686272717312.csv.gz
    >   -rw-r--r--   3 fedora supergroup    3445051 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_100222516391441280_100632114537641344.csv.gz
    >   -rw-r--r--   3 fedora supergroup    7090884 2020-04-09 18:25 /Gaia/gdr2/gaia_source/csv/GaiaSource_1002270754991788288_1002616826277079168.csv.gz


# -----------------------------------------------------
# Fetch a file from HDFS and checksum it on our workers.
#[fedora@master02]

    filename=GaiaSource_1000172165251650944_1000424567594791808.csv.gz

    ssh worker01 \
        "
        mkdir /tmp/gaia
        hdfs dfs -get -crc /Gaia/gdr2/gaia_source/csv/${filename:?} /tmp/gaia
        md5sum /tmp/gaia/${filename:?}
        "

    >   c4c70eca274a4ecf9e24e488e79e2495  /tmp/gaia/GaiaSource_1002270754991788288_1002616826277079168.csv.gz

    ssh worker02 \
        "
        mkdir /tmp/gaia
        hdfs dfs -get -crc /Gaia/gdr2/gaia_source/csv/${filename:?} /tmp/gaia
        md5sum /tmp/gaia/${filename:?}
        "

    >   c4c70eca274a4ecf9e24e488e79e2495  /tmp/gaia/GaiaSource_1002270754991788288_1002616826277079168.csv.gz



