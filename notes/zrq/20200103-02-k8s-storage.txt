#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

    -------------------------

    volume_driver: ""

    docker_storage_driver: overlay2                                                                                                                                                                                                                                                                                                                                                                              |
    docker_volume_size: '0'                                                                                                                                                                                                                                                                                                                                                                                      |
    docker_volume_type: rbd                                                                                                                                                                                                                                                                                                                                                                                      |

    volume type rdb

        Block device in the container linked to a Ceph filesystem service.

        Ceph RADOS Block Device Driver
        https://docs.ceph.com/docs/master/rbd/

        RADOS (Reliable Autonomic Distributed Object Store)
        https://searchstorage.techtarget.com/definition/RADOS-Reliable-Autonomic-Distributed-Object-Store

        Ceph in OpenStack
        https://docs.ceph.com/docs/master/rbd/rbd-openstack/

        Ceph in Kubernetes
        https://docs.ceph.com/docs/master/rbd/rbd-kubernetes/



# -----------------------------------------------------
# List our volumes.
#[user@openstacker]

    time \
        openstack \
            --os-cloud "${cloudname:?}" \
            volume list

    >   real	0m2.853s
    >   user	0m1.038s
    >   sys	0m0.116s

    #
    # We don't have any volumes allocated yet.
    #

    #
    # What happens if we ask for a volume from inside K8s ?
    # _how_ do we allocate a volume from inside K8s ?
    # If we do allocate a volume inside K8s, can we see it in OpenStack ?
    #

    #
    # Create a shared filesystem in OpenStack.
    # Mount the shared file system in some of our K8s nodes.
    #

# -----------------------------------------------------

    #
    # Storage options in K8s
    # https://kubernetes.io/docs/concepts/storage/

    #
    # Ceph storage in K8s
    # https://kubernetes.io/docs/concepts/storage/#cephfs

        "A cephfs volume allows an existing CephFS volume to
        be mounted into your Pod. Unlike emptyDir, which is
        erased when a Pod is removed, the contents of a cephfs
        volume are preserved and the volume is merely unmounted.
        This means that a CephFS volume can be pre-populated with
        data, and that data can be “handed off” between Pods.
        CephFS can be mounted by multiple writers simultaneously."

    #
    # The example is a little thin.
    # https://github.com/kubernetes/examples/tree/master/volumes/cephfs/

        "Install Ceph on the Kubernetes host."
        - is that all of the machines that are hosting Kubernetes?
        - so in our case, all of the cluster worker nodes?
        - all of the worker nodes that contain pods that have volumes on the CephFS filesystem?

        "get the keyring from the Ceph cluster and copy it to /etc/ceph/keyring"
        - again, do we need to do this on all of the cluster worker nodes?
        - all of the worker nodes that contain pods that have volumes on the CephFS filesystem?
        - will the Magnum template help with that?

        implication is that a worker node can only be linked to one CephFS service
        unless /etc/ceph/keyring can contain multople keys ?

    #
    # What is a pod?
    # https://kubernetes.io/docs/concepts/workloads/pods/pod/

        "A Pod (as in a pod of whales or pea pod) is a group of one or more containers
        (such as Docker containers), with shared storage/network, and a specification
        for how to run the containers."

        Sounds like a pod is equivalent to the way we use a docker-compose file
        to group containers, networks and volumes.

        "In terms of Docker constructs, a Pod is modelled as a group of Docker containers
        with shared namespaces and shared filesystem volumes."

        Unlike docker-compose, containers within the pod share a single IP address.
        'localhost' works from one container to another within the pod.

    #
    # The distributed system toolkit patterns
    # https://kubernetes.io/blog/2015/06/the-distributed-system-toolkit-patterns/

    #
    # Container storage interface (CSI)
    # https://kubernetes.io/blog/2019/01/15/container-storage-interface-ga/


    #
    # April 17, 2019
    # The Future of Cloud Providers in Kubernetes
    # https://kubernetes.io/blog/2019/04/17/the-future-of-cloud-providers-in-kubernetes/

        In-tree - developed as part of the K8s code base.
        Out-of-tree - developed and released independent of Kubernetes core

    #
    # Kubernetes Enhancement Proposals (KEPs)
    # https://github.com/kubernetes/enhancements/tree/master/keps#kubernetes-enhancement-proposals-keps

    #
    # Cloud provider KEPS
    # https://github.com/kubernetes/enhancements/tree/master/keps/sig-cloud-provider

    #
    # Supporting Out-of-Tree OpenStack Cloud Provider
    # https://github.com/kubernetes/enhancements/blob/master/keps/sig-cloud-provider/20190125-out-of-tree-openstack.md

        Implementation and testing completed in 2018.
        Matching kubernetes versions released from v1.11, latest version is v1.16.

    #
    # Cloud Provider OpenStack
    # https://github.com/kubernetes/cloud-provider-openstack

        * OpenStack Cloud Controller Manager
        * Octavia Ingress Controller
        * Cinder CSI Plugin
        * Keystone Webhook Authentication Authorization
        * Client Keystone
        * Cinder Standalone Provisioner[DEPRECATED]
        * Manila CSI Plugin
        * Manila Provisioner
        * Barbican KMS Plugin


    #
    # CSI Manila driver
    # https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/using-manila-csi-plugin.md

        "The CSI Manila driver is able to create and mount OpenStack Manila shares."

        "... Helm is the preferred way of deployment because it greatly simplifies the
        difficulties with managing multiple share protocols."

    #
    # So, can we create a CephFS Manilla share ?
    #


    #
    # How to run a Kubernetes cluster in OpenStack
    # https://superuser.openstack.org/articles/how-to-run-a-kubernetes-cluster-in-openstack/

        Simple example we can build on ..

        "Make sure to install Helm in the master node ..."


    #
    # Juju
    # https://en.wikipedia.org/wiki/Juju_(software)

        Yet another orchestration system this time from Canonical.
        Yet another layer of abstraction ...
        Tied to yet another provider ...


    #
    # Kubernetes: How to Share Disk Storage Between Containers in a Pod
    # https://www.stratoscale.com/blog/kubernetes/kubernetes-how-to-share-disk-storage-between-containers-in-a-pod/

        Nice simple example we can build on ... ?



    #
    # https://kubernetes.io/docs/concepts/storage/storage-classes/

        apiVersion: storage.k8s.io/v1
        kind: StorageClass
        provisioner: kubernetes.io/cinder
        ...

        This internal provisioner of OpenStack is deprecated. Please use the external cloud provider for OpenStack.

    #
    # Cloud Provider OpenStack
    # https://github.com/kubernetes/cloud-provider-openstack

        See above ..


    #
    # Dynamic Storage Provisioning of Manila/CephFS Shares on Kubernetes
    # https://www.openstack.org/videos/summits/berlin-2018/dynamic-storage-provisioning-of-manilacephfs-shares-on-kubernetes
    # https://www.youtube.com/watch?v=ruFdq-bB6ew
    # https://object-storage-ca-ymq-1.vexxhost.net/swift/v1/6e4619c416ff4bd19e1c087f27a43eea/www-assets-prod/presentation-media/presentation4.pdf

        #20
        * Container Storage Interface (CSI) is collaboration between Kubernetes, Mesos Docker and Cloud Foundry.
        * RPC services (endpoints)
            * Controller service - Creates, deletes and lists volumes and snapshots
            * Node service - stages and publishes volumes on a 'node' (VM?)

        #28
        * Magnum→Kubernetes + manila-provisioner StorageClass+ trustee secrets = Manila support out-of-the-box
        * Shared authentication credentials work for creating shares etc ..

        #30
        * Manila Provisioner

        #55
        Next Steps
            * Add support for volume expansion and snapshots
            * Make the Manila Provisioner a CSI plugin
                * At the moment Manila Provisioner is K8s specific.
                  Making it a CSI plugin means it can work with other Orchestration services.



    #
    # Kubelet
    # https://coreos.com/blog/introducing-the-kubelet-in-coreos.html

        "The kubelet is responsible for maintaining a set of pods, which are composed
        of one or more containers, on a local system. Within a Kubernetes cluster,
        the kubelet functions as a local agent that watches for pod specs via the
        Kubernetes API server. The kubelet is also responsible for registering a node
        with a Kubernetes cluster, sending events and pod status, and reporting resource
        utilization."

    #
    # Kubelet
    # https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/

        "The kubelet is the primary “node agent” that runs on each node. It can register
        the node with the apiserver using one of: the hostname; a flag to override the
        hostname; or specific logic for a cloud provider."

    #
    # Monolithic vs microkernel
    # http://www.aboutlinux.info/2006/05/monolithic-kernel-vs-microkernel-which.html

        "A Monolithic kernel is an OS architecture where the entire operating system
        (which includes the device drivers, file system, and the application IPC) is
        working in kernel space."

        "Where as in a Microkernel architecture, the core functionality is isolated from
        system services and device drivers (which are basically just system services)."

        K8s is the new OS
        Microkernel architecture, with everything in containers.

    #
    # ceph-csi
    # https://github.com/ceph/ceph-csi

        Ceph based implemenmtation of the CSI interface.
        Out-of-tree, separate from the main K8s code base.

    #
    # https://github.com/kubernetes/cloud-provider-openstack

        See above

    #
    # Hyper converged infrastructure (HCI)
    # https://en.wikipedia.org/wiki/Hyper-converged_infrastructure

        "Hyper-converged infrastructure (HCI) is a software-defined IT
        infrastructure that virtualizes all of the elements of conventional
        'hardware-defined' systems."

        "Hyperconvergence evolves away from discrete, hardware-defined systems
        that are connected and packaged together toward a purely software-defined
        environment where all functional elements run on commercial, off-the-shelf
        (COTS) servers, with the convergence of elements enabled by a hypervisor."

        "HCI infrastructures are usually made up of server systems equipped with
        Direct-Attached Storage (DAS)."

        "HCI includes the ability to plug and play into a data-center pool of like
        systems. All physical data-center resources reside on a single administrative
        platform for both hardware and software layers."

        "Consolidation of all functional elements at the hypervisor level, together
        with federated management, eliminates traditional data-center inefficiencies
        and reduces the total cost of ownership (TCO) for data centers."

    #
    # Direct-Attached Storage (DAS)
    # https://en.wikipedia.org/wiki/Direct-attached_storage

        "Direct-attached storage (DAS) is digital storage directly attached to the
        computer accessing it, as opposed to storage accessed over a computer network
        (i.e. network-attached storage)."


    #
    # Run a container that does nothing
    docker run -d fedora /usr/bin/bash -c 'while true ; do date; sleep 10; done'

    #
    # The almighty pause container
    # https://www.ianlewis.org/en/almighty-pause-container


    Configure the Cinder provisioner
    Test we can allocate volume for each container.

    Configure the Magnum provisioner
    Create a Magnum share of a CephFS filesystem.
    Test we can access it from Docker containers inside K8s.




