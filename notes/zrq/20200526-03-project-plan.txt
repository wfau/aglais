#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#



# -----------------------------------------------------
# Describe the system from the user's perspective.


    Aglais website - register and login

        Visit the home page and click the [give it a try] button.

            Unknown account created based generated identifier.

                New account added to DB linked to generated identifier.
                account type = anonymous

                Single use time limited login token saved in DB.
                301 redirect to Zeppelin site with login token in the URL.


        Visit the home page and click the [login/register] button.

            Login using OAuth providers
                [Google]
                [FaceBook]
                [GitHub]
                ....

                OAuth process ....
                Known account selected based on OAuth identifier.

                    Single use time limited login token saved in DB.
                    301 redirect to Zeppelin site with login token in the URL.

                Unknown account created based on OAuth identifier.

                    Intermediate pages ask for additional info ?

                    New account added to DB linked to OAuth identifier.
                    account type = basic

                    Single use time limited login token saved in DB.
                    301 redirect to Zeppelin site with login token in the URL.


            Login using email/password
                [email]
                [password]

                Known account selected based on email as identifier.

                    Single use time limited login token saved in DB.
                    301 redirect to Zeppelin site with login token in the URL.

                Unknown account created based on email as identifier.

                    New account added to DB linked to email and password.

                "Please check your email for a confirmation code."

                    Single use time limited confirmation code saved in DB.
                    Email contains link with confirmation code in the URL [http://example.com/confirm/#####].

                User gets the email and clicks on the [confirm] link.

                    GET request to the URL marks email as confirmed in DB and expires the confirmation code.
                    Single use time limited login token saved in DB.
                    301 redirect to Zeppelin site with login token in the URL.

        We have enough requirements to justify a project website, separate from the Zeppelin website.
        Placing this functionality in our own website should development easier.
        Trying to fit this functionality into the Zeppelin website means modifying it to fit with a 3rd party structure.
        If we decide to include Jupyter as well as Zeppelin, then we would have to re-write code embedded Zeppelin.
        If we decide to allow webservice access, then we would have to re-write code embedded Zeppelin.

    Zeppelin login

        Zeppelin user/pass login not used.
        Same model as IRIS login to OpenStack Horizon GUI.

        Zeppelin landing page extracts login token and converts it to user login.
        301 redirect to Zeppelin with session cookies set.


    Account registration micro-service

        Separate web service, used by the main website, also available via REST API.

        Guest/anon users are all connected to the same Spark instance ?
            Sounds simpler but in reality, probably not.
            Would need to limit any changes to the instance to prevent cross contamination.
            Would need to cleanup any changes to the instance when a user leaves.
            Lessons learned from covid - disposable PPE is easier

        Guest/anon users get their own Spark instance ?
            Disposable scalable deployments are easier to manage.
            No need to clean the instance, just destory it.
            Lessons learned from covid - disposable PPE is easier

        Guest/anon users get limited resources.
            Single Zeppelin instance.
            Single Spark master.
            Limits on
                * Zeppelin worker cores
                * Zeppelin worker memory
                * Spark worker cores
                * Spark worker memory
            K8s configuration may share VMs between guest accounts


        Level-0 Anonymous account :

            Notebooks  - max number and size
            Saved data - none
            /temp data - max number and size

            /temp data deleted on exit
            Notebooks deleted on exit

            Level-0 access is always available.
            Share compute resources with other level-0 users.
            Separate Docker containers and K8s pods sharing a single OpenStack Magnum cluster.

            Level-0 access is always transient.
                When the Zeppelin user logs out; everything gets deleted.
                When the Zeppelin session expires; everything gets deleted.


            (stretch goal)
            Warning on logout with level-0 account :
                "Your notebooks and data will be deleted"
                [OK][Cancel]

            (stretch goal)
            Option to register level-0 account from inside Zeppelin
                [Register] button


        Level-1 Basic user account :

            Notebooks  - max number and size
            Saved data - max number and size
            /temp data - max number and size

            /temp data deleted after - days
            Saved data deleted after - months
            Notebooks deleted after  - months

            Level-1 registered accounts get more resources.
            Share compute resources with other level-1 users.
            Separate Docker containers and K8s pods sharing one or more OpenStack Magnum cluster(s).

            Level-1 accounts can book extended compute resources


        Level-n custom user account :

            Account attributes set manually.

            Notebooks  - max number and size
            Saved data - max number and size
            /temp data - max number and size

            /temp data deleted after - days
            Notebooks not deleted
            By default saved data deleted after - months
            Option manually extend expiry dates on specific resources
                [Keep permanently] allocation

            Level-n accounts can book extended compute resources


    Resource booking micro-service

        Separate web service, used by the main website, also available via REST API.

        Level-1 accounts can book extended compute resources

        Register a booking for compute resources and resource sharing

            Resource packages

                Standard package sizes set limits for

                    * Zeppelin worker cores
                    * Zeppelin worker memory
                    * Spark worker cores
                    * Spark worker memory

                Tiny
                    Level-0 accounts get tiny package

                Small
                    Level-1 accounts get small package by default

                Medium
                Large
                    Level-1+ can reserve medium and large packages for specific periods of time

                Custom
                    Level-n+ can reserve custom instances for specific periods of time
                        * Zeppelin worker cores
                        * Zeppelin worker memory
                        * Spark worker cores
                        * Spark worker memory

            Resource sharing

                Shared
                    Level-0 accounts always share the same OpenStack resources

                Managed
                    Level-1 accounts may be sharing some OpenStack resources
                    System manages the sharing based on load.

                Reserved
                    Level-1+ can reserve their own OpenStack resources for specific periods of time

                Custom (stretch)
                    Level-n+ can reserve custom resources for specific periods of time
                        * Specific platforms - Cumulus, RAL, Google, Azure ...
                        * Specific hardware - CPU, GPU, SSD ...


        Calendar based booking system

            Booking information calculated for a specific time period

                Timeline of physical resources (database/API)
                Timeline of reserved resources (database)

                    available = physical - reserved

                Timeline of available resources (calculated)

            Use cases :

                Availability based

                    What resources are available today ..
                    What resources are available tomorrow, next week, next month ..


                Select and book available packages in a block.

                    Book a small package for two days

                         large  --- --- --- --- --- === ===
                         medium === --- --- --- === === ===
                         small  === === ---[### ###]=== === <-- book this package
                         tiny   === === === === === === ===
                                Mon Tue Web Thu Fri Sat Sun

                    Book a medium package for three days

                         large  --- --- --- --- --- === ===
                         medium === --- --- ---[### ### ###] <-- book this package
                         small  === === --- === === === ===
                         tiny   === === === === === === ===
                                Mon Tue Web Thu Fri Sat Sun

                Display availability for a specific package


                Show availability for this week :

                     large  --- --- --- --- --- === ===
                     medium === --- --- --- === === ===
                     small  === === --- === === === ===
                     tiny   === === === === === === ===
                            Mon Tue Web Thu Fri Sat Sun


                Show availability for large and medium for this month :

                     large  --- --- --- --- --- === === === === === --- --- --- --- ...
                     medium === --- --- --- === === === === === === === === --- === ...
                            Mon Tue Web Thu Fri Sat Sun Mon Tue Web Thu Fri Sat Sun ...


                Show availability for a custom package for May-Jul 2020

                     custom ===== ----- ----- ----- ===== ===== ===== ===== ===== =====
                            May25 Jun01 Jun08 Jun15 Jun22 Jun29 Jul06 Jul13 Jul20 Jul27




            (stretch goal)
            Extend granularity to hourly.

            (stretch goal)
            Stretch goal to support interruptable processing, booking resources in multiple time spans.
            Use cases
                Booking large instances at multiple weekends
                Booking long running processing to run overnight for a week

            (stretch goal)
            Spare time
                Lower level accounts can run interruptable jobs in spare time.


            (stretch goal)
            Blazar integration

                StackHPC are planning to deploy OpenStack Blazar on Cumulus cloud a Cambridge.
                https://docs.openstack.org/blazar/latest/

                Work with StackHPC to integrate our booking service with OpenStack Blazar.
                Reservations are offered/booked based on available compute resources.
                Dynamic allocations on OpenStack ..

            (stretch goal)
            Request more resources button.
            Users can ask for more resources to be added by clicking a button and filling in a form.
            Project admin can negotiate with Cumulus admin to get more resources allocated.
                Implication - the available resources are not a fixed level.
                Available resource allocations have a size and a start/end date.



    Zeppelin content

        Zeppelin /examples directory is read-only mount of NFS/CephFS share.
        Zeppelin /user directory is read-write mount of NFS/CephFS share.

        Notebook directories
          +-- examples
                +-- tiny
                      +-- example analysis that will run in a tiny package
                      +-- example analysis that will run in a tiny package
                +-- small
                      +-- example analysis that will run in a small package
                +-- medium
                      +-- example analysis that will run in a medium package
                      +-- example analysis that will run in a medium package
                +-- large
                      +-- example analysis that will run in a large package

          +-- utils
                +-- single cell howto examples
                +-- count rows
                +-- basic SQL query
                +-- plot a graph

          +-- user
                +-- my first notebook
                +-- my other notebook

        Test notebook directory

            Available to all
            Visible during development
            Hidden by defult in production

          +-- tests
                +-- tiny
                      +-- test analysis that will run in a tiny package
                      +-- test analysis that will run in a tiny package
                +-- small
                      +-- test analysis that will run in a small package
                +-- medium
                      +-- test analysis that will run in a medium package
                      +-- test analysis that will run in a medium package
                +-- large
                      +-- test analysis that will run in a large package


        Example notebooks available for experimenting.
        Select an example and run it.

        Available examples depend on resource package

            Only show examples that will run on your package ?
            Show all examples but prevent large examples running on small resources ?

        Resource package in notebook environment variable.
            resources.package = [tiny, small, medium, large ..]

        Resource quotas in notebook environment variables.
            resources.worker.cores = [10]
            resources.worker.memory = [10]
            [....]

        Place examples in package directories
            examples/tiny
            examples/small
            examples/medium
            examples/large

        Notebook header section checks the resource package and quotas.
            "WARN - Not enough resources available"
            "This notebook requires a large package"


        Example notebooks are read only
        Copy an example to create an editable version.
            User notebooks are editable and runnable.

        Create your own notebooks edit and run them.
            User notebooks are editable and runnable.

        Level-0 users have temporary notebook space.
        Level-0 users have temporary dataset space.


        (stretch goal)
        Shared note books
            How do we manage shared notebooks ?
            Allow two or more users to collaborate on a notebook ?
            Is this a common use case ?

        (stretch goal)
        Editable examples
            Edit and run an example in place - no copy needed.
            Reset an example to original state


    Source control

        Source control handled in Aglais website not Zeppelin.
        File system list view.

        Each notebook has a web page
          +-- user
                +-- notebook page
                +-- notebook page

        Notebook page has [resource] section.

            Details of the compute resources needed for the notebook.

        Notebook page has [environment] section.

            Details of the Spark environment needed for the notebook.
            * see below

        Notebook page has [dependencies] section.

            Details of the dependencies needed for the notebook.

        Notebook page has [sync] section.

            [git]

                Import from Git

                    Select a repository, clone into /user space.
                    Execution controls, ignore binary files - malware !
                    Remember the link to origin repository.
                    [pull] to refresh from repository

                Export to Git

                    SSH authentication
                        Generate key pair in Aglais platform, transfer public key to GitHub.
                        SSH keys for a user account
                            authorized keys
                            generated keys

                    Create a repository
                    Select a repository
                        Remember the account details
                        Remember the link to origin repository.
                        [pull] to refresh from repository
                        [push] to save to repository
                        How do we resolve conflicts ?

            [svn]

                Same as git

            [GitHub]

                Same as git

                Plus GitHub login via OAuth delegation

            [GitLab]

                Same as GitHub


    Acces control

        SSH keys stored for a user account
            authorized keys
            generated keys

        (stretch goal)
        Authorized keys allow level-n users command line access virtual machines
            Spark master nodes
            Spark worker nodes


    Spark environment

        Platform configuration for running a set of analyses.
        By default, users gets a copy of standard Spark environment.

        Environment config contains a system configutation as a JSON document

        The Spark system is built from the system configutation.
            Cached Docker images of standard configutations
          - Power users can modify the configutation and build a new Docker image
          + Power users can post GitHub PR requests to modify the configuration, and system admins build new Docker images.

            Automated build from JSON configuration document.
            This is NOT just a Spark/Kubernetes configuration renamed.
            Our code needs to parse the JSON configuration to build a Spark/Kubernetes configuration for the image.
            We need to avoid straight pass though which would expose system config to end users.

        Options for environment.

            Python version
            Python packages

            Java version
            Java packages

            System version
            System packages

            Binary packages
                binary.so library for Roger's analysis

        Dependency resolution
            Manual resolution, automated testing and GitHub review process.
            Environment config managed as source code.




    Technical requirements

        Separation between business logic (accounts, resources quotas etc.) and website view (html, css etc.).
        No mixed content files e.g. SQL and HTML in the same component.

        Micro service architecture.
        REST form-post/json-get webservices
        Python client based on common code base

        Every 'thing' has a web service URL.
        Every 'thing' has a web service editor.

        Every 'thing' has a website URL.
        Every 'thing' has a website editor.

        Micro services are designed to be scaleable.
        Stateless webapp and state stored in DB.
        Avoid sharing database state between webapps.
            No JOIN between resource tables and account tables.
            Webapp databases run as separate instances

    Testing requirements

        Everything needs an automated test to show it works.

        Zeppelin notebooks can be invoked via the REST API.
            Bash script to run a notebook and check the result.
            Python client to run a notebook and check the result.
            Standard way of expressing a test API [version] at the start of the notebook.
            Standard way of expressing a testable [result] at the end of the notebook.
            Standard logging/monitoring includes write to Kafka

        Spark jobs can be invoked via a ssh login to a master.
            Bash script to run a Spark job and check the result.
            Python client to run a Spark job and check the result.
            Standard way of expressing a test API [version] at the start of the job.
            Standard way of expressing a testable [result] at the end of the job.
            Standard logging/monitoring includes write to Kafka






# -----------------------------------------------------
# Map theese onto service architecture

--
Account levels

    Level-0 Anonymous account
    Level-1 Basic user account
    Level-n Custom user account

    account-manager service

        - account login
        - account levels
        - account tokens

Resource packages

    Standard package sizes setting limits for
    [tiny, small, medium, large, custom]

        * Zeppelin worker cores
        * Zeppelin worker memory
        * Spark worker cores
        * Spark worker memory
        * Local disk space

    Overall number of cores, memory etc.
    Mapped to the K8s resource limits not the VM sizes.
    User (normally) has no knowledge of the underlying VM resources.

    resource-manager service

        - booking system
        - package templates


Resource sharing

    Shared   - shared cluster
    Managed  - load balanced auto-scaling
    Reserved - exclusive use

    Mapped to the K8s cluster on OpenStack VMs.
    Shared = using the same K8s Magnum cluster and OpenStack VMs.
    Reserved = separate K8s Magnum cluster on separate OpenStack VMs.

    cluster-manager service

        - interaction with Helm, K8s, Magnum and OpenStack

Config packages

    Standard packages, custom config for reserved resources
    Jupyter, Zeppelin and Spark config

    * Gaia01
    * GaiaML
    * ...

        Python version
        Python packages

        Java version
        Java packages

        System version
        System packages

        Binary packages

    Stored as combination of JSON object and key|value pairs.

    config-manager service

        - package templates

Storage space

    Temp data space
    User data space
    Shared data space

    storage-manager service

        - temp, user and shared space allocation
        - interaction with CephFS, NFS, Manila and OpenStack
        - file:// URLs in Zeppelin and Spark

Access control

    library code for authentication
    library code for access control

Logging

    library code to write logs to Kafka

    logging-service

        - interact with Kafka to manage topics
        - interact with Kafka to manage schema

Website

    Website content framework
        Python  Django ?
        Java    Spring

--
Twelve-factor software-as-a-service pattern
https://12factor.net/
--







